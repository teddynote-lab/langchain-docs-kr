---
title: v1의 새로운 기능
sidebarTitle: 릴리스 노트
---

**LangChain v1은 에이전트 구축을 위한 집중적이고 프로덕션 준비가 완료된 기반입니다.** 세 가지 핵심 개선 사항을 중심으로 프레임워크를 간소화했습니다:

<CardGroup cols={1}>
    <Card title="create_agent" icon="robot" href="#create-agent" arrow>
        LangChain에서 에이전트를 구축하는 새로운 표준으로, `langgraph.prebuilt.create_react_agent`를 대체합니다.
    </Card>
    <Card title="표준 content block" icon="cube" href="#standard-content-blocks" arrow>
        제공자 간에 최신 LLM 기능에 대한 통합 액세스를 제공하는 새로운 `content_blocks` 속성입니다.
    </Card>
    <Card title="간소화된 namespace" icon="sitemap" href="#simplified-package" arrow>
        `langchain` namespace는 에이전트를 위한 필수 구성 요소에 집중하도록 간소화되었으며, 레거시 기능은 `langchain-classic`으로 이동되었습니다.
    </Card>
</CardGroup>

업그레이드하려면,

<CodeGroup>
```bash pip
pip install -U langchain
```
```bash uv
uv add langchain
```
</CodeGroup>

전체 변경 사항 목록은 [마이그레이션 가이드](/oss/migrate/langchain-v1)를 참조하세요.

## `create_agent`

@[`create_agent`]는 LangChain 1.0에서 에이전트를 구축하는 표준 방법입니다. @[`langgraph.prebuilt.create_react_agent`][create_react_agent]보다 간단한 인터페이스를 제공하면서 [middleware](#middleware)를 사용하여 더 큰 커스터마이징 가능성을 제공합니다.

```python
from langchain.agents import create_agent


agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    tools=[search_web, analyze_data, send_email],
    system_prompt="You are a helpful research assistant."
)

result = agent.invoke({
    "messages": [
        {"role": "user", "content": "Research AI safety trends"}
    ]
})
```

내부적으로 @[`create_agent`]는 기본 에이전트 루프를 기반으로 구축됩니다 -- 모델을 호출하고, 실행할 도구를 선택하게 한 다음, 더 이상 도구를 호출하지 않을 때 완료됩니다:

<div style={{ display: "flex", justifyContent: "center" }}>
  <img
    src="/oss/images/core_agent_loop.png"
    alt="핵심 에이전트 루프 다이어그램"
    className="rounded-lg"
  />
</div>

자세한 내용은 [Agents](/oss/langchain/agents)를 참조하세요.

### Middleware

Middleware는 @[`create_agent`]의 핵심 기능입니다. 매우 커스터마이징 가능한 진입점을 제공하여 구축할 수 있는 범위를 확장합니다.

훌륭한 에이전트는 [context engineering](/oss/langchain/context-engineering)이 필요합니다: 적절한 시간에 모델에 올바른 정보를 제공하는 것입니다. Middleware는 구성 가능한 추상화를 통해 동적 프롬프트, 대화 요약, 선택적 도구 액세스, 상태 관리 및 가드레일을 제어하는 데 도움을 줍니다.

#### 사전 구축된 middleware

LangChain은 일반적인 패턴을 위한 몇 가지 [사전 구축된 middleware](/oss/langchain/middleware#built-in-middleware)를 제공합니다:

- @[`PIIMiddleware`]: 모델로 전송하기 전에 민감한 정보를 삭제합니다
- @[`SummarizationMiddleware`]: 대화 기록이 너무 길어지면 압축합니다
- @[`HumanInTheLoopMiddleware`]: 민감한 도구 호출에 대한 승인을 요구합니다

```python
from langchain.agents import create_agent
from langchain.agents.middleware import (
    PIIMiddleware,
    SummarizationMiddleware,
    HumanInTheLoopMiddleware
)


agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    tools=[read_email, send_email],
    middleware=[
        PIIMiddleware(patterns=["email", "phone", "ssn"]),
        SummarizationMiddleware(
            model="anthropic:claude-sonnet-4-5",
            max_tokens_before_summary=500
        ),
        HumanInTheLoopMiddleware(
            interrupt_on={
                "send_email": {
                    "allowed_decisions": ["approve", "edit", "reject"]
                }
            }
        ),
    ]
)
```

#### 커스텀 middleware

필요에 맞게 커스텀 middleware를 구축할 수도 있습니다. Middleware는 에이전트 실행의 각 단계에서 hook을 노출합니다:

<div style={{ display: "flex", justifyContent: "center" }}>
  <img
    src="/oss/images/middleware_final.png"
    alt="Middleware 흐름 다이어그램"
    className="rounded-lg"
  />
</div>

@[`AgentMiddleware`] 클래스의 서브클래스에서 다음 hook 중 하나를 구현하여 커스텀 middleware를 구축하세요:

| Hook              | 실행 시점             | 사용 사례                               |
|-------------------|--------------------------|-----------------------------------------|
| `before_agent`    | 에이전트 호출 전 | 메모리 로드, 입력 검증             |
| `before_model`    | 각 LLM 호출 전     | 프롬프트 업데이트, 메시지 트리밍           |
| `wrap_model_call` | 각 LLM 호출 전후     | 요청/응답 가로채기 및 수정 |
| `wrap_tool_call`  | 각 도구 호출 전후    | 도구 실행 가로채기 및 수정     |
| `after_model`     | 각 LLM 응답 후  | 출력 검증, 가드레일 적용       |
| `after_agent`     | 에이전트 완료 후    | 결과 저장, 정리                   |


커스텀 middleware 예제:

```python expandable
from dataclasses import dataclass
from typing import Callable

from langchain_openai import ChatOpenAI

from langchain.agents.middleware import (
    AgentMiddleware,
    ModelRequest
)
from langchain.agents.middleware.types import ModelResponse

@dataclass
class Context:
    user_expertise: str = "beginner"

class ExpertiseBasedToolMiddleware(AgentMiddleware):
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse]
    ) -> ModelResponse:
        user_level = request.runtime.context.user_expertise

        if user_level == "expert":
            # More powerful model
            model = ChatOpenAI(model="openai:gpt-5")
            tools = [advanced_search, data_analysis]
        else:
            # Less powerful model
            model = ChatOpenAI(model="openai:gpt-5-nano")
            tools = [simple_search, basic_calculator]

        request.model = model
        request.tools = tools
        return handler(request)

agent = create_agent(
    model="anthropic:claude-sonnet-4-5",
    tools=[
        simple_search,
        advanced_search,
        basic_calculator,
        data_analysis
    ],
    middleware=[ExpertiseBasedToolMiddleware()],
    context_schema=Context
)
```

자세한 내용은 [전체 middleware 가이드](/oss/langchain/middleware)를 참조하세요.

### LangGraph 기반

@[`create_agent`]는 [LangGraph](/oss/langgraph)를 기반으로 구축되었기 때문에 다음을 통해 장기 실행 및 안정적인 에이전트에 대한 기본 지원을 자동으로 받을 수 있습니다:

<CardGroup cols={2}>
    <Card title="Persistence" icon="database">
        기본 제공 체크포인팅으로 세션 간에 대화가 자동으로 유지됩니다
    </Card>
    <Card title="Streaming" icon="water">
        실시간으로 토큰, 도구 호출 및 추론 추적을 스트리밍합니다
    </Card>
    <Card title="Human-in-the-loop" icon="hand">
        민감한 작업 전에 사람의 승인을 위해 에이전트 실행을 일시 중지합니다
    </Card>
    <Card title="Time travel" icon="clock-rotate-left">
        대화를 임의의 시점으로 되돌리고 대체 경로와 프롬프트를 탐색합니다
    </Card>
</CardGroup>

이러한 기능을 사용하기 위해 LangGraph를 배울 필요가 없습니다—기본적으로 작동합니다.

### Structured output

@[`create_agent`]는 개선된 structured output 생성 기능을 제공합니다:

- **메인 루프 통합**: Structured output이 이제 추가 LLM 호출을 요구하는 대신 메인 루프에서 생성됩니다
- **Structured output 전략**: 모델은 도구 호출과 제공자 측 structured output 생성 중에서 선택할 수 있습니다
- **비용 절감**: 추가 LLM 호출로 인한 추가 비용을 제거합니다

```python
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from pydantic import BaseModel


class Weather(BaseModel):
    temperature: float
    condition: str

def weather_tool(city: str) -> str:
    """Get the weather for a city."""
    return f"it's sunny and 70 degrees in {city}"

agent = create_agent(
    "openai:gpt-4o-mini",
    tools=[weather_tool],
    response_format=ToolStrategy(Weather)
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "What's the weather in SF?"}]
})

print(repr(result["structured_response"]))
# results in `Weather(temperature=70.0, condition='sunny')`
```

**오류 처리**: `ToolStrategy`의 `handle_errors` 매개변수를 통해 오류 처리를 제어합니다:
- **파싱 오류**: 모델이 원하는 구조와 일치하지 않는 데이터를 생성합니다
- **다중 도구 호출**: 모델이 structured output 스키마에 대해 2개 이상의 도구 호출을 생성합니다

---

## 표준 content block

<Note>
    Content block 지원은 현재 다음 통합에서만 사용할 수 있습니다:

    - [`langchain-anthropic`](https://pypi.org/project/langchain-anthropic/)
    - [`langchain-aws`](https://pypi.org/project/langchain-aws/)
    - [`langchain-openai`](https://pypi.org/project/langchain-openai/)
    - [`langchain-google-genai`](https://pypi.org/project/langchain-google-genai/)
    - [`langchain-ollama`](https://pypi.org/project/langchain-ollama/)

    더 많은 제공자에 대한 content block 지원은 점진적으로 확대될 예정입니다.
</Note>

새로운 @[`content_blocks`][BaseMessage(content_blocks)] 속성은 제공자 간에 작동하는 메시지 콘텐츠에 대한 표준 표현을 도입합니다:

```python
from langchain_anthropic import ChatAnthropic

model = ChatAnthropic(model="claude-sonnet-4-5")
response = model.invoke("What's the capital of France?")

# Unified access to content blocks
for block in response.content_blocks:
    if block["type"] == "reasoning":
        print(f"Model reasoning: {block['reasoning']}")
    elif block["type"] == "text":
        print(f"Response: {block['text']}")
    elif block["type"] == "tool_call":
        print(f"Tool call: {block['name']}({block['args']})")
```

### 이점

- **제공자 독립적**: 제공자에 관계없이 동일한 API를 사용하여 추론 추적, 인용, 기본 제공 도구(웹 검색, 코드 인터프리터 등) 및 기타 기능에 액세스합니다
- **타입 안전**: 모든 content block 타입에 대한 완전한 타입 힌트
- **하위 호환성**: 표준 콘텐츠는 [지연 로드](/oss/langchain/messages#standard-content-blocks)될 수 있으므로 관련된 호환성 문제가 없습니다

자세한 내용은 [content block](/oss/langchain/messages#standard-content-blocks)에 대한 가이드를 참조하세요.

---

## 간소화된 패키지

LangChain v1은 [`langchain`](https://pypi.org/project/langchain/) 패키지 namespace를 에이전트를 위한 필수 구성 요소에 집중하도록 간소화합니다. 개선된 namespace는 가장 유용하고 관련성 있는 기능을 노출합니다:

### Namespace

| 모듈 | 사용 가능한 항목 | 참고 사항 |
|--------|------------------|-------|
| @[`langchain.agents`] | @[`create_agent`], @[`AgentState`] | 핵심 에이전트 생성 기능 |
| @[`langchain.messages`] | Message 타입, @[content block][ContentBlock], @[`trim_messages`] | @[`langchain-core`]에서 재내보내기 |
| @[`langchain.tools`] | @[`@tool`], @[`BaseTool`], injection helper | @[`langchain-core`]에서 재내보내기 |
| @[`langchain.chat_models`] | @[`init_chat_model`], @[`BaseChatModel`] | 통합 모델 초기화 |
| @[`langchain.embeddings`] | @[`Embeddings`], @[`init_embeddings`] | Embedding 모델 |

이들 대부분은 편의를 위해 `langchain-core`에서 재내보내기되어 에이전트 구축을 위한 집중된 API 표면을 제공합니다.

```python
# Agent building
from langchain.agents import create_agent

# Messages and content
from langchain.messages import AIMessage, HumanMessage

# Tools
from langchain.tools import tool

# Model initialization
from langchain.chat_models import init_chat_model
from langchain.embeddings import init_embeddings
```

### `langchain-classic`

레거시 기능은 핵심 패키지를 간결하고 집중적으로 유지하기 위해 [`langchain-classic`](https://pypi.org/project/langchain-classic)으로 이동되었습니다.

**`langchain-classic`에 포함된 항목:**

- 레거시 chain 및 chain 구현
- Retriever (예: `MultiQueryRetriever` 또는 이전 `langchain.retrievers` 모듈의 모든 항목)
- Indexing API
- Hub 모듈 (프로그래밍 방식으로 프롬프트 관리)
- [`langchain-community`](https://pypi.org/project/langchain-community) export
- 기타 deprecated 기능

이러한 기능을 사용하는 경우 [`langchain-classic`](https://pypi.org/project/langchain-classic)을 설치하세요:

<CodeGroup>
```bash pip
pip install langchain-classic
```

```bash uv
uv add langchain-classic
```
</CodeGroup>

그런 다음 import를 업데이트하세요:

```python
from langchain import ...  # [!code --]
from langchain_classic import ...  # [!code ++]

from langchain.chains import ...  # [!code --]
from langchain_classic.chains import ...  # [!code ++]

from langchain.retrievers import ...  # [!code --]
from langchain_classic.retrievers import ...  # [!code ++]

from langchain import hub  # [!code --]
from langchain_classic import hub  # [!code ++]
```

## 마이그레이션 가이드

LangChain v1로 코드를 업데이트하는 데 도움이 필요하면 [마이그레이션 가이드](/oss/migrate/langchain-v1)를 참조하세요.

## 이슈 보고

1.0에서 발견된 이슈는 `'v1'` [label](https://github.com/langchain-ai/langchain/issues?q=state%3Aopen%20label%3Av1)을 사용하여 [GitHub](https://github.com/langchain-ai/langchain/issues)에 보고해 주세요.

## 추가 리소스

<CardGroup cols={3}>
    <Card title="LangChain 1.0" icon="rocket" href="https://blog.langchain.com/langchain-langchain-1-0-alpha-releases/">
        공지사항 읽기
    </Card>
    <Card title="Middleware 가이드" icon="puzzle-piece" href="https://blog.langchain.com/agent-middleware/">
        Middleware 심층 분석
    </Card>
    <Card title="Agents 문서" icon="book" href="/oss/langchain/agents" arrow>
        전체 에이전트 문서
    </Card>
    <Card title="Message Content" icon="message" href="/oss/langchain/messages#message-content" arrow>
        새로운 content block API
    </Card>
    <Card title="마이그레이션 가이드" icon="arrow-right-arrow-left" href="/oss/migrate/langchain-v1" arrow>
        LangChain v1로 마이그레이션하는 방법
    </Card>
    <Card title="GitHub" icon="github" href="https://github.com/langchain-ai/langchain">
        이슈 보고 또는 기여
    </Card>
</CardGroup>

## 참고

- [Versioning](/oss/versioning) - 버전 번호 이해하기
- [Release policy](/oss/release-policy) - 상세한 릴리스 정책