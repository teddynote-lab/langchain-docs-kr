---
title: ChatPremAI
---

[PremAI](https://premai.io/)ëŠ” Generative AIë¡œ êµ¬ë™ë˜ëŠ” ê°•ë ¥í•˜ê³  í”„ë¡œë•ì…˜ ì¤€ë¹„ê°€ ì™„ë£Œëœ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±ì„ ê°„ì†Œí™”í•˜ëŠ” ì˜¬ì¸ì› í”Œë«í¼ì…ë‹ˆë‹¤. ê°œë°œ í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”í•¨ìœ¼ë¡œì¨ PremAIë¥¼ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒê³¼ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ë°˜ì ì¸ ì„±ì¥ ì´‰ì§„ì— ì§‘ì¤‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [ì—¬ê¸°](https://docs.premai.io/quick-start)ì—ì„œ í”Œë«í¼ ì‚¬ìš©ì„ ë¹ ë¥´ê²Œ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì˜ˆì œëŠ” `ChatPremAI`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ chat modelê³¼ ìƒí˜¸ì‘ìš©í•˜ê¸° ìœ„í•´ LangChainì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

### Installation ë° setup

ë¨¼ì € `langchain`ê³¼ `premai-sdk`ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤. ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
pip install premai langchain
```

ê³„ì† ì§„í–‰í•˜ê¸° ì „ì— PremAIì— ê³„ì •ì„ ë§Œë“¤ê³  ì´ë¯¸ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš° [quick start](https://docs.premai.io/introduction) ê°€ì´ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ PremAI í”Œë«í¼ì„ ì‹œì‘í•˜ì„¸ìš”. ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•˜ê³  API keyë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”.

```python
from langchain_community.chat_models import ChatPremAI
from langchain.messages import HumanMessage, SystemMessage
```

### LangChainì—ì„œ PremAI client setup

í•„ìš”í•œ moduleì„ importí•œ í›„ clientë¥¼ ì„¤ì •í•´ë´…ì‹œë‹¤. ì§€ê¸ˆì€ `project_id`ê°€ `8`ì´ë¼ê³  ê°€ì •í•˜ê² ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë°˜ë“œì‹œ ìì‹ ì˜ project-idë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

langchainê³¼ premì„ í•¨ê»˜ ì‚¬ìš©í•˜ë ¤ë©´ chat-clientì— model ì´ë¦„ì„ ì „ë‹¬í•˜ê±°ë‚˜ parameterë¥¼ ì„¤ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ [LaunchPad](https://docs.premai.io/get-started/launchpad)ì—ì„œ ì‚¬ìš©ëœ model ì´ë¦„ê³¼ parameterë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

> ì°¸ê³ : clientë¥¼ ì„¤ì •í•  ë•Œ `model`ì´ë‚˜ `temperature` ë˜ëŠ” `max_tokens`ì™€ ê°™ì€ ë‹¤ë¥¸ parameterë¥¼ ë³€ê²½í•˜ë©´ LaunchPadì—ì„œ ì‚¬ìš©ëœ ê¸°ì¡´ ê¸°ë³¸ êµ¬ì„±ì„ ì¬ì •ì˜í•©ë‹ˆë‹¤.

```python
import getpass
import os

# First step is to set up the env variable.
# you can also pass the API key while instantiating the model but this
# comes under a best practices to set it as env variable.

if os.environ.get("PREMAI_API_KEY") is None:
    os.environ["PREMAI_API_KEY"] = getpass.getpass("PremAI API Key:")
```

```python
# By default it will use the model which was deployed through the platform
# in my case it will is "gpt-4o"

chat = ChatPremAI(project_id=1234, model_name="gpt-4o")
```

### Chat Completions

`ChatPremAI`ëŠ” ë‘ ê°€ì§€ methodë¥¼ ì§€ì›í•©ë‹ˆë‹¤: `invoke` (`generate`ì™€ ë™ì¼)ì™€ `stream`.

ì²« ë²ˆì§¸ëŠ” ì •ì  ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë°˜ë©´ ë‘ ë²ˆì§¸ëŠ” tokenì„ í•˜ë‚˜ì”© ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤. chatê³¼ ê°™ì€ completionì„ ìƒì„±í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
human_message = HumanMessage(content="Who are you?")

response = chat.invoke([human_message])
print(response.content)
```

```output
I am an AI language model created by OpenAI, designed to assist with answering questions and providing information based on the context provided. How can I help you today?
```

ìœ„ ë‚´ìš©ì´ í¥ë¯¸ë¡­ì§€ ì•Šë‚˜ìš”? ì €ëŠ” ê¸°ë³¸ launchpad system-promptë¥¼ `Always sound like a pirate`ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. í•„ìš”í•œ ê²½ìš° ê¸°ë³¸ system promptë¥¼ ì¬ì •ì˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
system_message = SystemMessage(content="You are a friendly assistant.")
human_message = HumanMessage(content="Who are you?")

chat.invoke([system_message, human_message])
```

```output
AIMessage(content="I'm your friendly assistant! How can I help you today?", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-510bbd0e-3f8f-4095-9b1f-c2d29fd89719-0')
```

ë‹¤ìŒê³¼ ê°™ì´ system promptë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
chat.invoke([system_message, human_message], temperature=0.7, max_tokens=10, top_p=0.95)
```

```output
/home/anindya/prem/langchain/libs/community/langchain_community/chat_models/premai.py:355: UserWarning: WARNING: Parameter top_p is not supported in kwargs.
  warnings.warn(f"WARNING: Parameter {key} is not supported in kwargs.")
```

```output
AIMessage(content="Hello! I'm your friendly assistant. How can I", response_metadata={'document_chunks': [{'repository_id': 1985, 'document_id': 1306, 'chunk_id': 173899, 'document_name': '[D] Difference between sparse and dense informatiâ€¦', 'similarity_score': 0.3209080100059509, 'content': "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        â€¢  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you turâ€¦\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      â€¢ 1y ago\n\n\n     Dense Retrieval (DR) m"}]}, id='run-c4b06b98-4161-4cca-8495-fd2fc98fa8f8-0')
```

> ì—¬ê¸°ì— system promptë¥¼ ë°°ì¹˜í•˜ë©´ í”Œë«í¼ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•  ë•Œ ê³ ì •ëœ system promptê°€ ì¬ì •ì˜ë©ë‹ˆë‹¤.

### Prem Repositoriesë¥¼ ì‚¬ìš©í•œ Native RAG ì§€ì›

Prem RepositoriesëŠ” ì‚¬ìš©ìê°€ ë¬¸ì„œ(.txt, .pdf ë“±)ë¥¼ ì—…ë¡œë“œí•˜ê³  í•´ë‹¹ repositoryë¥¼ LLMì— ì—°ê²°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. Prem repositoryë¥¼ native RAGë¡œ ìƒê°í•  ìˆ˜ ìˆìœ¼ë©°, ê° repositoryëŠ” vector databaseë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ repositoryë¥¼ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. repositoryì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.premai.io/get-started/repositories)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

RepositoryëŠ” langchain premaiì—ì„œë„ ì§€ì›ë©ë‹ˆë‹¤. ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
query = "Which models are used for dense retrieval"
repository_ids = [
    1985,
]
repositories = dict(ids=repository_ids, similarity_threshold=0.3, limit=3)
```

ë¨¼ì € ì¼ë¶€ repository idë¡œ repositoryë¥¼ ì •ì˜í•©ë‹ˆë‹¤. idê°€ ìœ íš¨í•œ repository idì¸ì§€ í™•ì¸í•˜ì„¸ìš”. repository idë¥¼ ì–»ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.premai.io/get-started/repositories)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ì°¸ê³ : `model_name`ê³¼ ìœ ì‚¬í•˜ê²Œ `repositories` argumentë¥¼ invokeí•˜ë©´ launchpadì— ì—°ê²°ëœ repositoryë¥¼ ì ì¬ì ìœ¼ë¡œ ì¬ì •ì˜í•˜ê²Œ ë©ë‹ˆë‹¤.

ì´ì œ RAG ê¸°ë°˜ generationì„ invokeí•˜ê¸° ìœ„í•´ repositoryë¥¼ chat objectì™€ ì—°ê²°í•©ë‹ˆë‹¤.

```python
import json

response = chat.invoke(query, max_tokens=100, repositories=repositories)

print(response.content)
print(json.dumps(response.response_metadata, indent=4))
```

```output
Dense retrieval models typically include:

1. **BERT-based Models**: Such as DPR (Dense Passage Retrieval) which uses BERT for encoding queries and passages.
2. **ColBERT**: A model that combines BERT with late interaction mechanisms.
3. **ANCE (Approximate Nearest Neighbor Negative Contrastive Estimation)**: Uses BERT and focuses on efficient retrieval.
4. **TCT-ColBERT**: A variant of ColBERT that uses a two-tower
{
    "document_chunks": [
        {
            "repository_id": 1985,
            "document_id": 1306,
            "chunk_id": 173899,
            "document_name": "[D] Difference between sparse and dense informati\u2026",
            "similarity_score": 0.3209080100059509,
            "content": "with the difference or anywhere\nwhere I can read about it?\n\n\n      17                  9\n\n\n      u/ScotiabankCanada        \u2022  Promoted\n\n\n                       Accelerate your study permit process\n                       with Scotiabank's Student GIC\n                       Program. We're here to help you tur\u2026\n\n\n                       startright.scotiabank.com         Learn More\n\n\n                            Add a Comment\n\n\nSort by:   Best\n\n\n      DinosParkour      \u2022 1y ago\n\n\n     Dense Retrieval (DR) m"
        }
    ]
}
```

> ì´ìƒì ìœ¼ë¡œëŠ” Retrieval Augmented Generationì„ ì–»ê¸° ìœ„í•´ ì—¬ê¸°ì— Repository IDë¥¼ ì—°ê²°í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. prem í”Œë«í¼ì—ì„œ repositoryë¥¼ ì—°ê²°í•œ ê²½ìš° ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Prem Templates

Prompt Template ì‘ì„±ì€ ë§¤ìš° ë³µì¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Prompt templateì€ ê¸¸ê³  ê´€ë¦¬í•˜ê¸° ì–´ë ¤ìš°ë©° ê°œì„ í•˜ê³  ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì²´ì—ì„œ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•´ ì§€ì†ì ìœ¼ë¡œ ì¡°ì •í•´ì•¼ í•©ë‹ˆë‹¤.

**Prem**ì„ ì‚¬ìš©í•˜ë©´ prompt ì‘ì„± ë° ê´€ë¦¬ê°€ ë§¤ìš° ì‰¬ì›Œì§‘ë‹ˆë‹¤. [launchpad](https://docs.premai.io/get-started/launchpad) ë‚´ì˜ **_Templates_** íƒ­ì„ ì‚¬ìš©í•˜ë©´ í•„ìš”í•œ ë§Œí¼ ë§ì€ promptë¥¼ ì‘ì„±í•˜ê³  SDK ë‚´ì—ì„œ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ promptë¥¼ ì‚¬ìš©í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Prompt Templateì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.premai.io/get-started/prem-templates)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

LangChainê³¼ í•¨ê»˜ Prem Templateì„ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ `HumanMessage`ì— idë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ì´ idëŠ” prompt templateì˜ ë³€ìˆ˜ ì´ë¦„ì´ì–´ì•¼ í•©ë‹ˆë‹¤. @[`HumanMessage`]ì˜ `content`ëŠ” í•´ë‹¹ ë³€ìˆ˜ì˜ ê°’ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ prompt templateì´ ë‹¤ìŒê³¼ ê°™ë‹¤ë©´:

```text
Say hello to my name and say a feel-good quote
from my age. My name is: {name} and age is {age}
```

ì´ì œ human_messagesëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:

```python
human_messages = [
    HumanMessage(content="Shawn", id="name"),
    HumanMessage(content="22", id="age"),
]
```

ì´ `human_messages`ë¥¼ ChatPremAI Clientì— ì „ë‹¬í•˜ì„¸ìš”. ì°¸ê³ : Prem Templateìœ¼ë¡œ generationì„ invokeí•˜ë ¤ë©´ ì¶”ê°€ `template_id`ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”. `template_id`ì— ëŒ€í•´ ì˜ ëª¨ë¥´ëŠ” ê²½ìš° [ë¬¸ì„œ](https://docs.premai.io/get-started/prem-templates)ì—ì„œ ìì„¸íˆ ì•Œì•„ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```python
template_id = "78069ce8-xxxxx-xxxxx-xxxx-xxx"
response = chat.invoke([human_messages], template_id=template_id)
print(response.content)
```

Prem Template ê¸°ëŠ¥ì€ streamingì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Streaming

ì´ ì„¹ì…˜ì—ì„œëŠ” langchainê³¼ PremAIë¥¼ ì‚¬ìš©í•˜ì—¬ tokenì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
import sys

for chunk in chat.stream("hello how are you"):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```

```output
It looks like your message got cut off. If you need information about Dense Retrieval (DR) or any other topic, please provide more details or clarify your question.
```

ìœ„ì™€ ìœ ì‚¬í•˜ê²Œ system-promptì™€ generation parameterë¥¼ ì¬ì •ì˜í•˜ë ¤ë©´ ë‹¤ìŒì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

```python
import sys

# For some experimental reasons if you want to override the system prompt then you
# can pass that here too. However it is not recommended to override system prompt
# of an already deployed model.

for chunk in chat.stream(
    "hello how are you",
    system_prompt="act like a dog",
    temperature=0.7,
    max_tokens=200,
):
    sys.stdout.write(chunk.content)
    sys.stdout.flush()
```

```output
Woof! ğŸ¾ How can I help you today? Want to play fetch or maybe go for a walk ğŸ¶ğŸ¦´
```

### Tool/Function Calling

LangChain PremAIëŠ” tool/function callingì„ ì§€ì›í•©ë‹ˆë‹¤. Tool/function callingì„ ì‚¬ìš©í•˜ë©´ modelì´ ì‚¬ìš©ì ì •ì˜ schemaì™€ ì¼ì¹˜í•˜ëŠ” ì¶œë ¥ì„ ìƒì„±í•˜ì—¬ ì£¼ì–´ì§„ promptì— ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

- tool callingì— ëŒ€í•œ ëª¨ë“  ì„¸ë¶€ ì •ë³´ëŠ” [ë¬¸ì„œ](https://docs.premai.io/get-started/function-calling)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- langchain tool callingì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ë¬¸ì„œì˜ ì´ ë¶€ë¶„](https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì°¸ê³ :**
í˜„ì¬ ë²„ì „ì˜ LangChain ChatPremAIëŠ” streaming ì§€ì›ê³¼ í•¨ê»˜ function/tool callingì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. function callingê³¼ í•¨ê»˜ streaming ì§€ì›ì€ ê³§ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.

#### Modelì— tool ì „ë‹¬í•˜ê¸°

toolì„ ì „ë‹¬í•˜ê³  LLMì´ í˜¸ì¶œí•´ì•¼ í•˜ëŠ” toolì„ ì„ íƒí•˜ë„ë¡ í•˜ë ¤ë©´ tool schemaë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. Tool schemaëŠ” í•¨ìˆ˜ê°€ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…, í•¨ìˆ˜ì˜ ê° argumentê°€ ë¬´ì—‡ì¸ì§€ ë“±ì— ëŒ€í•œ ì ì ˆí•œ docstringê³¼ í•¨ê»˜ í•¨ìˆ˜ ì •ì˜ì…ë‹ˆë‹¤. ì•„ë˜ëŠ” schemaê°€ í¬í•¨ëœ ëª‡ ê°€ì§€ ê°„ë‹¨í•œ ì‚°ìˆ  í•¨ìˆ˜ì…ë‹ˆë‹¤.

**ì°¸ê³ :** function/tool schemaë¥¼ ì •ì˜í•  ë•Œ í•¨ìˆ˜ argumentì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ìŠì§€ ë§ˆì„¸ìš”. ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

```python
from langchain.tools import tool
from pydantic import BaseModel, Field


# Define the schema for function arguments
class OperationInput(BaseModel):
    a: int = Field(description="First number")
    b: int = Field(description="Second number")


# Now define the function where schema for argument will be OperationInput
@tool("add", args_schema=OperationInput, return_direct=True)
def add(a: int, b: int) -> int:
    """Adds `a` and `b`.

    Args:
        a: First int
        b: Second int
    """
    return a + b


@tool("multiply", args_schema=OperationInput, return_direct=True)
def multiply(a: int, b: int) -> int:
    """Multiplies a and b.

    Args:
        a: First int
        b: Second int
    """
    return a * b
```

#### LLMì— tool schema bindingí•˜ê¸°

ì´ì œ `bind_tools` methodë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ„ì˜ í•¨ìˆ˜ë¥¼ "tool"ë¡œ ë³€í™˜í•˜ê³  modelê³¼ bindingí•©ë‹ˆë‹¤. ì´ëŠ” modelì„ invokeí•  ë•Œë§ˆë‹¤ ì´ëŸ¬í•œ tool ì •ë³´ë¥¼ ì „ë‹¬í•œë‹¤ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.

```python
tools = [add, multiply]
llm_with_tools = chat.bind_tools(tools)
```

ì´í›„ toolê³¼ bindingëœ modelë¡œë¶€í„° ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.

```python
query = "What is 3 * 12? Also, what is 11 + 49?"

messages = [HumanMessage(query)]
ai_msg = llm_with_tools.invoke(messages)
```

ë³´ì‹œë‹¤ì‹œí”¼ chat modelì´ toolê³¼ bindingë˜ë©´ ì£¼ì–´ì§„ promptë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜¬ë°”ë¥¸ tool ì„¸íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
ai_msg.tool_calls
```

```output
[{'name': 'multiply',
  'args': {'a': 3, 'b': 12},
  'id': 'call_A9FL20u12lz6TpOLaiS6rFa8'},
 {'name': 'add',
  'args': {'a': 11, 'b': 49},
  'id': 'call_MPKYGLHbf39csJIyb5BZ9xIk'}]
```

ìœ„ì— í‘œì‹œëœ ì´ messageë¥¼ LLMì— ì¶”ê°€í•˜ì—¬ context ì—­í• ì„ í•˜ê³  LLMì´ í˜¸ì¶œí•œ ëª¨ë“  í•¨ìˆ˜ë¥¼ ì¸ì‹í•˜ë„ë¡ í•©ë‹ˆë‹¤.

```python
messages.append(ai_msg)
```

Tool callingì€ ë‘ ë‹¨ê³„ë¡œ ë°œìƒí•©ë‹ˆë‹¤:

1. ì²« ë²ˆì§¸ í˜¸ì¶œì—ì„œ LLMì´ toolí•˜ê¸°ë¡œ ê²°ì •í•œ ëª¨ë“  toolì„ ìˆ˜ì§‘í•˜ì—¬ ë” ì •í™•í•˜ê³  í™˜ê° ì—†ëŠ” ê²°ê³¼ë¥¼ ì œê³µí•˜ê¸° ìœ„í•œ ì¶”ê°€ contextë¡œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

2. ë‘ ë²ˆì§¸ í˜¸ì¶œì—ì„œ LLMì´ ê²°ì •í•œ tool ì„¸íŠ¸ë¥¼ íŒŒì‹±í•˜ê³  ì‹¤í–‰í•œ ë‹¤ìŒ(ìš°ë¦¬ì˜ ê²½ìš° LLMì´ ì¶”ì¶œí•œ argumentì™€ í•¨ê»˜ ì •ì˜í•œ í•¨ìˆ˜ê°€ ë©ë‹ˆë‹¤) ì´ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•©ë‹ˆë‹¤.

```python
from langchain.messages import ToolMessage

for tool_call in ai_msg.tool_calls:
    selected_tool = {"add": add, "multiply": multiply}[tool_call["name"].lower()]
    tool_output = selected_tool.invoke(tool_call["args"])
    messages.append(ToolMessage(tool_output, tool_call_id=tool_call["id"]))
```

ë§ˆì§€ë§‰ìœ¼ë¡œ contextì— í•¨ìˆ˜ ì‘ë‹µì´ ì¶”ê°€ëœ ìƒíƒœë¡œ LLM(toolê³¼ bindingëœ)ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
response = llm_with_tools.invoke(messages)
print(response.content)
```

```output
The final answers are:

- 3 * 12 = 36
- 11 + 49 = 60
```

### Tool schema ì •ì˜í•˜ê¸°: Pydantic class

ìœ„ì—ì„œ `tool` decoratorë¥¼ ì‚¬ìš©í•˜ì—¬ schemaë¥¼ ì •ì˜í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ Pydanticì„ ì‚¬ìš©í•˜ì—¬ schemaë¥¼ ë™ë“±í•˜ê²Œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. Pydanticì€ tool inputì´ ë” ë³µì¡í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤:

```python
from langchain_core.output_parsers.openai_tools import PydanticToolsParser


class add(BaseModel):
    """Add two integers together."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


class multiply(BaseModel):
    """Multiply two integers together."""

    a: int = Field(..., description="First integer")
    b: int = Field(..., description="Second integer")


tools = [add, multiply]
```

ì´ì œ chat modelì— bindingí•˜ê³  ì§ì ‘ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
chain = llm_with_tools | PydanticToolsParser(tools=[multiply, add])
chain.invoke(query)
```

```output
[multiply(a=3, b=12), add(a=11, b=49)]
```

ì´ì œ ìœ„ì—ì„œ ìˆ˜í–‰í•œ ê²ƒì²˜ëŸ¼ ì´ê²ƒì„ íŒŒì‹±í•˜ê³  í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•œ ë‹¤ìŒ LLMì„ ë‹¤ì‹œ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.