---
title: ChatXAI
---


이 페이지는 xAI [chat models](/oss/langchain/models) 시작하기를 도와드립니다. 모든 `ChatXAI` 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/xai/chat_models/langchain_xai.chat_models.ChatXAI.html)를 참조하세요.

[xAI](https://console.x.ai/)는 Grok 모델과 상호작용할 수 있는 API를 제공합니다.

## Overview

### Integration details

| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/xai) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [ChatXAI](https://python.langchain.com/api_reference/xai/chat_models/langchain_xai.chat_models.ChatXAI.html) | [langchain-xai](https://python.langchain.com/api_reference/xai/index.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-xai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-xai?style=flat-square&label=%20) |

### Model features

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming#llm-tokens) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ❌ | ❌ | ❌ | ❌ | ✅ | ❌ | ✅ | ✅ |

## Setup

xAI 모델에 액세스하려면 xAI 계정을 생성하고 API 키를 받은 다음 `langchain-xai` integration package를 설치해야 합니다.

### Credentials

[이 페이지](https://console.x.ai/)로 이동하여 xAI에 가입하고 API 키를 생성하세요. 완료한 후 `XAI_API_KEY` environment variable을 설정하세요:

```python
import getpass
import os

if "XAI_API_KEY" not in os.environ:
    os.environ["XAI_API_KEY"] = getpass.getpass("Enter your xAI API key: ")
```

모델 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정하세요:

```python
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

LangChain xAI integration은 `langchain-xai` package에 있습니다:

```python
pip install -qU langchain-xai
```

## Instantiation

이제 모델 객체를 인스턴스화하고 chat completion을 생성할 수 있습니다:

```python
from langchain_xai import ChatXAI

llm = ChatXAI(
    model="grok-beta",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    # other params...
)
```

## Invocation

```python
messages = [
    (
        "system",
        "You are a helpful assistant that translates English to French. Translate the user sentence.",
    ),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```output
AIMessage(content="J'adore programmer.", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 30, 'total_tokens': 36, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'grok-beta', 'system_fingerprint': 'fp_14b89b2dfc', 'finish_reason': 'stop', 'logprobs': None}, id='run-adffb7a3-e48a-4f52-b694-340d85abe5c3-0', usage_metadata={'input_tokens': 30, 'output_tokens': 6, 'total_tokens': 36, 'input_token_details': {}, 'output_token_details': {}})
```

```python
print(ai_msg.content)
```

```output
J'adore programmer.
```

## Tool calling

ChatXAI는 도구와 그 인수를 설명하고 모델이 호출할 도구와 해당 도구에 대한 입력이 포함된 JSON 객체를 반환하도록 하는 [tool calling](https://docs.x.ai/docs#capabilities) (여기서는 "tool calling"과 "function calling"을 같은 의미로 사용합니다) API를 제공합니다. Tool-calling은 도구를 사용하는 chain과 agent를 구축하고 모델에서 구조화된 출력을 얻는 데 매우 유용합니다.

### ChatXAI.bind_tools()

`ChatXAI.bind_tools`를 사용하면 Pydantic class, dict schema, LangChain tool 또는 함수를 모델에 도구로 쉽게 전달할 수 있습니다. 내부적으로 이들은 다음과 같은 OpenAI tool schema로 변환됩니다:

```
{
    "name": "...",
    "description": "...",
    "parameters": {...}  # JSONSchema
}
```

그리고 모든 모델 호출에 전달됩니다.

```python
from pydantic import BaseModel, Field


class GetWeather(BaseModel):
    """Get the current weather in a given location"""

    location: str = Field(..., description="The city and state, e.g. San Francisco, CA")


llm_with_tools = llm.bind_tools([GetWeather])
```

```python
ai_msg = llm_with_tools.invoke(
    "what is the weather like in San Francisco",
)
ai_msg
```

```output
AIMessage(content='I am retrieving the current weather for San Francisco.', additional_kwargs={'tool_calls': [{'id': '0', 'function': {'arguments': '{"location":"San Francisco, CA"}', 'name': 'GetWeather'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 151, 'total_tokens': 162, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'grok-beta', 'system_fingerprint': 'fp_14b89b2dfc', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-73707da7-afec-4a52-bee1-a176b0ab8585-0', tool_calls=[{'name': 'GetWeather', 'args': {'location': 'San Francisco, CA'}, 'id': '0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 151, 'output_tokens': 11, 'total_tokens': 162, 'input_token_details': {}, 'output_token_details': {}})
```

## Live Search

xAI는 Grok이 웹 검색 결과를 사용하여 답변을 근거로 제시할 수 있도록 하는 [Live Search](https://docs.x.ai/docs/guides/live-search) 기능을 지원합니다:

```python
from langchain_xai import ChatXAI

llm = ChatXAI(
    model="grok-3-latest",
    search_parameters={
        "mode": "auto",
        # Example optional parameters below:
        "max_search_results": 3,
        "from_date": "2025-05-26",
        "to_date": "2025-05-27",
    },
)

llm.invoke("Provide me a digest of world news in the last 24 hours.")
```

전체 웹 검색 옵션은 [xAI docs](https://docs.x.ai/docs/guides/live-search)를 참조하세요.

## API reference

모든 `ChatXAI` 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/xai/chat_models/langchain_xai.chat_models.ChatXAI.html)를 참조하세요.