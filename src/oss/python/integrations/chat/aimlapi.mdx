---
title: ChatAimlapi
---

이 가이드는 AI/ML API [chat models](/oss/langchain/models) 시작하기를 도와줍니다. 모든 `ChatAimlapi` 기능과 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html)를 참조하세요.

[AI/ML API](https://aimlapi.com/app/?utm_source=langchain&utm_medium=github&utm_campaign=integration)는 높은 가용성과 처리량으로 수백 개의 호스팅된 foundation model에 대한 통합 액세스를 제공합니다.

## Overview

### Integration details

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| [ChatAimlapi](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html) | [langchain-aimlapi](https://python.langchain.com/api_reference/aimlapi/index.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-aimlapi?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-aimlapi?style=flat-square&label=%20) |

### Model features

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming/) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

## Setup

AI/ML API model에 액세스하려면 계정을 생성하고 API key를 받은 다음 `langchain-aimlapi` integration package를 설치해야 합니다.

### Credentials

[aimlapi.com](https://aimlapi.com/app/?utm_source=langchain&utm_medium=github&utm_campaign=integration)으로 이동하여 가입하고 API key를 생성하세요. 완료되면 `AIMLAPI_API_KEY` environment variable을 설정하세요:

```python
import getpass
import os

if not os.getenv("AIMLAPI_API_KEY"):
    os.environ["AIMLAPI_API_KEY"] = getpass.getpass("Enter your AI/ML API key: ")
```

model 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API key를 설정하세요:

```python
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

LangChain AI/ML API integration은 `langchain-aimlapi` package에 있습니다:

```python
pip install -qU langchain-aimlapi
```

## Instantiation

이제 model object를 인스턴스화하고 chat completion을 생성할 수 있습니다:

```python
from langchain_aimlapi import ChatAimlapi

llm = ChatAimlapi(
    model="meta-llama/Llama-3-70b-chat-hf",
    temperature=0.7,
    max_tokens=512,
    timeout=30,
    max_retries=3,
)
```

## Invocation

```python
messages = [
    ("system", "You are a helpful assistant that translates English to French."),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```output
AIMessage(content="J'adore la programmation.", response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 23, 'total_tokens': 32}, 'model_name': 'meta-llama/Llama-3-70b-chat-hf'}, id='run-...')
```

```python
print(ai_msg.content)
```

```output
J'adore la programmation.
```

## Streaming invocation

token 단위로 응답을 스트리밍할 수도 있습니다:

```python
for chunk in llm.stream("List top 5 programming languages in 2025 with reasons."):
    print(chunk.content, end="", flush=True)
```

## API reference

모든 ChatAimlapi 기능과 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/aimlapi/chat_models/langchain_aimlapi.chat_models.ChatAimlapi.html)를 참조하세요.