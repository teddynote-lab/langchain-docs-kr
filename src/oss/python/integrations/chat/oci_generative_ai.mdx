---
title: ChatOCIGenAI
---

이 가이드는 OCIGenAI [chat models](/oss/langchain/models) 시작하기에 대한 간단한 개요를 제공합니다. 모든 ChatOCIGenAI 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html)를 참조하세요.

Oracle Cloud Infrastructure (OCI) Generative AI는 다양한 사용 사례를 다루는 최첨단의 맞춤형 대규모 언어 모델(LLM) 세트를 제공하는 완전 관리형 서비스이며, 단일 API를 통해 사용할 수 있습니다.
OCI Generative AI 서비스를 사용하면 바로 사용 가능한 사전 학습된 모델에 액세스하거나, 전용 AI 클러스터에서 자체 데이터를 기반으로 미세 조정된 사용자 정의 모델을 생성하고 호스팅할 수 있습니다. 서비스 및 API에 대한 자세한 문서는 __[여기](https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm)__와 __[여기](https://docs.oracle.com/en-us/iaas/api/#/en/generative-ai/20231130/)__에서 확인할 수 있습니다.

## Overview

### Integration details

| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/oci_generative_ai) |
| :--- | :--- | :---: | :---: |  :---: |
| [ChatOCIGenAI](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | ❌ | ❌ | ❌ |

### Model features

| [Tool calling](/oss/langchain/tools/) | [Structured output](/oss/langchain/structured-output) | [JSON mode](/oss/langchain/structured-output#advanced-specifying-the-method-for-structuring-outputs) | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming/) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ❌ | ❌ | ✅ | ❌ | ❌ | ❌ |

## Setup

OCIGenAI 모델에 액세스하려면 `oci` 및 `langchain-community` 패키지를 설치해야 합니다.

### Credentials

이 통합에서 지원되는 자격 증명 및 인증 방법은 다른 OCI 서비스에서 사용되는 방법과 동일하며, __[표준 SDK 인증](https://docs.oracle.com/en-us/iaas/Content/API/Concepts/sdk_authentication_methods.htm)__ 방법, 특히 API Key, session token, instance principal, resource principal을 따릅니다.

API key는 위 예제에서 사용된 기본 인증 방법입니다. 다음 예제는 다른 인증 방법(session token)을 사용하는 방법을 보여줍니다.

### Installation

LangChain OCIGenAI 통합은 `langchain-community` 패키지에 포함되어 있으며 `oci` 패키지도 설치해야 합니다:

```python
pip install -qU langchain-community oci
```

## Instantiation

이제 model 객체를 인스턴스화하고 chat completion을 생성할 수 있습니다:

```python
from langchain_community.chat_models.oci_generative_ai import ChatOCIGenAI
from langchain.messages import AIMessage, HumanMessage, SystemMessage

chat = ChatOCIGenAI(
    model_id="cohere.command-r-16k",
    service_endpoint="https://inference.generativeai.us-chicago-1.oci.oraclecloud.com",
    compartment_id="MY_OCID",
    model_kwargs={"temperature": 0.7, "max_tokens": 500},
)
```

## Invocation

```python
messages = [
    SystemMessage(content="your are an AI assistant."),
    AIMessage(content="Hi there human!"),
    HumanMessage(content="tell me a joke."),
]
response = chat.invoke(messages)
```

```python
print(response.content)
```

## API reference

모든 ChatOCIGenAI 기능 및 구성에 대한 자세한 문서는 API reference를 참조하세요: [python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.oci_generative_ai.ChatOCIGenAI.html)