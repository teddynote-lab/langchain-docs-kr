---
title: Chat(MODULE_NAME)
---

이 Python chat model 템플릿 사용 방법:

- [ ] (MODULE_NAME)을 모듈 이름으로 대체하세요. 예: Anthropic, OpenAI 등 (`command + F`를 활용하세요)
- [ ] 링크를 올바른 모듈을 가리키도록 업데이트하세요
- [ ] details 및 features 테이블 아래에서 ✅/❌를 chat model의 실제 기능을 반영하도록 업데이트하세요
- [ ] 필요한 경우 PyPi/registry 패키지 이름을 업데이트하세요
- [ ] 필요한 경우 API key 환경 변수 이름을 업데이트하세요

템플릿은 이 줄 아래부터 시작됩니다...

이 가이드는 (MODULE_NAME) [chat model](/oss/langchain/models) 시작하기에 대한 빠른 개요를 제공합니다. 모든 Chat(MODULE_NAME) 기능, 매개변수 및 구성에 대한 자세한 목록은 [Chat(MODULE_NAME) API reference](https://python.langchain.com/api_reference/(MODULE_NAME)/chat_models/langchain_(MODULE_NAME).chat_models.Chat(MODULE_NAME).html)를 참조하세요.

## Overview

### Details

| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/docs/integrations/chat/anthropic) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [Chat(MODULE_NAME)](https://python.langchain.com/api_reference/(MODULE_NAME)/chat_models/langchain_(MODULE_NAME).chat_models.Chat(MODULE_NAME).html) | [langchain-(MODULE_NAME)](https://python.langchain.com/api_reference/anthropic/index.html) | ✅/❌ | beta/❌ | ✅/❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-(MODULE_NAME)?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-(MODULE_NAME)?style=flat-square&label=%20) |

### Features

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output/) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | [Audio input](/oss/langchain/messages#multimodal) | [Video input](/oss/langchain/messages#multimodal) | [Token-level streaming](/oss/langchain/streaming/) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅/❌ | ✅❌ |

---

## Setup

(MODULE_NAME) model에 액세스하려면 (MODULE_NAME) 계정을 생성하고 API key를 받은 다음 `langchain-(MODULE_NAME)` integration package를 설치해야 합니다.

### Credentials

```python Set API key icon="key"
import getpass
import os

if "(MODULE_NAME)_API_KEY" not in os.environ:
    os.environ["(MODULE_NAME)_API_KEY"] = getpass.getpass("Enter your (MODULE_NAME) API key: ")
```

모델 호출의 자동화된 <Tooltip tip="모델 실행의 각 단계를 로깅하여 디버그하고 개선합니다">tracing</Tooltip>을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API key를 설정하세요:

```python Enable tracing icon="flask"
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

LangChain (MODULE_NAME) integration은 `langchain-(MODULE_NAME)` package에 있습니다:

<CodeGroup>
    ```python pip
    pip install -U langchain-(MODULE_NAME)
    ```
    ```python uv
    uv add langchain-(MODULE_NAME)
    ```
</CodeGroup>

---

## Instantiation

이제 model object를 인스턴스화하고 응답을 생성할 수 있습니다:

```python Initialize chat model icon="robot"
from langchain_(MODULE_NAME) import Chat(MODULE_NAME)

model = Chat(MODULE_NAME)(
    model="model-name",
    temperature=0,
    timeout=None,
    max_tokens=1024,
    max_retries=2,
    # Other params - see API reference for full list
)
```

---

## Invocation

<CodeGroup>
    ```python Dictionary format icon="book"
    messages = [
        {"role": "system", "content": "You are a poetry expert"},
        {"role": "user", "content": "Write a haiku about spring"},
    ]
    response = model.invoke(messages)
    print(response)
    ```
    ```python Message objects icon="message"
    from langchain.messages import SystemMessage, HumanMessage, AIMessage

    messages = [
        SystemMessage("You are a poetry expert"),
        HumanMessage("Write a haiku about spring"),
        AIMessage("Cherry blossoms bloom...")
    ]
    response = model.invoke(messages)
    ```
</CodeGroup>

```text Response object icon="terminal"
TODO - replace with response.model_dump_json(indent=2) or similar
```

```python Text content icon="i-cursor"
print(response.text)

# TODO - replace with the output of response.text
```

```python Content Blocks icon="shapes"
print(response.content_blocks)

# TODO - replace with the output of response.content_blocks
```

<Tip>
    [chat model invocation types](/oss/langchain/models#invocation), [message types](/oss/langchain/messages#message-types), [content blocks](/oss/langchain/messages#standard-content-blocks)에 대한 전체 가이드를 확인할 수 있습니다.
</Tip>

## TODO: 이 모델에 특정한 기능

관련이 없으면 삭제하세요.

예시는 기존 model 문서를 참조하세요:

- [ChatAnthropic](/oss/integrations/chat/anthropic)
- [ChatOpenAI](/oss/integrations/chat/openai)
- [ChatGenAI](/oss/integrations/chat/google_generative_ai)

예시:
- <Icon icon="wrench" size={16}/> Tool calling
- <Icon icon="brain" size={16}/> Reasoning output / extended reasoning
- <Icon icon="bullhorn" size={16}/> Verbosity
- <Icon icon="quote-right" size={16}/> Citations
- <Icon icon="terminal" size={16}/> Built-in tools
    - <Icon icon="clipboard-question" size={16}/> Web search
    - <Icon icon="code" size={16}/> Code execution
    - <Icon icon="rss" size={16}/> Remote MCP
- <Icon icon="photo-film" size={16}/> Multimodal input / output
- <Icon icon="database" size={16}/> Caching
- <Icon icon="link" size={16}/> Chaining
- <Icon icon="wifi" size={16}/> Streaming usage metadata
- <Icon icon="vial" size={16}/> Fine-tuning
- <Icon icon="microchip" size={16}/> Flex processing
- <Icon icon="timeline" size={16}/> Custom base URL or proxy behavior

---

## API reference

모든 Chat(MODULE_NAME) 기능 및 구성에 대한 자세한 문서는 [API reference](<LINK>)를 참조하세요.