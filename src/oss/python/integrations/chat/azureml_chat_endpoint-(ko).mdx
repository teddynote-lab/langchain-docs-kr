---
title: AzureMLChatOnlineEndpoint
---

>[Azure Machine Learning](https://azure.microsoft.com/en-us/products/machine-learning/)은 머신러닝 모델을 구축, 학습 및 배포하는 데 사용되는 플랫폼입니다. 사용자는 Model Catalog에서 다양한 제공업체의 기본 및 범용 모델을 제공하는 배포할 모델 유형을 탐색할 수 있습니다.
>
>일반적으로 예측(추론)을 사용하려면 모델을 배포해야 합니다. `Azure Machine Learning`에서 [Online Endpoints](https://learn.microsoft.com/en-us/azure/machine-learning/concept-endpoints)는 실시간 서빙으로 이러한 모델을 배포하는 데 사용됩니다. 이들은 `Endpoints`와 `Deployments`의 개념을 기반으로 하며, 프로덕션 워크로드의 인터페이스를 이를 제공하는 구현으로부터 분리할 수 있게 해줍니다.

이 노트북은 `Azure Machine Learning Endpoint`에 호스팅된 chat model을 사용하는 방법을 다룹니다.

```python
from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint
```

## 설정

[Azure ML에 모델을 배포](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-use-foundation-models?view=azureml-api-2#deploying-foundation-models-to-endpoints-for-inferencing)하거나 [Azure AI Foundry(이전 Azure AI Studio)에 배포](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-open)하고 다음 매개변수를 얻어야 합니다:

* `endpoint_url`: endpoint에서 제공하는 REST endpoint url입니다.
* `endpoint_api_type`: **Dedicated endpoints**(호스팅 관리 인프라)에 모델을 배포할 때는 `endpoint_type='dedicated'`를 사용합니다. **Pay-as-you-go** 제공 방식(model as a service)을 사용하여 모델을 배포할 때는 `endpoint_type='serverless'`를 사용합니다.
* `endpoint_api_key`: endpoint에서 제공하는 API key입니다.

## Content Formatter

`content_formatter` 매개변수는 AzureML endpoint의 요청과 응답을 필요한 스키마와 일치하도록 변환하는 핸들러 클래스입니다. model catalog에는 다양한 모델이 있으며, 각 모델은 서로 다르게 데이터를 처리할 수 있으므로, 사용자가 원하는 대로 데이터를 변환할 수 있도록 `ContentFormatterBase` 클래스가 제공됩니다. 다음 content formatter들이 제공됩니다:

* `CustomOpenAIChatContentFormatter`: 요청 및 응답에 대해 OpenAI API 사양을 따르는 LLaMa2-chat과 같은 모델의 요청 및 응답 데이터를 포맷합니다.

*참고: `langchain.chat_models.azureml_endpoint.LlamaChatContentFormatter`는 더 이상 사용되지 않으며 `langchain.chat_models.azureml_endpoint.CustomOpenAIChatContentFormatter`로 대체됩니다.*

`langchain_community.llms.azureml_endpoint.ContentFormatterBase` 클래스에서 파생하여 모델에 특화된 사용자 정의 content formatter를 구현할 수 있습니다.

## 예제

다음 섹션에는 이 클래스를 사용하는 방법에 대한 예제가 포함되어 있습니다:

### 예제: 실시간 endpoint를 사용한 Chat completions

```python
from langchain_community.chat_models.azureml_endpoint import (
    AzureMLEndpointApiType,
    CustomOpenAIChatContentFormatter,
)
from langchain.messages import HumanMessage

chat = AzureMLChatOnlineEndpoint(
    endpoint_url="https://<your-endpoint>.<your_region>.inference.ml.azure.com/score",
    endpoint_api_type=AzureMLEndpointApiType.dedicated,
    endpoint_api_key="my-api-key",
    content_formatter=CustomOpenAIChatContentFormatter(),
)
response = chat.invoke(
    [HumanMessage(content="Will the Collatz conjecture ever be solved?")]
)
response
```

```output
AIMessage(content='  The Collatz Conjecture is one of the most famous unsolved problems in mathematics, and it has been the subject of much study and research for many years. While it is impossible to predict with certainty whether the conjecture will ever be solved, there are several reasons why it is considered a challenging and important problem:\n\n1. Simple yet elusive: The Collatz Conjecture is a deceptively simple statement that has proven to be extraordinarily difficult to prove or disprove. Despite its simplicity, the conjecture has eluded some of the brightest minds in mathematics, and it remains one of the most famous open problems in the field.\n2. Wide-ranging implications: The Collatz Conjecture has far-reaching implications for many areas of mathematics, including number theory, algebra, and analysis. A solution to the conjecture could have significant impacts on these fields and potentially lead to new insights and discoveries.\n3. Computational evidence: While the conjecture remains unproven, extensive computational evidence supports its validity. In fact, no counterexample to the conjecture has been found for any starting value up to 2^64 (a number', additional_kwargs={}, example=False)
```

### 예제: pay-as-you-go 배포(model as a service)를 사용한 Chat completions

```python
chat = AzureMLChatOnlineEndpoint(
    endpoint_url="https://<your-endpoint>.<your_region>.inference.ml.azure.com/v1/chat/completions",
    endpoint_api_type=AzureMLEndpointApiType.serverless,
    endpoint_api_key="my-api-key",
    content_formatter=CustomOpenAIChatContentFormatter,
)
response = chat.invoke(
    [HumanMessage(content="Will the Collatz conjecture ever be solved?")]
)
response
```

모델에 추가 매개변수를 전달해야 하는 경우 `model_kwargs` 인수를 사용하세요:

```python
chat = AzureMLChatOnlineEndpoint(
    endpoint_url="https://<your-endpoint>.<your_region>.inference.ml.azure.com/v1/chat/completions",
    endpoint_api_type=AzureMLEndpointApiType.serverless,
    endpoint_api_key="my-api-key",
    content_formatter=CustomOpenAIChatContentFormatter,
    model_kwargs={"temperature": 0.8},
)
```

매개변수는 호출 중에도 전달할 수 있습니다:

```python
response = chat.invoke(
    [HumanMessage(content="Will the Collatz conjecture ever be solved?")],
    max_tokens=512,
)
response
```