---
keywords: [moorcheh, vectorstore, semantic-search, embeddings]
---

# Moorcheh

>[Moorcheh](https://www.moorcheh.ai/)는 초고속 semantic search engine이자 vector store입니다. L2나 Cosine과 같은 단순한 거리 메트릭을 사용하는 대신, Moorcheh는 Maximally Informative Binarization (MIB)과 Information-Theoretic Score (ITS)를 사용하여 정확한 문서 청크를 검색합니다.

이 페이지에서는 vector storage, semantic search, 그리고 generative AI 응답을 위해 LangChain 내에서 Moorcheh를 사용하는 방법을 다룹니다.

## Installation and Setup

Python integration package를 설치합니다:

```bash
pip install langchain-moorcheh
```

[Moorcheh Console](https://console.moorcheh.ai/)에서 Moorcheh API key를 받아 환경 변수로 설정합니다:

```bash
export MOORCHEH_API_KEY="your-api-key-here"
```

## Vector Store

Moorcheh는 문서 embedding을 효율적으로 저장, 검색 및 조회할 수 있는 vector store wrapper를 제공합니다.

[자세한 사용 예제](/oss/integrations/vectorstores/moorcheh)를 참조하세요.

```python
from langchain_moorcheh import MoorchehVectorStore

# Initialize the vector store
store = MoorchehVectorStore(
    api_key="your-api-key",
    namespace="your_namespace",
    namespace_type="text"  # or "vector"
)

# Add documents
from langchain_core.documents import Document
documents = [
    Document(page_content="Your document content here", metadata={"source": "example"})
]
store.add_documents(documents=documents)
```

## Generative AI

Moorcheh는 Claude 3를 포함한 다양한 LLM 모델을 사용하여 generative AI 응답을 지원하며, 저장된 문서를 기반으로 AI가 생성한 답변을 얻을 수 있습니다.

```python
# Get an AI-generated answer based on your documents
query = "What are the main topics covered in the documents?"
answer = store.generative_answer(
    query,
    ai_model="anthropic.claude-3-7-sonnet-20250219-v1:0"
)
print(answer)
```

## Core Features

- **Document Management**: 고유 ID로 문서를 추가하고 삭제합니다
- **Semantic Search**: 자연어 쿼리를 사용하여 관련 문서를 찾습니다
- **Generative AI**: 다양한 LLM 모델을 사용하여 AI가 생성한 답변을 얻습니다
- **Namespace Organization**: 데이터를 별도의 namespace로 구성합니다
- **Metadata Support**: 사용자 정의 metadata와 함께 문서를 저장하고 조회합니다

더 자세한 예제와 고급 사용법은 [Moorcheh vectorstore integration](/oss/integrations/vectorstores/moorcheh)을 참조하세요.