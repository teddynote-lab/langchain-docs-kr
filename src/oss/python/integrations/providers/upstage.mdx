---
title: Upstage
---

>[Upstage](https://upstage.ai)는 인간 수준 이상의 성능을 제공하는 LLM 컴포넌트를 전문으로 하는 선도적인 인공지능(AI) 기업입니다.
>
>**Solar Pro**는 단일 GPU 배포에 최적화된 엔터프라이즈급 LLM으로, instruction-following과 HTML 및 Markdown과 같은 구조화된 형식 처리에 뛰어납니다. 영어, 한국어, 일본어를 지원하며 최고 수준의 다국어 성능을 제공하고, 금융, 의료, 법률 분야의 전문성을 제공합니다.

>Solar 외에도 Upstage는 **Document Parse** 및 **Groundedness Check**와 같은 실제 RAG(retrieval-augmented generation)를 위한 기능을 제공합니다.

### Upstage LangChain integrations

| API | Description | Import | Example usage |
| --- | --- | --- | --- |
| Chat | Solar Chat을 사용하여 assistant 구축 | `from langchain_upstage import ChatUpstage` | [바로가기](/oss/integrations/chat/upstage) |
| Text Embedding | 문자열을 벡터로 임베딩 | `from langchain_upstage import UpstageEmbeddings` | [바로가기](/oss/integrations/text_embedding/upstage) |
| Groundedness Check | assistant 응답의 근거성 검증 | `from langchain_upstage import UpstageGroundednessCheck` | [바로가기](/oss/integrations/tools/upstage_groundedness_check) |
| Document Parse | 표와 그림이 포함된 문서 직렬화 | `from langchain_upstage import UpstageDocumentParseLoader` | [바로가기](/oss/integrations/document_loaders/upstage) |

모델 및 기능에 대한 자세한 내용은 [문서](https://console.upstage.ai/docs/getting-started/overview)를 참조하세요.

## Installation and Setup

`langchain-upstage` 패키지 설치:

```bash
pip install -qU langchain-core langchain-upstage
```

[API Keys](https://console.upstage.ai)를 받고 환경 변수 `UPSTAGE_API_KEY`를 설정하세요.

```python
import os

os.environ["UPSTAGE_API_KEY"] = "YOUR_API_KEY"
```

## Chat models

### Solar LLM

[사용 예제](/oss/integrations/chat/upstage)를 참조하세요.

```python
from langchain_upstage import ChatUpstage

chat = ChatUpstage()
response = chat.invoke("Hello, how are you?")
print(response)
```

## Embedding models

[사용 예제](/oss/integrations/text_embedding/upstage)를 참조하세요.

```python
from langchain_upstage import UpstageEmbeddings

embeddings = UpstageEmbeddings(model="solar-embedding-1-large")
doc_result = embeddings.embed_documents(
    ["Sung is a professor.", "This is another document"]
)
print(doc_result)

query_result = embeddings.embed_query("What does Sung do?")
print(query_result)
```

## Document loader

### Document Parse

[사용 예제](/oss/integrations/document_loaders/upstage)를 참조하세요.

```python
from langchain_upstage import UpstageDocumentParseLoader

file_path = "/PATH/TO/YOUR/FILE.pdf"
layzer = UpstageDocumentParseLoader(file_path, split="page")

# For improved memory efficiency, consider using the lazy_load method to load documents page by page.
docs = layzer.load()  # or layzer.lazy_load()

for doc in docs[:3]:
    print(doc)
```

## Tools

### Groundedness Check

[사용 예제](/oss/integrations/tools/upstage_groundedness_check)를 참조하세요.

```python
from langchain_upstage import UpstageGroundednessCheck

groundedness_check = UpstageGroundednessCheck()

request_input = {
    "context": "Mauna Kea is an inactive volcano on the island of Hawaii. Its peak is 4,207.3 m above sea level, making it the highest point in Hawaii and second-highest peak of an island on Earth.",
    "answer": "Mauna Kea is 5,207.3 meters tall.",
}
response = groundedness_check.invoke(request_input)
print(response)
```