---
title: Spark
---

>[Apache Spark](https://spark.apache.org/)는 대규모 데이터 처리를 위한 통합 분석 엔진입니다.
> Scala, Java, Python, R로 작성된 고수준 API와 데이터 분석을 위한 일반 계산 그래프를 지원하는
> 최적화된 엔진을 제공합니다. 또한 SQL 및 DataFrame을 위한 `Spark SQL`, pandas 워크로드를 위한
> `pandas API on Spark`, 머신러닝을 위한 `MLlib`, 그래프 처리를 위한 `GraphX`,
> 스트림 처리를 위한 `Structured Streaming`을 포함한 풍부한 고수준 도구를 지원합니다.

## Document loaders

### PySpark

`PySpark` DataFrame에서 데이터를 로드합니다.

[사용 예제](/oss/integrations/document_loaders/pyspark_dataframe)를 참조하세요.

```python
from langchain_community.document_loaders import PySparkDataFrameLoader
```

## Tools/Toolkits

### Spark SQL toolkit

`Spark SQL`과 상호작용하기 위한 Toolkit입니다.

[사용 예제](/oss/integrations/tools/spark_sql)를 참조하세요.

```python
from langchain_community.agent_toolkits import SparkSQLToolkit, create_spark_sql_agent
from langchain_community.utilities.spark_sql import SparkSQL
```

#### Spark SQL individual tools

Spark SQL Toolkit에서 개별 tool을 사용할 수 있습니다:
- `InfoSparkSQLTool`: Spark SQL에 대한 메타데이터를 가져오는 tool
- `ListSparkSQLTool`: 테이블 이름을 가져오는 tool
- `QueryCheckerTool`: LLM을 사용하여 쿼리가 올바른지 확인하는 tool
- `QuerySparkSQLTool`: Spark SQL을 쿼리하는 tool

```python
from langchain_community.tools.spark_sql.tool import InfoSparkSQLTool
from langchain_community.tools.spark_sql.tool import ListSparkSQLTool
from langchain_community.tools.spark_sql.tool import QueryCheckerTool
from langchain_community.tools.spark_sql.tool import QuerySparkSQLTool
```