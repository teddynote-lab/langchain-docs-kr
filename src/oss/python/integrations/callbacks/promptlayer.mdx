---
title: PromptLayer
---

>[PromptLayer](https://docs.promptlayer.com/introduction)는 prompt engineering을 위한 플랫폼입니다. 또한 요청을 시각화하고, prompt 버전을 관리하며, 사용량을 추적하는 LLM observability 기능을 제공합니다.
>
>`PromptLayer`는 LangChain과 직접 통합되는 LLM을 제공하지만(예: [`PromptLayerOpenAI`](/oss/integrations/llms/promptlayer_openai)), callback을 사용하는 것이 `PromptLayer`를 LangChain과 통합하는 권장 방법입니다.

이 가이드에서는 `PromptLayerCallbackHandler`를 설정하는 방법을 다룹니다.

자세한 내용은 [PromptLayer 문서](https://docs.promptlayer.com/languages/langchain)를 참조하세요.

## Installation and Setup

```python
pip install -qU  langchain-community promptlayer --upgrade
```

### Getting API Credentials

PromptLayer 계정이 없다면 [promptlayer.com](https://www.promptlayer.com)에서 계정을 생성하세요. 그런 다음 navbar의 설정 톱니바퀴를 클릭하여 API key를 받고
`PROMPTLAYER_API_KEY`라는 환경 변수로 설정하세요.

## Usage

`PromptLayerCallbackHandler` 시작하기는 매우 간단합니다. 두 개의 선택적 인자를 받습니다:

1. `pl_tags` - PromptLayer에서 tag로 추적될 문자열 목록(선택 사항).
2. `pl_id_callback` - `promptlayer_request_id`를 인자로 받는 함수(선택 사항). 이 ID는 PromptLayer의 모든 추적 기능과 함께 사용하여 metadata, score, prompt 사용량을 추적할 수 있습니다.

## Simple OpenAI Example

이 간단한 예제에서는 @[`ChatOpenAI`]와 함께 `PromptLayerCallbackHandler`를 사용합니다. `chatopenai`라는 PromptLayer tag를 추가합니다.

```python
import promptlayer  # Don't forget this 🍰
from langchain_community.callbacks.promptlayer_callback import (
    PromptLayerCallbackHandler,
)
```

```python
from langchain.messages import HumanMessage
from langchain_openai import ChatOpenAI

chat_llm = ChatOpenAI(
    temperature=0,
    callbacks=[PromptLayerCallbackHandler(pl_tags=["chatopenai"])],
)
llm_results = chat_llm.invoke(
    [
        HumanMessage(content="What comes after 1,2,3 ?"),
        HumanMessage(content="Tell me another joke?"),
    ]
)
print(llm_results)
```

## GPT4All Example

```python
from langchain_community.llms import GPT4All

model = GPT4All(model="./models/gpt4all-model.bin", n_ctx=512, n_threads=8)
callbacks = [PromptLayerCallbackHandler(pl_tags=["langchain", "gpt4all"])]

response = model.invoke(
    "Once upon a time, ",
    config={"callbacks": callbacks},
)
```

## Full Featured Example

이 예제에서는 `PromptLayer`의 더 많은 기능을 활용합니다.

PromptLayer를 사용하면 prompt template을 시각적으로 생성하고, 버전을 관리하며, 추적할 수 있습니다. [Prompt Registry](https://docs.promptlayer.com/features/prompt-registry)를 사용하여 `example`이라는 prompt template을 프로그래밍 방식으로 가져올 수 있습니다.

또한 `promptlayer_request_id`를 받아 score, metadata를 기록하고 사용된 prompt template을 연결하는 `pl_id_callback` 함수를 정의합니다. 추적에 대한 자세한 내용은 [문서](https://docs.promptlayer.com/features/prompt-history/request-id)를 참조하세요.

```python
from langchain_openai import OpenAI


def pl_id_callback(promptlayer_request_id):
    print("prompt layer id ", promptlayer_request_id)
    promptlayer.track.score(
        request_id=promptlayer_request_id, score=100
    )  # score is an integer 0-100
    promptlayer.track.metadata(
        request_id=promptlayer_request_id, metadata={"foo": "bar"}
    )  # metadata is a dictionary of key value pairs that is tracked on PromptLayer
    promptlayer.track.prompt(
        request_id=promptlayer_request_id,
        prompt_name="example",
        prompt_input_variables={"product": "toasters"},
        version=1,
    )  # link the request to a prompt template


openai_llm = OpenAI(
    model_name="gpt-3.5-turbo-instruct",
    callbacks=[PromptLayerCallbackHandler(pl_id_callback=pl_id_callback)],
)

example_prompt = promptlayer.prompts.get("example", version=1, langchain=True)
openai_llm.invoke(example_prompt.format(product="toasters"))
```

이것이 전부입니다! 설정 후 모든 요청이 PromptLayer 대시보드에 표시됩니다.
이 callback은 LangChain에 구현된 모든 LLM과 함께 작동합니다.