---
title: Pinecone Hybrid Search
---

>[Pinecone](https://docs.pinecone.io/docs/overview)은 광범위한 기능을 제공하는 vector database입니다.

이 notebook은 내부적으로 Pinecone과 Hybrid Search를 사용하는 retriever를 사용하는 방법을 다룹니다.

이 retriever의 로직은 [이 문서](https://docs.pinecone.io/docs/hybrid-search)에서 가져왔습니다.

Pinecone을 사용하려면 API key와 Environment가 필요합니다.
[설치 지침](https://docs.pinecone.io/docs/quickstart)은 여기에서 확인하세요.

```python
pip install -qU  pinecone pinecone-text pinecone-notebooks
```

```python
# Connect to Pinecone and get an API key.
from pinecone_notebooks.colab import Authenticate

Authenticate()

import os

api_key = os.environ["PINECONE_API_KEY"]
```

```python
from langchain_community.retrievers import (
    PineconeHybridSearchRetriever,
)
```

`OpenAIEmbeddings`를 사용하려면 OpenAI API Key를 가져와야 합니다.

```python
import getpass

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")
```

## Pinecone 설정

이 부분은 한 번만 수행하면 됩니다.

```python
import os

from pinecone import Pinecone, ServerlessSpec

index_name = "langchain-pinecone-hybrid-search"

# initialize Pinecone client
pc = Pinecone(api_key=api_key)

# create the index
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=1536,  # dimensionality of dense model
        metric="dotproduct",  # sparse values supported only for dotproduct
        spec=ServerlessSpec(cloud="aws", region="us-east-1"),
    )
```

```output
WhoAmIResponse(username='load', user_label='label', projectname='load-test')
```

이제 index가 생성되었으므로 사용할 수 있습니다.

```python
index = pc.Index(index_name)
```

## Embeddings와 sparse encoders 가져오기

Embeddings는 dense vectors에 사용되고, tokenizer는 sparse vector에 사용됩니다.

```python
from langchain_openai import OpenAIEmbeddings

embeddings = OpenAIEmbeddings()
```

텍스트를 sparse 값으로 인코딩하려면 SPLADE 또는 BM25 중 하나를 선택할 수 있습니다. 도메인 외 작업의 경우 BM25를 사용하는 것이 좋습니다.

sparse encoders에 대한 자세한 내용은 pinecone-text library [문서](https://pinecone-io.github.io/pinecone-text/pinecone_text.html)를 확인하세요.

```python
from pinecone_text.sparse import BM25Encoder

# or from pinecone_text.sparse import SpladeEncoder if you wish to work with SPLADE

# use default tf-idf values
bm25_encoder = BM25Encoder().default()
```

위 코드는 기본 tfids 값을 사용합니다. tf-idf 값을 자신의 corpus에 맞추는 것을 강력히 권장합니다. 다음과 같이 수행할 수 있습니다:

```python
corpus = ["foo", "bar", "world", "hello"]

# fit tf-idf values on your corpus
bm25_encoder.fit(corpus)

# store the values to a json file
bm25_encoder.dump("bm25_values.json")

# load to your BM25Encoder object
bm25_encoder = BM25Encoder().load("bm25_values.json")
```

## Retriever 로드

이제 retriever를 구성할 수 있습니다!

```python
retriever = PineconeHybridSearchRetriever(
    embeddings=embeddings, sparse_encoder=bm25_encoder, index=index
)
```

## 텍스트 추가 (필요한 경우)

필요한 경우 retriever에 텍스트를 추가할 수 있습니다 (아직 없는 경우).

```python
retriever.add_texts(["foo", "bar", "world", "hello"])
```

```output
100%|██████████| 1/1 [00:02<00:00,  2.27s/it]
```

## Retriever 사용

이제 retriever를 사용할 수 있습니다!

```python
result = retriever.invoke("foo")
```

```python
result[0]
```

```output
Document(page_content='foo', metadata={})
```