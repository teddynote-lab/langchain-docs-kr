---
title: Contextual AI Reranker
---

Contextual AI의 Instruction-Following Reranker는 최신성, 출처, 메타데이터와 같은 특정 기준에 따라 문서의 우선순위를 지정하는 방법에 대한 맞춤 지침을 따르도록 설계된 세계 최초의 reranker입니다. BEIR 벤치마크에서 우수한 성능(61.2점을 기록하며 경쟁사를 큰 폭으로 앞섬)을 보이며, 엔터프라이즈 RAG 애플리케이션에 전례 없는 제어력과 정확도를 제공합니다.

## 주요 기능

- **Instruction Following**: 자연어 명령을 통해 문서 순위를 동적으로 제어
- **Conflict Resolution**: 여러 지식 소스의 모순된 정보를 지능적으로 처리
- **Superior Accuracy**: 업계 벤치마크에서 최첨단 성능 달성
- **Seamless Integration**: RAG 파이프라인의 기존 reranker를 즉시 대체 가능

이 reranker는 오래된 문서보다 최신 문서를 우선시하거나 외부 소스보다 내부 문서를 선호하는 등 엔터프라이즈 지식 베이스의 실제 과제를 해결하는 데 탁월합니다.

instruction-following reranker에 대해 자세히 알아보고 실제 사례를 보려면 [제품 개요](https://contextual.ai/blog/introducing-instruction-following-reranker/)를 방문하세요.

Contextual AI 제품에 대한 포괄적인 문서는 [개발자 포털](https://docs.contextual.ai/)을 방문하세요.

이 통합에는 `contextual-client` Python SDK가 필요합니다. 자세한 내용은 [여기](https://github.com/ContextualAI/contextual-client-python)에서 확인하세요.

## 개요

이 통합은 Contextual AI의 Grounded Language Model을 호출합니다.

### 통합 세부 정보

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [ContextualRerank](https://python.langchain.com/api_reference/en/latest/chat_models/langchain_contextual.rerank.ContextualRerank.html) | [langchain-contextual](https://python.langchain.com/api_reference/en/latest/contextual_api_reference.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-contextual?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-contextual?style=flat-square&label=%20) |

## 설정

Contextual의 reranker 모델에 액세스하려면 Contextual AI 계정을 생성하고 API 키를 받은 다음 `langchain-contextual` 통합 패키지를 설치해야 합니다.

### 자격 증명

[app.contextual.ai](https://app.contextual.ai)로 이동하여 Contextual에 가입하고 API 키를 생성하세요. 완료되면 CONTEXTUAL_AI_API_KEY 환경 변수를 설정하세요:

```python
import getpass
import os

if not os.getenv("CONTEXTUAL_AI_API_KEY"):
    os.environ["CONTEXTUAL_AI_API_KEY"] = getpass.getpass(
        "Enter your Contextual API key: "
    )
```

## 설치

LangChain Contextual 통합은 `langchain-contextual` 패키지에 있습니다:

```python
pip install -qU langchain-contextual
```

## 인스턴스화

Contextual Reranker 인수는 다음과 같습니다:

| Parameter | Type | Description |
| --- | --- | --- |
| documents | list[Document] | 재순위를 매길 문서 시퀀스. 문서에 포함된 모든 메타데이터도 재순위 지정에 사용됩니다. |
| query | str | 재순위 지정에 사용할 쿼리. |
| model | str | 사용할 reranker 버전. 현재는 "ctxl-rerank-en-v1-instruct"만 있습니다. |
| top_n | Optional[int] | 반환할 결과 수. None이면 모든 결과를 반환합니다. 기본값은 self.top_n입니다. |
| instruction | Optional[str] | reranker에 사용할 지침. |
| callbacks | Optional[Callbacks] | 압축 프로세스 중에 실행할 콜백. |

```python
from langchain_contextual import ContextualRerank

api_key = ""
model = "ctxl-rerank-en-v1-instruct"

compressor = ContextualRerank(
    model=model,
    api_key=api_key,
)
```

## 사용법

먼저 사용할 전역 변수와 예제를 설정하고 reranker 클라이언트를 인스턴스화합니다.

```python
from langchain_core.documents import Document

query = "What is the current enterprise pricing for the RTX 5090 GPU for bulk orders?"
instruction = "Prioritize internal sales documents over market analysis reports. More recent documents should be weighted higher. Enterprise portal content supersedes distributor communications."

document_contents = [
    "Following detailed cost analysis and market research, we have implemented the following changes: AI training clusters will see a 15% uplift in raw compute performance, enterprise support packages are being restructured, and bulk procurement programs (100+ units) for the RTX 5090 Enterprise series will operate on a $2,899 baseline.",
    "Enterprise pricing for the RTX 5090 GPU bulk orders (100+ units) is currently set at $3,100-$3,300 per unit. This pricing for RTX 5090 enterprise bulk orders has been confirmed across all major distribution channels.",
    "RTX 5090 Enterprise GPU requires 450W TDP and 20% cooling overhead.",
]

metadata = [
    {
        "Date": "January 15, 2025",
        "Source": "NVIDIA Enterprise Sales Portal",
        "Classification": "Internal Use Only",
    },
    {"Date": "11/30/2023", "Source": "TechAnalytics Research Group"},
    {
        "Date": "January 25, 2025",
        "Source": "NVIDIA Enterprise Sales Portal",
        "Classification": "Internal Use Only",
    },
]

documents = [
    Document(page_content=content, metadata=metadata[i])
    for i, content in enumerate(document_contents)
]
reranked_documents = compressor.compress_documents(
    query=query,
    instruction=instruction,
    documents=documents,
)
```

## 체인 내에서 사용

예제가 곧 제공될 예정입니다.

## API reference

모든 ChatContextual 기능 및 구성에 대한 자세한 문서는 Github 페이지를 참조하세요: [github.com/ContextualAI//langchain-contextual](https://github.com/ContextualAI//langchain-contextual)