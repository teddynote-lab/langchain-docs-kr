---
title: AimlapiLLM
---

<Warning>
**현재 AI/ML API 모델을 text completion 모델로 사용하는 방법을 설명하는 페이지를 보고 계십니다. 최신의 가장 인기 있는 AI/ML API 모델 대부분은 [chat completion 모델](/oss/langchain/models)입니다.**

[이 페이지](/oss/integrations/chat/aimlapi)를 찾고 계실 수 있습니다.
</Warning>

이 페이지는 AI/ML API text completion 모델을 시작하는 데 도움을 드립니다. 모든 `AimlapiLLM` 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/aimlapi/llms/langchain_aimlapi.llms.AimlapiLLM.html)를 참조하세요.

## Overview

### Integration details

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: | :---: | :---: | :---: |
| [AimlapiLLM](https://python.langchain.com/api_reference/aimlapi/llms/langchain_aimlapi.llms.AimlapiLLM.html) | [langchain-aimlapi](https://python.langchain.com/api_reference/aimlapi/index.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-aimlapi?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-aimlapi?style=flat-square&label=%20) |

### Model features

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming/) | Native async | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ | ✅ |

## Setup

AI/ML API 모델에 액세스하려면 계정을 생성하고 API key를 받은 다음 `langchain-aimlapi` integration package를 설치해야 합니다.

### Credentials

[aimlapi.com](https://aimlapi.com/app/?utm_source=langchain&utm_medium=github&utm_campaign=integration)으로 이동하여 가입하고 API key를 생성하세요. 완료한 후 `AIMLAPI_API_KEY` environment variable을 설정하세요:

```python
import getpass
import os

if not os.getenv("AIMLAPI_API_KEY"):
    os.environ["AIMLAPI_API_KEY"] = getpass.getpass("Enter your AI/ML API key: ")
```

모델 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API key를 설정하세요:

```python
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
```

### Installation

LangChain AI/ML API integration은 `langchain-aimlapi` package에 있습니다:

```python
pip install -qU langchain-aimlapi
```

## Instantiation

이제 model object를 인스턴스화하고 text completion을 생성할 수 있습니다:

```python
from langchain_aimlapi import AimlapiLLM

llm = AimlapiLLM(
    model="gpt-3.5-turbo-instruct",
    temperature=0.5,
    max_tokens=256,
)
```

## Invocation

```python
response = llm.invoke("Explain the bubble sort algorithm in Python.")
print(response)
```

```output
Bubble sort is a simple sorting algorithm that repeatedly steps through a list, compares adjacent items, and swaps them when they are out of order. The process repeats until the entire list is sorted. While easy to understand and implement, bubble sort is inefficient on large datasets because it has quadratic time complexity.
```

## Streaming invocation

토큰 단위로 응답을 스트리밍할 수도 있습니다:

```python
llm = AimlapiLLM(
    model="gpt-3.5-turbo-instruct",
)

for chunk in llm.stream("List top 5 programming languages in 2025 with reasons."):
    print(chunk, end="", flush=True)
```

## API reference

모든 AimlapiLLM 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/aimlapi/llms/langchain_aimlapi.llms.AimlapiLLM.html)를 참조하세요.