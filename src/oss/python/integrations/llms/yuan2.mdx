```mdx
---
title: Yuan2.0
---

[Yuan2.0](https://github.com/IEIT-Yuan/Yuan-2.0)은 IEIT System에서 개발한 차세대 기본 대규모 언어 모델입니다. Yuan 2.0-102B, Yuan 2.0-51B, Yuan 2.0-2B 세 가지 모델을 모두 공개했습니다. 그리고 다른 개발자들을 위해 사전 학습, 파인튜닝, 추론 서비스를 위한 관련 스크립트를 제공합니다. Yuan2.0은 Yuan1.0을 기반으로 하며, 더 광범위한 고품질 사전 학습 데이터와 instruction 파인튜닝 데이터셋을 활용하여 의미론, 수학, 추론, 코드, 지식 및 기타 측면에 대한 모델의 이해를 향상시켰습니다.

이 예제는 텍스트 생성을 위해 LangChain을 사용하여 `Yuan2.0`(2B/51B/102B) 추론과 상호작용하는 방법을 다룹니다.

Yuan2.0은 추론 서비스를 설정하여 사용자가 추론 API를 요청하기만 하면 결과를 얻을 수 있도록 했으며, 이는 [Yuan2.0 Inference-Server](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/inference_server.md)에 소개되어 있습니다.

```python
from langchain.chains import LLMChain
from langchain_community.llms.yuan2 import Yuan2
```

```python
# default infer_api for a local deployed Yuan2.0 inference server
infer_api = "http://127.0.0.1:8000/yuan"

# direct access endpoint in a proxied environment
# import os
# os.environ["no_proxy"]="localhost,127.0.0.1,::1"

yuan_llm = Yuan2(
    infer_api=infer_api,
    max_tokens=2048,
    temp=1.0,
    top_p=0.9,
    use_history=False,
)

# turn on use_history only when you want the Yuan2.0 to keep track of the conversation history
# and send the accumulated context to the backend model api, which make it stateful. By default it is stateless.
# llm.use_history = True
```

```python
question = "请介绍一下中国。"
```

```python
print(yuan_llm.invoke(question))
```
```