---
title: Outlines
---

이 가이드는 Outlines LLM을 시작하는 데 도움을 드립니다. 모든 Outlines 기능과 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.outlines.Outlines.html)를 참조하세요.

[Outlines](https://github.com/outlines-dev/outlines)는 제약 조건이 있는 언어 생성을 위한 라이브러리입니다. 다양한 백엔드를 사용하는 대규모 언어 모델(LLM)을 사용하면서 생성된 출력에 제약 조건을 적용할 수 있습니다.

## Overview

### Integration details

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [Outlines](https://python.langchain.com/api_reference/community/llms/langchain_community.llms.outlines.Outlines.html) | [langchain-community](https://python.langchain.com/api_reference/community/index.html) | ✅ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-community?style=flat-square&label=%20) |

## Setup

Outlines 모델에 액세스하려면 huggingface에서 모델 가중치를 다운로드하기 위한 인터넷 연결이 필요합니다. 사용하는 백엔드에 따라 필요한 종속성을 설치해야 합니다([Outlines docs](https://dottxt-ai.github.io/outlines/latest/installation/) 참조).

### Credentials

Outlines에는 내장된 인증 메커니즘이 없습니다.

## Installation

LangChain Outlines integration은 `langchain-community` 패키지에 포함되어 있으며 `outlines` 라이브러리가 필요합니다:

```python
pip install -qU langchain-community outlines
```

## Instantiation

이제 모델 객체를 인스턴스화하고 chat completion을 생성할 수 있습니다:

```python
from langchain_community.llms import Outlines

# For use with llamacpp backend
model = Outlines(model="microsoft/Phi-3-mini-4k-instruct", backend="llamacpp")

# For use with vllm backend (not available on Mac)
model = Outlines(model="microsoft/Phi-3-mini-4k-instruct", backend="vllm")

# For use with mlxlm backend (only available on Mac)
model = Outlines(model="microsoft/Phi-3-mini-4k-instruct", backend="mlxlm")

# For use with huggingface transformers backend
model = Outlines(
    model="microsoft/Phi-3-mini-4k-instruct"
)  # defaults to backend="transformers"
```

## Invocation

```python
model.invoke("Hello how are you?")
```

## Chaining

```python
from langchain_core.prompts import PromptTemplate

prompt = PromptTemplate.from_template("How to say {input} in {output_language}:\n")

chain = prompt | model
chain.invoke(
    {
        "output_language": "German",
        "input": "I love programming.",
    }
)
```

### Streaming

Outlines는 토큰 스트리밍을 지원합니다:

```python
for chunk in model.stream("Count to 10 in French:"):
    print(chunk, end="", flush=True)
```

### Constrained Generation

Outlines를 사용하면 생성된 출력에 다양한 제약 조건을 적용할 수 있습니다:

#### Regex Constraint

```python
model.regex = r"((25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(25[0-5]|2[0-4]\d|[01]?\d\d?)"
response = model.invoke("What is the IP address of Google's DNS server?")

response
```

### Type Constraints

```python
model.type_constraints = int
response = model.invoke("What is the answer to life, the universe, and everything?")
```

#### JSON Schema

```python
from pydantic import BaseModel


class Person(BaseModel):
    name: str


model.json_schema = Person
response = model.invoke("Who is the author of LangChain?")
person = Person.model_validate_json(response)

person
```

#### Grammar Constraint

```python
model.grammar = """
?start: expression
?expression: term (("+" | "-") term)
?term: factor (("" | "/") factor)
?factor: NUMBER | "-" factor | "(" expression ")"
%import common.NUMBER
%import common.WS
%ignore WS
"""
response = model.invoke("Give me a complex arithmetic expression:")

response
```

## API reference

모든 ChatOutlines 기능과 구성에 대한 자세한 문서는 API reference를 참조하세요: [python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.outlines.ChatOutlines.html](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.outlines.ChatOutlines.html)

## Outlines Documentation

[dottxt-ai.github.io/outlines/latest/](https://dottxt-ai.github.io/outlines/latest/)