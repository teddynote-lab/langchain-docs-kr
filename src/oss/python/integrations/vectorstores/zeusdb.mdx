---
title: ZeusDB
---

>[ZeusDB](https://www.zeusdb.com)는 Rust로 구동되는 고성능 vector database로, product quantization, 영구 저장소, 엔터프라이즈급 로깅과 같은 고급 기능을 제공합니다.

이 문서는 ZeusDB를 사용하여 LangChain 애플리케이션에 엔터프라이즈급 vector 검색 기능을 제공하는 방법을 보여줍니다.

---

## Setup

PyPi에서 ZeusDB LangChain integration package를 설치하세요:

```python
pip install -qU langchain-zeusdb
```

Jupyter Notebook에서 설정하기
> 💡 팁: Jupyter 또는 Google Colab에서 작업하는 경우, %pip magic command를 사용하여 활성 kernel에 package를 설치하세요:
>
```python
pip install -qU langchain-zeusdb
```

---

## Getting Started

이 예제는 OpenAI API key가 필요한 OpenAIEmbeddings를 사용합니다: [여기에서 OpenAI API key를 받으세요](https://platform.openai.com/api-keys)
원하시면 다른 embedding provider(Hugging Face, Cohere, custom function 등)와 함께 이 package를 사용할 수도 있습니다.
PyPi에서 LangChain OpenAI integration package를 설치하세요:

```python
pip install -qU langchain-openai

# Use this command if inside Jupyter Notebooks
#pip install -qU langchain-openai
```

#### OpenAI key 통합을 위해 아래 옵션 중 하나를 선택하세요

*옵션 1: 🔑 매번 API key 입력하기*
Jupyter에서 getpass를 사용하여 현재 세션에 대한 key를 안전하게 입력하세요:

```python
import os
import getpass

os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")
```

*옵션 2: 🗂️ .env 파일 사용하기*
로컬 .env 파일에 key를 보관하고 python-dotenv로 자동으로 로드하세요

```python
from dotenv import load_dotenv

load_dotenv()  # reads .env and sets OPENAI_API_KEY
```

<Info>
🎉 잘하셨습니다! 이제 시작할 준비가 되었습니다.
</Info>
---

## Initialization

```python
# Import required Packages and Classes
from langchain_zeusdb import ZeusDBVectorStore
from langchain_openai import OpenAIEmbeddings
from zeusdb import VectorDatabase
```

```python
# Initialize embeddings
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

# Create ZeusDB index
vdb = VectorDatabase()
index = vdb.create(index_type="hnsw", dim=1536, space="cosine")

# Create vector store
vector_store = ZeusDBVectorStore(zeusdb_index=index, embedding=embeddings)
```

---

## Manage vector store

### 2.1 Add items to vector store

```python
from langchain_core.documents import Document

document_1 = Document(
    page_content="ZeusDB is a high-performance vector database",
    metadata={"source": "https://docs.zeusdb.com"},
)

document_2 = Document(
    page_content="Product Quantization reduces memory usage significantly",
    metadata={"source": "https://docs.zeusdb.com"},
)

document_3 = Document(
    page_content="ZeusDB integrates seamlessly with LangChain",
    metadata={"source": "https://docs.zeusdb.com"},
)

documents = [document_1, document_2, document_3]

vector_store.add_documents(documents=documents, ids=["1", "2", "3"])
```

### 2.2 Update items in vector store

```python
updated_document = Document(
    page_content="ZeusDB now supports advanced Product Quantization with 4x-256x compression",
    metadata={"source": "https://docs.zeusdb.com", "updated": True},
)

vector_store.add_documents([updated_document], ids=["1"])
```

### 2.3 Delete items from vector store

```python
vector_store.delete(ids=["3"])
```

---

## Query vector store

### 3.1 Query directly

간단한 similarity search 수행하기:

```python
results = vector_store.similarity_search(query="high performance database", k=2)

for doc in results:
    print(f"* {doc.page_content} [{doc.metadata}]")
```

similarity search를 실행하고 해당 score를 받고 싶다면:

```python
results = vector_store.similarity_search_with_score(query="memory optimization", k=2)

for doc, score in results:
    print(f"* [SIM={score:.3f}] {doc.page_content} [{doc.metadata}]")
```

### 3.2 Query by turning into retriever

vector store를 retriever로 변환하여 chain에서 더 쉽게 사용할 수도 있습니다:

```python
retriever = vector_store.as_retriever(search_type="mmr", search_kwargs={"k": 2})

retriever.invoke("vector database features")
```

---

## ZeusDB-Specific Features

### 4.1 Memory-Efficient Setup with Product Quantization

대규모 dataset의 경우, Product Quantization을 사용하여 메모리 사용량을 줄이세요:

```python
# Create memory-optimized vector store
quantization_config = {"type": "pq", "subvectors": 8, "bits": 8, "training_size": 10000}

vdb_quantized = VectorDatabase()
quantized_index = vdb_quantized.create(
    index_type="hnsw", dim=1536, quantization_config=quantization_config
)

quantized_vector_store = ZeusDBVectorStore(
    zeusdb_index=quantized_index, embedding=embeddings
)

print(f"Created quantized store: {quantized_index.info()}")
```

### 4.2 Persistence

vector store를 디스크에 저장하고 로드하기:
vector store 저장하는 방법

```python
# Save the vector store
vector_store.save_index("my_zeusdb_index.zdb")
```

vector store 로드하는 방법

```python
# Load the vector store
loaded_store = ZeusDBVectorStore.load_index(
    path="my_zeusdb_index.zdb", embedding=embeddings
)

print(f"Loaded store with {loaded_store.get_vector_count()} vectors")
```

---

## Usage for retrieval-augmented generation

retrieval-augmented generation(RAG)을 위해 이 vector store를 사용하는 방법에 대한 가이드는 다음 섹션을 참조하세요:

- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)
- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval/)

---

## API reference

모든 ZeusDBVectorStore feature 및 configuration에 대한 자세한 문서는 [ZeusDB Docs](https://docs.zeusdb.com/en/latest/vector_database/integrations/langchain.html)를 참조하세요.