---
title: OceanbaseVectorStore
---

이 노트북은 Oceanbase vector store를 시작하는 방법을 다룹니다.

## Setup

Oceanbase vector store에 액세스하려면 독립 실행형 OceanBase 서버를 배포해야 합니다:
%docker run --name=ob433 -e MODE=mini -e OB_SERVER_IP=127.0.0.1 -p 2881:2881 -d quay.io/oceanbase/oceanbase-ce:4.3.3.1-101000012024102216
그리고 `langchain-oceanbase` integration package를 설치합니다.
pip install -qU "langchain-oceanbase"
OceanBase에 대한 연결을 확인하고 vector 데이터의 메모리 사용 비율을 설정합니다:

```python
from pyobvector import ObVecClient

tmp_client = ObVecClient()
tmp_client.perform_raw_text_sql("ALTER SYSTEM ob_vector_memory_limit_percentage = 30")
```

```output
<sqlalchemy.engine.cursor.CursorResult at 0x12696f2a0>
```

## Initialization

embedding model의 API key를 구성합니다. 여기서는 `DashScopeEmbeddings`를 예시로 사용합니다. 위에서 설명한 대로 Docker image로 `Oceanbase`를 배포할 때는 아래 스크립트를 따라 `host`, `port`, `user`, `password`, `database name`을 설정하면 됩니다. 다른 배포 방법의 경우 실제 상황에 따라 이러한 매개변수를 설정하세요.
pip install dashscope

```python
import os

from langchain_community.embeddings import DashScopeEmbeddings
from langchain_oceanbase.vectorstores import OceanbaseVectorStore

DASHSCOPE_API = os.environ.get("DASHSCOPE_API_KEY", "")
connection_args = {
    "host": "127.0.0.1",
    "port": "2881",
    "user": "root@test",
    "password": "",
    "db_name": "test",
}

embeddings = DashScopeEmbeddings(
    model="text-embedding-v1", dashscope_api_key=DASHSCOPE_API
)

vector_store = OceanbaseVectorStore(
    embedding_function=embeddings,
    table_name="langchain_vector",
    connection_args=connection_args,
    vidx_metric_type="l2",
    drop_old=True,
)
```

## Manage vector store

### Add items to vector store

- TODO: Edit and then run code cell to generate output

```python
from langchain_core.documents import Document

document_1 = Document(page_content="foo", metadata={"source": "https://foo.com"})
document_2 = Document(page_content="bar", metadata={"source": "https://bar.com"})
document_3 = Document(page_content="baz", metadata={"source": "https://baz.com"})

documents = [document_1, document_2, document_3]

vector_store.add_documents(documents=documents, ids=["1", "2", "3"])
```

```output
['1', '2', '3']
```

### Update items in vector store

```python
updated_document = Document(
    page_content="qux", metadata={"source": "https://another-example.com"}
)

vector_store.add_documents(documents=[updated_document], ids=["1"])
```

```output
['1']
```

### Delete items from vector store

```python
vector_store.delete(ids=["3"])
```

## Query vector store

vector store가 생성되고 관련 문서가 추가되면 chain이나 agent를 실행하는 동안 쿼리하고 싶을 것입니다.

### Query directly

간단한 유사도 검색은 다음과 같이 수행할 수 있습니다:

```python
results = vector_store.similarity_search(
    query="thud", k=1, filter={"source": "https://another-example.com"}
)
for doc in results:
    print(f"* {doc.page_content} [{doc.metadata}]")
```

```output
* bar [{'source': 'https://bar.com'}]
```

유사도 검색을 실행하고 해당 점수를 받으려면 다음을 실행할 수 있습니다:

```python
results = vector_store.similarity_search_with_score(
    query="thud", k=1, filter={"source": "https://example.com"}
)
for doc, score in results:
    print(f"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]")
```

```output
* [SIM=133.452299] bar [{'source': 'https://bar.com'}]
```

### Query by turning into retriever

chain에서 더 쉽게 사용하기 위해 vector store를 retriever로 변환할 수도 있습니다.

```python
retriever = vector_store.as_retriever(search_kwargs={"k": 1})
retriever.invoke("thud")
```

```output
[Document(metadata={'source': 'https://bar.com'}, page_content='bar')]
```

## Usage for retrieval-augmented generation

이 vector store를 retrieval-augmented generation (RAG)에 사용하는 방법에 대한 가이드는 다음 섹션을 참조하세요:

- [LangChain으로 RAG 앱 만들기](/oss/langchain/rag)
- [Agentic RAG](/oss/langgraph/agentic-rag)
- [Retrieval 문서](/oss/langchain/retrieval)

## API reference

모든 OceanbaseVectorStore 기능 및 구성에 대한 자세한 문서는 API reference를 참조하세요: [python.langchain.com/docs/integrations/vectorstores/oceanbase](https://python.langchain.com/docs/integrations/vectorstores/oceanbase)