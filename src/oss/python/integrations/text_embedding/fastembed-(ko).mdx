---
title: Qdrant의 FastEmbed
---

>[FastEmbed](https://qdrant.github.io/fastembed/)는 [Qdrant](https://qdrant.tech)에서 제공하는 경량화되고 빠른 Python 라이브러리로, embedding 생성을 위해 만들어졌습니다.
>
>- 양자화된 model weights
>- ONNX Runtime, PyTorch 의존성 없음
>- CPU 우선 설계
>- 대규모 데이터셋 인코딩을 위한 데이터 병렬 처리

## Dependencies

LangChain에서 FastEmbed를 사용하려면 `fastembed` Python package를 설치하세요.

```python
pip install -qU  fastembed
```

## Imports

```python
from langchain_community.embeddings.fastembed import FastEmbedEmbeddings
```

## FastEmbed 인스턴스화

### Parameters

- `model_name: str` (기본값: "BAAI/bge-small-en-v1.5")
        > 사용할 FastEmbedding model의 이름입니다. 지원되는 model 목록은 [여기](https://qdrant.github.io/fastembed/examples/Supported_Models/)에서 확인할 수 있습니다.

- `max_length: int` (기본값: 512)
        > 최대 token 수입니다. 512보다 큰 값에 대한 동작은 정의되지 않았습니다.

- `cache_dir: Optional[str]` (기본값: None)
        > cache directory의 경로입니다. 기본값은 상위 directory의 `local_cache`입니다.

- `threads: Optional[int]` (기본값: None)
        > 단일 onnxruntime session이 사용할 수 있는 thread 수입니다.

- `doc_embed_type: Literal["default", "passage"]` (기본값: "default")
        > "default": FastEmbed의 기본 embedding 방법을 사용합니다.

        > "passage": embedding 전에 텍스트 앞에 "passage"를 접두사로 붙입니다.

- `batch_size: int` (기본값: 256)
        > 인코딩을 위한 batch size입니다. 값이 클수록 더 많은 메모리를 사용하지만 더 빠릅니다.

- `parallel: Optional[int]` (기본값: None)

        > `>1`인 경우, 데이터 병렬 인코딩이 사용되며, 대규모 데이터셋의 오프라인 인코딩에 권장됩니다.
        > `0`인 경우, 사용 가능한 모든 core를 사용합니다.
        > `None`인 경우, 데이터 병렬 처리를 사용하지 않고 기본 onnxruntime threading을 사용합니다.

```python
embeddings = FastEmbedEmbeddings()
```

## Usage

### document embedding 생성

```python
document_embeddings = embeddings.embed_documents(
    ["This is a document", "This is some other document"]
)
```

### query embedding 생성

```python
query_embeddings = embeddings.embed_query("This is a query")
```