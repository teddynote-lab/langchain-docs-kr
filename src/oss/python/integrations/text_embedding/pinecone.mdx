---
title: Pinecone Embeddings
---

Pinecone의 inference API는 `PineconeEmbeddings`를 통해 접근할 수 있습니다. Pinecone 서비스를 통해 텍스트 임베딩을 제공합니다. 먼저 필수 라이브러리를 설치합니다:

```python
!pip install -qU "langchain-pinecone>=0.2.0"
```

다음으로, [Pinecone에 가입 / 로그인](https://app.pinecone.io)하여 API 키를 받습니다:

```python
import os
from getpass import getpass

os.environ["PINECONE_API_KEY"] = os.getenv("PINECONE_API_KEY") or getpass(
    "Enter your Pinecone API key: "
)
```

사용 가능한 [models](https://docs.pinecone.io/models/overview)에 대한 문서를 확인하세요. 이제 다음과 같이 임베딩 모델을 초기화합니다:

```python
from langchain_pinecone import PineconeEmbeddings

embeddings = PineconeEmbeddings(model="multilingual-e5-large")
```

여기서부터 동기 또는 비동기 방식으로 임베딩을 생성할 수 있습니다. 먼저 동기 방식부터 시작하겠습니다! `embed_query`를 사용하여 단일 텍스트를 query 임베딩(즉, RAG에서 검색할 때 사용하는 것)으로 임베딩합니다:

```python
docs = [
    "Apple is a popular fruit known for its sweetness and crisp texture.",
    "The tech company Apple is known for its innovative products like the iPhone.",
    "Many people enjoy eating apples as a healthy snack.",
    "Apple Inc. has revolutionized the tech industry with its sleek designs and user-friendly interfaces.",
    "An apple a day keeps the doctor away, as the saying goes.",
]
```

```python
doc_embeds = embeddings.embed_documents(docs)
doc_embeds
```

```python
query = "Tell me about the tech company known as Apple"
query_embed = embeddings.embed_query(query)
query_embed
```