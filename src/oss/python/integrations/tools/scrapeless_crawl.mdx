---
title: Scrapeless Crawl
---

[**Scrapeless**](https://www.scrapeless.com/)ëŠ” ê´‘ë²”ìœ„í•œ ë§¤ê°œë³€ìˆ˜ ì»¤ìŠ¤í„°ë§ˆì´ì§•ê³¼ ë‹¤ì¤‘ í˜•ì‹ ë‚´ë³´ë‚´ê¸° ì§€ì›ì„ í†µí•´ ìœ ì—°í•˜ê³  ê¸°ëŠ¥ì´ í’ë¶€í•œ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ LangChainì´ ì™¸ë¶€ ë°ì´í„°ë¥¼ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ í†µí•©í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤. í•µì‹¬ ê¸°ëŠ¥ ëª¨ë“ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

**DeepSerp**

- **Google Search**: ëª¨ë“  ê²°ê³¼ ìœ í˜•ì— ê±¸ì³ Google SERP ë°ì´í„°ì˜ í¬ê´„ì ì¸ ì¶”ì¶œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
  - ì§€ì—­ë³„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•´ ì§€ì—­í™”ëœ Google ë„ë©”ì¸(ì˜ˆ: `google.com`, `google.ad`) ì„ íƒì„ ì§€ì›í•©ë‹ˆë‹¤.
  - ì²« í˜ì´ì§€ ì´í›„ì˜ ê²°ê³¼ë¥¼ ê²€ìƒ‰í•˜ê¸° ìœ„í•œ í˜ì´ì§€ë„¤ì´ì…˜ì„ ì§€ì›í•©ë‹ˆë‹¤.
  - ì¤‘ë³µë˜ê±°ë‚˜ ìœ ì‚¬í•œ ì½˜í…ì¸ ë¥¼ ì œì™¸í• ì§€ ì œì–´í•˜ëŠ” ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§ í† ê¸€ì„ ì§€ì›í•©ë‹ˆë‹¤.
- **Google Trends**: ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ ì¸ê¸°ë„, ì§€ì—­ë³„ ê´€ì‹¬ë„, ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•œ Googleì˜ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
  - ë‹¤ì¤‘ í‚¤ì›Œë“œ ë¹„êµë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
  - ì—¬ëŸ¬ ë°ì´í„° ìœ í˜•ì„ ì§€ì›í•©ë‹ˆë‹¤: `interest_over_time`, `interest_by_region`, `related_queries`, `related_topics`.
  - ì†ŒìŠ¤ë³„ íŠ¸ë Œë“œ ë¶„ì„ì„ ìœ„í•´ íŠ¹ì • Google ì†ì„±(Web, YouTube, News, Shopping)ë³„ í•„í„°ë§ì„ í—ˆìš©í•©ë‹ˆë‹¤.

**Universal Scraping**

- JavaScriptê°€ ë§ì´ ì‚¬ìš©ë˜ëŠ” ìµœì‹  ì›¹ì‚¬ì´íŠ¸ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì–´ ë™ì  ì½˜í…ì¸  ì¶”ì¶œì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
  - ì§€ì—­ ì œí•œì„ ìš°íšŒí•˜ê³  ì•ˆì •ì„±ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ê¸€ë¡œë²Œ í”„ë¦¬ë¯¸ì—„ í”„ë¡ì‹œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

**Crawler**

- **Crawl**: ì›¹ì‚¬ì´íŠ¸ì™€ ì—°ê²°ëœ í˜ì´ì§€ë¥¼ ì¬ê·€ì ìœ¼ë¡œ í¬ë¡¤ë§í•˜ì—¬ ì‚¬ì´íŠ¸ ì „ì²´ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
  - êµ¬ì„± ê°€ëŠ¥í•œ í¬ë¡¤ë§ ê¹Šì´ì™€ ë²”ìœ„ê°€ ì§€ì •ëœ URL íƒ€ê²ŸíŒ…ì„ ì§€ì›í•©ë‹ˆë‹¤.
- **Scrape**: ë†’ì€ ì •ë°€ë„ë¡œ ë‹¨ì¼ ì›¹í˜ì´ì§€ì—ì„œ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
  - ê´‘ê³ , í‘¸í„° ë° ê¸°íƒ€ í•„ìˆ˜ì ì´ì§€ ì•Šì€ ìš”ì†Œë¥¼ ì œì™¸í•˜ëŠ” "ë©”ì¸ ì½˜í…ì¸ ë§Œ" ì¶”ì¶œì„ ì§€ì›í•©ë‹ˆë‹¤.
  - ì—¬ëŸ¬ ë…ë¦½ URLì˜ ì¼ê´„ ìŠ¤í¬ë˜í•‘ì„ í—ˆìš©í•©ë‹ˆë‹¤.

## Overview

### Integration details

| Class | Package | Serializable | JS support |  Version |
| :--- | :--- | :---: | :---: | :---: |
| [ScrapelessCrawlerScrapeTool](https://pypi.org/project/langchain-scrapeless/) | [langchain-scrapeless](https://pypi.org/project/langchain-scrapeless/) | âœ… | âŒ |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-scrapeless?style=flat-square&label=%20) |
| [ScrapelessCrawlerCrawlTool](https://pypi.org/project/langchain-scrapeless/) | [langchain-scrapeless](https://pypi.org/project/langchain-scrapeless/) | âœ… | âŒ |  ![PyPI - Version](https://img.shields.io/pypi/v/langchain-scrapeless?style=flat-square&label=%20) |

### Tool features

|Native async|Returns artifact|Return data|
|:-:|:-:|:-:|
|âœ…|âœ…|markdown, rawHtml, screenshot@fullPage, json, links, screenshot, html|

## Setup

integrationì€ `langchain-scrapeless` íŒ¨í‚¤ì§€ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
!pip install langchain-scrapeless

### Credentials

ì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Scrapeless API keyê°€ í•„ìš”í•©ë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
import os

os.environ["SCRAPELESS_API_KEY"] = "your-api-key"
```

## Instantiation

### ScrapelessCrawlerScrapeTool

ScrapelessCrawlerScrapeToolì„ ì‚¬ìš©í•˜ë©´ Scrapelessì˜ Crawler Scrape APIë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì½˜í…ì¸ ë¥¼ ìŠ¤í¬ë˜í•‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë©”ì¸ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•˜ê³ , í˜•ì‹, í—¤ë”, ëŒ€ê¸° ì‹œê°„ ë° ì¶œë ¥ ìœ í˜•ì„ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ë„êµ¬ëŠ” ë‹¤ìŒ ë§¤ê°œë³€ìˆ˜ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤:

- `urls` (í•„ìˆ˜, List[str]): ìŠ¤í¬ë˜í•‘í•˜ë ¤ëŠ” ì›¹ì‚¬ì´íŠ¸ì˜ í•˜ë‚˜ ì´ìƒì˜ URLì…ë‹ˆë‹¤.
- `formats` (ì„ íƒ, List[str]): ìŠ¤í¬ë˜í•‘ëœ ì¶œë ¥ì˜ í˜•ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `['markdown']`ì…ë‹ˆë‹¤. ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
  - `'markdown'`
  - `'rawHtml'`
  - `'screenshot@fullPage'`
  - `'json'`
  - `'links'`
  - `'screenshot'`
  - `'html'`
- `only_main_content` (ì„ íƒ, bool): í—¤ë”, ë„¤ë¹„ê²Œì´ì…˜, í‘¸í„° ë“±ì„ ì œì™¸í•˜ê³  ë©”ì¸ í˜ì´ì§€ ì½˜í…ì¸ ë§Œ ë°˜í™˜í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.
- `include_tags` (ì„ íƒ, List[str]): ì¶œë ¥ì— í¬í•¨í•  HTML íƒœê·¸ ëª©ë¡ì…ë‹ˆë‹¤(ì˜ˆ: `['h1', 'p']`). Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë˜ëŠ” íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.
- `exclude_tags` (ì„ íƒ, List[str]): ì¶œë ¥ì—ì„œ ì œì™¸í•  HTML íƒœê·¸ ëª©ë¡ì…ë‹ˆë‹¤. Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª…ì‹œì ìœ¼ë¡œ ì œì™¸ë˜ëŠ” íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.
- `headers` (ì„ íƒ, Dict[str, str]): ìš”ì²­ê³¼ í•¨ê»˜ ë³´ë‚¼ ì‚¬ìš©ì ì •ì˜ í—¤ë”ì…ë‹ˆë‹¤(ì˜ˆ: ì¿ í‚¤ ë˜ëŠ” user-agent). ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤.
- `wait_for` (ì„ íƒ, int): ìŠ¤í¬ë˜í•‘í•˜ê¸° ì „ì— ëŒ€ê¸°í•  ì‹œê°„(ë°€ë¦¬ì´ˆ)ì…ë‹ˆë‹¤. í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë  ì‹œê°„ì„ ì£¼ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `0`ì…ë‹ˆë‹¤.
- `timeout` (ì„ íƒ, int): ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ë°€ë¦¬ì´ˆ)ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `30000`ì…ë‹ˆë‹¤.

### ScrapelessCrawlerCrawlTool

ScrapelessCrawlerCrawlToolì„ ì‚¬ìš©í•˜ë©´ Scrapelessì˜ Crawler Crawl APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ URLì—ì„œ ì‹œì‘í•˜ëŠ” ì›¹ì‚¬ì´íŠ¸ë¥¼ í¬ë¡¤ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. URLì˜ ê³ ê¸‰ í•„í„°ë§, í¬ë¡¤ë§ ê¹Šì´ ì œì–´, ì½˜í…ì¸  ìŠ¤í¬ë˜í•‘ ì˜µì…˜, í—¤ë” ì»¤ìŠ¤í„°ë§ˆì´ì§• ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.

ì´ ë„êµ¬ëŠ” ë‹¤ìŒ ë§¤ê°œë³€ìˆ˜ë¥¼ í—ˆìš©í•©ë‹ˆë‹¤:

- `url` (í•„ìˆ˜, str): í¬ë¡¤ë§ì„ ì‹œì‘í•  ê¸°ë³¸ URLì…ë‹ˆë‹¤.

- `limit` (ì„ íƒ, int): í¬ë¡¤ë§í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `10000`ì…ë‹ˆë‹¤.
- `include_paths` (ì„ íƒ, List[str]): í¬ë¡¤ë§ì— ì¼ì¹˜í•˜ëŠ” URLì„ í¬í•¨í•  URL ê²½ë¡œëª… ì •ê·œì‹ íŒ¨í„´ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ” URLë§Œ í¬í•¨ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `["blog/.*"]`ë¡œ ì„¤ì •í•˜ë©´ `/blog/` ê²½ë¡œ ì•„ë˜ì˜ URLë§Œ í¬í•¨ë©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤.
- `exclude_paths` (ì„ íƒ, List[str]): í¬ë¡¤ë§ì—ì„œ ì¼ì¹˜í•˜ëŠ” URLì„ ì œì™¸í•  URL ê²½ë¡œëª… ì •ê·œì‹ íŒ¨í„´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `["blog/.*"]`ë¡œ ì„¤ì •í•˜ë©´ `/blog/` ê²½ë¡œ ì•„ë˜ì˜ URLì´ ì œì™¸ë©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤.
- `max_depth` (ì„ íƒ, int): ê¸°ë³¸ URLì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ìµœëŒ€ í¬ë¡¤ë§ ê¹Šì´ë¡œ, URL ê²½ë¡œì˜ ìŠ¬ë˜ì‹œ ìˆ˜ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `10`ì…ë‹ˆë‹¤.
- `max_discovery_depth` (ì„ íƒ, int): ë°œê²¬ ìˆœì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìµœëŒ€ í¬ë¡¤ë§ ê¹Šì´ì…ë‹ˆë‹¤. ë£¨íŠ¸ ë° ì‚¬ì´íŠ¸ë§µ í˜ì´ì§€ì˜ ê¹Šì´ëŠ” `0`ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `1`ë¡œ ì„¤ì •í•˜ê³  ì‚¬ì´íŠ¸ë§µì„ ë¬´ì‹œí•˜ë©´ ì…ë ¥ëœ URLê³¼ ì§ì ‘ ë§í¬ë§Œ í¬ë¡¤ë§í•©ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤.
- `ignore_sitemap` (ì„ íƒ, bool): í¬ë¡¤ë§ ì¤‘ ì›¹ì‚¬ì´íŠ¸ ì‚¬ì´íŠ¸ë§µì„ ë¬´ì‹œí• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤.
- `ignore_query_params` (ì„ íƒ, bool): ìœ ì‚¬í•œ URLì˜ ì¬ìŠ¤í¬ë˜í•‘ì„ í”¼í•˜ê¸° ìœ„í•´ ì¿¼ë¦¬ ë§¤ê°œë³€ìˆ˜ ì°¨ì´ë¥¼ ë¬´ì‹œí• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤.
- `deduplicate_similar_urls` (ì„ íƒ, bool): ìœ ì‚¬í•œ URLì„ ì¤‘ë³µ ì œê±°í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.
- `regex_on_full_url` (ì„ íƒ, bool): ì •ê·œì‹ ë§¤ì¹­ì´ ê²½ë¡œë§Œì´ ì•„ë‹Œ ì „ì²´ URLì— ì ìš©ë˜ëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.
- `allow_backward_links` (ì„ íƒ, bool): URL ê³„ì¸µ êµ¬ì¡° ì™¸ë¶€ì˜ ë°±ë§í¬ í¬ë¡¤ë§ì„ í—ˆìš©í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤.
- `allow_external_links` (ì„ íƒ, bool): ì™¸ë¶€ ì›¹ì‚¬ì´íŠ¸ë¡œì˜ ë§í¬ í¬ë¡¤ë§ì„ í—ˆìš©í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤.
- `delay` (ì„ íƒ, int): ì†ë„ ì œí•œì„ ì¤€ìˆ˜í•˜ê¸° ìœ„í•œ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ê°„ ì§€ì—° ì‹œê°„(ì´ˆ)ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `1`ì…ë‹ˆë‹¤.
- `formats` (ì„ íƒ, List[str]): ìŠ¤í¬ë˜í•‘ëœ ì½˜í…ì¸ ì˜ í˜•ì‹ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ ["markdown"]ì…ë‹ˆë‹¤. ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
  - `'markdown'`
  - `'rawHtml'`
  - `'screenshot@fullPage'`
  - `'json'`
  - `'links'`
  - `'screenshot'`
  - `'html'`
- `only_main_content` (ì„ íƒ, bool): í—¤ë”, ë„¤ë¹„ê²Œì´ì…˜ ë°”, í‘¸í„° ë“±ì„ ì œì™¸í•˜ê³  ë©”ì¸ ì½˜í…ì¸ ë§Œ ë°˜í™˜í• ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Trueì…ë‹ˆë‹¤.
- `include_tags` (ì„ íƒ, List[str]): ì¶œë ¥ì— í¬í•¨í•  HTML íƒœê·¸ ëª©ë¡ì…ë‹ˆë‹¤(ì˜ˆ: `['h1', 'p']`). ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤(ëª…ì‹œì  í¬í•¨ í•„í„° ì—†ìŒ).
- `exclude_tags` (ì„ íƒ, List[str]): ì¶œë ¥ì—ì„œ ì œì™¸í•  HTML íƒœê·¸ ëª©ë¡ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤(ëª…ì‹œì  ì œì™¸ í•„í„° ì—†ìŒ).
- `headers` (ì„ íƒ, Dict[str, str]): ì¿ í‚¤ ë˜ëŠ” user-agent ë¬¸ìì—´ê³¼ ê°™ì´ ìš”ì²­ê³¼ í•¨ê»˜ ë³´ë‚¼ ì‚¬ìš©ì ì •ì˜ HTTP í—¤ë”ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ Noneì…ë‹ˆë‹¤.
- `wait_for` (ì„ íƒ, int): í˜ì´ì§€ê°€ ì™„ì „íˆ ë¡œë“œë˜ë„ë¡ ì½˜í…ì¸ ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê¸° ì „ì— ëŒ€ê¸°í•  ì‹œê°„(ë°€ë¦¬ì´ˆ)ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `0`ì…ë‹ˆë‹¤.
- `timeout` (ì„ íƒ, int): ìš”ì²­ íƒ€ì„ì•„ì›ƒ(ë°€ë¦¬ì´ˆ)ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ `30000`ì…ë‹ˆë‹¤.

## Invocation

### ScrapelessCrawlerCrawlTool

#### Usage with Parameters

```python
from langchain_scrapeless import ScrapelessCrawlerCrawlTool

tool = ScrapelessCrawlerCrawlTool()

# Advanced usage
result = tool.invoke({"url": "https://exmaple.com", "limit": 4})
print(result)
```

```output
{'success': True, 'status': 'completed', 'completed': 1, 'total': 1, 'data': [{'markdown': '# Well hello there.\n\nWelcome to exmaple.com.\n\nChances are you got here by mistake (example.com, anyone?)', 'metadata': {'scrapeId': '547b2478-a41a-4a17-8015-8db378ee455f', 'sourceURL': 'https://exmaple.com', 'url': 'https://exmaple.com', 'statusCode': 200}}]}
```

#### Use within an agent

```python
from langchain_openai import ChatOpenAI
from langchain_scrapeless import ScrapelessCrawlerCrawlTool
from langchain.agents import create_agent


model = ChatOpenAI()

tool = ScrapelessCrawlerCrawlTool()

# Use the tool with an agent
tools = [tool]
agent = create_agent(model, tools)

for chunk in agent.stream(
    {
        "messages": [
            (
                "human",
                "Use the scrapeless crawler crawl tool to crawl the website https://example.com and output the markdown content as a string.",
            )
        ]
    },
    stream_mode="values",
):
    chunk["messages"][-1].pretty_print()
```

```output
================================ Human Message =================================

Use the scrapeless crawler crawl tool to crawl the website https://example.com and output the markdown content as a string.
================================== Ai Message ==================================
Tool Calls:
  scrapeless_crawler_crawl (call_Ne5HbxqsYDOKFaGDSuc4xppB)
 Call ID: call_Ne5HbxqsYDOKFaGDSuc4xppB
  Args:
    url: https://example.com
    formats: ['markdown']
    limit: 1
================================= Tool Message =================================
Name: scrapeless_crawler_crawl

{"success": true, "status": "completed", "completed": 1, "total": 1, "data": [{"markdown": "# Example Domain\n\nThis domain is for use in illustrative examples in documents. You may use this\ndomain in literature without prior coordination or asking for permission.\n\n[More information...](https://www.iana.org/domains/example)", "metadata": {"viewport": "width=device-width, initial-scale=1", "title": "Example Domain", "scrapeId": "00561460-9166-492b-8fed-889667383e55", "sourceURL": "https://example.com", "url": "https://example.com", "statusCode": 200}}]}
================================== Ai Message ==================================

The crawl of the website https://example.com has been completed. Here is the markdown content extracted from the website:

\`\`\`
# Example Domain

This domain is for use in illustrative examples in documents. You may use this
domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)
\`\`\`

You can find more information on the website [here](https://www.iana.org/domains/example).
```

### ScrapelessCrawlerScrapeTool

#### Usage with Parameters

```python
from langchain_scrapeless import ScrapelessDeepSerpGoogleTrendsTool

tool = ScrapelessDeepSerpGoogleTrendsTool()

# Basic usage
result = tool.invoke("Funny 2048,negamon monster trainer")
print(result)
```

```output
{'parameters': {'engine': 'google.trends.search', 'hl': 'en', 'data_type': 'INTEREST_OVER_TIME', 'tz': '0', 'cat': '0', 'date': 'today 1-m', 'q': 'Funny 2048,negamon monster trainer'}, 'interest_over_time': {'timeline_data': [{'date': 'Jul 11, 2025', 'timestamp': '1752192000', 'value': [0, 0]}, {'date': 'Jul 12, 2025', 'timestamp': '1752278400', 'value': [0, 0]}, {'date': 'Jul 13, 2025', 'timestamp': '1752364800', 'value': [0, 0]}, {'date': 'Jul 14, 2025', 'timestamp': '1752451200', 'value': [0, 0]}, {'date': 'Jul 15, 2025', 'timestamp': '1752537600', 'value': [0, 0]}, {'date': 'Jul 16, 2025', 'timestamp': '1752624000', 'value': [0, 0]}, {'date': 'Jul 17, 2025', 'timestamp': '1752710400', 'value': [0, 0]}, {'date': 'Jul 18, 2025', 'timestamp': '1752796800', 'value': [0, 0]}, {'date': 'Jul 19, 2025', 'timestamp': '1752883200', 'value': [0, 0]}, {'date': 'Jul 20, 2025', 'timestamp': '1752969600', 'value': [0, 0]}, {'date': 'Jul 21, 2025', 'timestamp': '1753056000', 'value': [0, 0]}, {'date': 'Jul 22, 2025', 'timestamp': '1753142400', 'value': [0, 0]}, {'date': 'Jul 23, 2025', 'timestamp': '1753228800', 'value': [0, 0]}, {'date': 'Jul 24, 2025', 'timestamp': '1753315200', 'value': [0, 0]}, {'date': 'Jul 25, 2025', 'timestamp': '1753401600', 'value': [0, 0]}, {'date': 'Jul 26, 2025', 'timestamp': '1753488000', 'value': [0, 0]}, {'date': 'Jul 27, 2025', 'timestamp': '1753574400', 'value': [0, 0]}, {'date': 'Jul 28, 2025', 'timestamp': '1753660800', 'value': [0, 0]}, {'date': 'Jul 29, 2025', 'timestamp': '1753747200', 'value': [0, 0]}, {'date': 'Jul 30, 2025', 'timestamp': '1753833600', 'value': [0, 0]}, {'date': 'Jul 31, 2025', 'timestamp': '1753920000', 'value': [0, 0]}, {'date': 'Aug 1, 2025', 'timestamp': '1754006400', 'value': [0, 0]}, {'date': 'Aug 2, 2025', 'timestamp': '1754092800', 'value': [0, 0]}, {'date': 'Aug 3, 2025', 'timestamp': '1754179200', 'value': [0, 0]}, {'date': 'Aug 4, 2025', 'timestamp': '1754265600', 'value': [0, 0]}, {'date': 'Aug 5, 2025', 'timestamp': '1754352000', 'value': [0, 0]}, {'date': 'Aug 6, 2025', 'timestamp': '1754438400', 'value': [0, 0]}, {'date': 'Aug 7, 2025', 'timestamp': '1754524800', 'value': [0, 0]}, {'date': 'Aug 8, 2025', 'timestamp': '1754611200', 'value': [0, 0]}, {'date': 'Aug 9, 2025', 'timestamp': '1754697600', 'value': [0, 0]}, {'date': 'Aug 10, 2025', 'timestamp': '1754784000', 'value': [0, 100]}, {'date': 'Aug 11, 2025', 'timestamp': '1754870400', 'value': [0, 0]}], 'averages': [{'value': 0}, {'value': 3}], 'isPartial': True}}
```

#### Advanced Usage with Parameters

```python
from langchain_scrapeless import ScrapelessCrawlerScrapeTool

tool = ScrapelessCrawlerScrapeTool()

result = tool.invoke(
    {
        "urls": ["https://exmaple.com", "https://www.scrapeless.com/en"],
        "formats": ["markdown"],
    }
)
print(result)
```

```output
{'success': True, 'status': 'completed', 'completed': 1, 'total': 1, 'data': [{'markdown': "[ğŸ©µ Don't just take our word for it. See what our users say on Product Hunt.](https://www.producthunt.com/posts/scrapeless-deep-serpapi)\n\n# Effortless Web Scraping Toolkit  for Business and Developers\n\nThe ultimate scraper's companion: an expandable suite of tools, including\n\nScraping Browser, Scraping API, Universal Scraping API\n\nand Anti-Bot Solutionsâ€”designed to work together or independently.\n\n[**4.8**](https://www.g2.com/products/scrapeless/reviews) [**4.5**](https://www.trustpilot.com/review/scrapeless.com) [**4.8**](https://slashdot.org/software/p/Scrapeless/) [**8.5**](https://tekpon.com/software/scrapeless/reviews/)\n\nNo credit card required\n\n## A Flexible Toolkit for Accessing Public Web Data\n\nAI-powered seamless data extraction, effortlessly bypassing blocks with a single API call.\n\n[scrapeless](https://www.scrapeless.com/en)\n\n[![Deep SerpApi](https://www.scrapeless.com/_next/image?url=%2Fassets%2Fimages%2Ftoolkit%2Flight%2Fimg-2.png&w=750&q=100)\\\\\n\\\\\nView more\\\\\n\\\\\n20+ custom parameters\\\\\n\\\\\n20+ Google SERP scenarios\\\\\n\\\\\nPrecision Search Fueling LLM & RAG AI\\\\\n\\\\\n1-2s response; $0.1/1k queries](https://www.scrapeless.com/en/product/deep-serp-api) [![Scraping Browser](https://www.scrapeless.com/_next/image?url=%2Fassets%2Fimages%2Ftoolkit%2Flight%2Fimg-4.png&w=750&q=100)\\\\\n\\\\\nView more\\\\\n\\\\\nHuman-like Behavior\\\\\n\\\\\nHigh Performance\\\\\n\\\\\nBypassing Risk Control\\\\\n\\\\\nConnect using the CDP Protocol](https://www.scrapeless.com/en/product/scraping-browser) [![Universal Scraping API](https://www.scrapeless.com/_next/image?url=%2Fassets%2Fimages%2Ftoolkit%2Flight%2Fimg-1.png&w=750&q=100)\\\\\n\\\\\nView more\\\\\n\\\\\nSession Mode\\\\\n\\\\\nCustom TLS\\\\\n\\\\\nJs Render](https://www.scrapeless.com/en/product/universal-scraping-api)\n\n### Customized Services\n\nContact our technical experts for custom solutions.\n\nBook a demo\n\n## From Simple Data Scraping to Complex Anti-Bot Challenges,   Scrapeless Has You Covered.\n\nFlexible Toolkit for Adapting to Diverse Data Extraction Needs.\n\n[Try for Free](https://app.scrapeless.com/passport/register)\n\n### Fully Compatible with Key Programming Languages and Tools\n\nSeamlessly integrate across all devices, OS, and languages. Worry-free compatibility ensures smooth data collection.\n\nGet all example codes on the dashboard after login\n\n![scrapeless](https://www.scrapeless.com/_next/image?url=%2Fassets%2Fimages%2Fcode%2Fcode-l.jpg&w=3840&q=75)\n\n## Enterprise-level Data Scraping Solution\n\nHigh-quality, tailored web scraping solutions and expert services designed for critical business projects.\n\n### Customized Data Scraping Solutions\n\nTailored web scraping services designed to address your\xa0 unique business requirements and deliver actionable insights.\n\n### High Concurrency and High-Performance Scraping\n\nEfficiently gather massive volumes of data with unparalleled speed and reliability,\xa0ensuring optimal performance even under heavy load.\n\n### Data Cleaning and Transformation\n\nEnhance data accuracy and usability through comprehensive\xa0 cleaning and transformation processes, turning raw data into\xa0 valuable information.\n\n### Real-Time Data Push and API Integration\n\nSeamlessly integrate and access live data streams with robust APIs,\xa0ensuring your applications are always up-to-date with the latest information.\n\n### Data Security and Privacy Protection\n\nProtect your data with state-of-the-art security measures and strict\xa0compliance standards, ensuring privacy and confidentiality at every step.\n\n### Enterprise-level SLA\n\nThe Service Level Agreement (SLA) serves as a safeguard for your project,\xa0ensuring a contract for anticipated outcomes, automated oversight, prompt issue\xa0resolution, and a personalized maintenance plan.\n\n## Why Scrapeless: Simplify Your Data Flow Effortlessly.\n\nAchieve all your data scraping tasks with more power, simplicity, and cost-effectiveness in less time.\n\n### Articles\n\nNews articles/Blog posts/Research papers\n\n### Organized Fresh Data\n\n### Prices\n\nProduct prices/Discount information/Market trend analysis\n\n### No need to hassle with browser maintenance\n\n### Reviews\n\nProduct reviews/User feedback/Social media reviews\n\n### Only pay for successful requests\n\n### Products\n\nProduct Launches/Tech Specs/Product Comparisons\n\n### Fully scalable\n\n## Unleash Your Competitive Edge  in Data within the Industry\n\n## Regulate Compliance for All Users\n\nContact us\n\nWe are committed to using technology for the benefit of humanity and firmly oppose any illegal activities and misuse of our products. We support the collection of publicly available data to improve human life, while strongly opposing the collection of unauthorized or unapproved sensitive information. If you find anyone abusing our services, please provide us with feedback! To further enhance user confidence and control, we have established a dedicated Privacy Center aimed at empowering users with more capabilities and information rights.\n\n![scrapeless](https://www.scrapeless.com/_next/image?url=%2Fassets%2Fimages%2Fregulate-compliance.png&w=640&q=75)\n\n## Web Scraping Blog\n\nMost comprehensive guide, created for all Web Scraping developers.\n\n[View All Blogs](https://www.scrapeless.com/en/blog)\n\n[**Scrapeless MCP Server Is Officially Live! Build Your Ultimate AI-Web Connector** \\\\\n\\\\\nDiscover how the Scrapeless MCP Server gives LLMs real-time web browsing and scraping abilities. Learn how to build AI agents that search, extract, and interact with dynamic web content seamlessly.\\\\\n\\\\\n![Michael Lee](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fimages%2Fauthor-avatars%2Fmichael-lee.png&w=48&q=75)Michael Lee\\\\\n\\\\\n17-Jul-2025\\\\\n\\\\\n![Scrapeless MCP Server](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fposts%2Fscrapeless-mcp-server%2Fc85738fc1c504abe930fd4514e4a2190.jpeg&w=3840&q=75)](https://www.scrapeless.com/en/blog/scrapeless-mcp-server) [**Product Updates \\| New Profile Feature** \\\\\n\\\\\nProduct Updates \\| Introducing the new Profile feature to enable persistent browser data storage, streamline cross-session workflows, and boost automation efficiency.\\\\\n\\\\\n![Emily Chen](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fimages%2Fauthor-avatars%2Femily-chen.png&w=48&q=75)Emily Chen\\\\\n\\\\\n17-Jul-2025\\\\\n\\\\\n![Product Updates | New Profile Feature: Make Browser Data Persistent, Efficient, and Controllable](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fposts%2Fscrapeelss-profile%2F3194244c16c9b56e1592640ea95c389e.jpeg&w=3840&q=75)](https://www.scrapeless.com/en/blog/scrapeelss-profile) [**How to Track Your Ranking on ChatGPT?** \\\\\n\\\\\nLearn why traditional SEO tools fall short and how Scrapeless helps you monitor and optimize your AI rankings effortlessly.\\\\\n\\\\\n![Michael Lee](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fimages%2Fauthor-avatars%2Fmichael-lee.png&w=48&q=75)Michael Lee\\\\\n\\\\\n01-Jul-2025\\\\\n\\\\\n![ChatGPT Scraper](https://www.scrapeless.com/_next/image?url=https%3A%2F%2Fassets.scrapeless.com%2Fprod%2Fposts%2Fchatgpt-scraper%2F7c5b1ac494b6838a7eca2964df15ef59.png&w=3840&q=75)](https://www.scrapeless.com/en/blog/chatgpt-scraper)\n\nContact our sales team\n\nMonday to Friday, 9:00 AM - 18:00 PMSingapore Standard Time (UTC+08:00)\n\nScrapeless offers AI-powered, robust, and scalable web scraping and automation services trusted by leading enterprises. Our enterprise-grade solutions are tailored to meet your project needs, with dedicated technical support throughout. With a strong technical team and flexible delivery times, we charge only for successful data, enabling efficient data extraction while bypassing limitations.\n\nContact us now to fuel your business growth.\n\n[**4.8**](https://www.g2.com/products/scrapeless/reviews) [**4.5**](https://www.trustpilot.com/review/scrapeless.com) [**4.8**](https://slashdot.org/software/p/Scrapeless/) [**8.5**](https://tekpon.com/software/scrapeless/reviews/)\n\nBook a demo\n\nProvide your contact details, and we'll promptly reach out to offer a product demo and introduction. We ensure your information remains confidential, complying with GDPR standards.\n\nGet a demo\n\nRegister and Claim Free Trial\n\nYour free trial is ready! Sign up for a Scrapeless account for free, and your trial will be instantly activated in your account.\n\n[Sign up](https://app.scrapeless.com/passport/register)\n\nWe value your privacy\n\nWe use cookies to analyze website usage and do not record any of your personal information. View [Privacy Policy](https://www.scrapeless.com/en/legal/privacy-policy)\n\nReject\n\nAccept", 'metadata': {'language': 'en', 'description': 'Scrapeless is the best full-stack web scraping toolkit offering Scraping API, Scraping Browser, Universal Scraping API, Captcha Solver, and Proxies, designed to handle all your data collection needs with ease and reliability, empowering businesses and developers with efficient data extraction solutions.', 'google-site-verification': 'xj1xDpU8LpGG_h-2lIBVW_6GNW5Vtx0h5M3lz43HUXc', 'viewport': 'width=device-width, initial-scale=1', 'keywords': 'Scraping API, Scraping Browser, Universal Scraping API, Captcha Solver, and Proxies, web scraping,  web scraper, web scraping api, Web scraper,data scraping, web crawler', 'next-size-adjust': '', 'favicon': 'https://www.scrapeless.com/favicon.ico', 'title': 'Effortless Web Scraping Toolkit - Scrapeless', 'scrapeId': 'c7189211-7034-4e86-9afd-89fa5268b013', 'sourceURL': 'https://www.scrapeless.com/en', 'url': 'https://www.scrapeless.com/en', 'statusCode': 200}}]}
```

#### Use within an agent

```python
from langchain_openai import ChatOpenAI
from langchain_scrapeless import ScrapelessCrawlerScrapeTool
from langchain.agents import create_agent


model = ChatOpenAI()

tool = ScrapelessCrawlerScrapeTool()

# Use the tool with an agent
tools = [tool]
agent = create_agent(model, tools)

for chunk in agent.stream(
    {
        "messages": [
            (
                "human",
                "Use the scrapeless crawler scrape tool to get the website content of https://example.com and output the html content as a string.",
            )
        ]
    },
    stream_mode="values",
):
    chunk["messages"][-1].pretty_print()
```

```output
================================ Human Message =================================

Use the scrapeless crawler scrape tool to get the website content of https://example.com and output the html content as a string.
================================== Ai Message ==================================
Tool Calls:
  scrapeless_crawler_scrape (call_qrPMGLjXmzb5QlVoIZgMuyPN)
 Call ID: call_qrPMGLjXmzb5QlVoIZgMuyPN
  Args:
    urls: ['https://example.com']
    formats: ['html']
================================= Tool Message =================================
Name: scrapeless_crawler_scrape

{"success": true, "status": "completed", "completed": 1, "total": 1, "data": [{"metadata": {"viewport": "width=device-width, initial-scale=1", "title": "Example Domain", "scrapeId": "63070ee5-ebef-4727-afe7-2b06466c6777", "sourceURL": "https://example.com", "url": "https://example.com", "statusCode": 200}, "html": "<!DOCTYPE html><html>\n\n<body>\n<div>\n    <h1>Example Domain</h1>\n    <p>This domain is for use in illustrative examples in documents. You may use this\n    domain in literature without prior coordination or asking for permission.</p>\n    <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n</div>\n\n\n<div id=\"div-f3t6fv31hyl\" style=\"display: none;\"></div></body></html>"}]}
================================== Ai Message ==================================

The HTML content of the website "https://example.com" is as follows:

\`\`\`html
<!DOCTYPE html><html>
<body>
<div>
    <h1>Example Domain</h1>
    <p>This domain is for use in illustrative examples in documents. You may use this
    domain in literature without prior coordination or asking for permission.</p>
    <p><a href="https://www.iana.org/domains/example">More information...</a></p>
</div>

<div id="div-f3t6fv31hyl" style="display: none;"></div></body></html>
\`\`\`
```

## API reference

- [Scrapeless Documentation](https://docs.scrapeless.com/en/crawl/quickstart/introduction/)
- [Scrapeless API Reference](https://apidocs.scrapeless.com/api-17509003)