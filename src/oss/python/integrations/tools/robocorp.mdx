---
title: Robocorp Toolkit
---

이 노트북은 [Robocorp Action Server](https://github.com/robocorp/robocorp) action toolkit과 LangChain을 시작하는 방법을 다룹니다.

Robocorp은 custom action을 사용하여 AI agent, assistant 및 copilot의 기능을 확장하는 가장 쉬운 방법입니다.

## 설치

먼저, `Action Server`를 설정하고 Action을 생성하는 방법은 [Robocorp Quickstart](https://github.com/robocorp/robocorp#quickstart)를 참조하세요.

LangChain 애플리케이션에서 `langchain-robocorp` 패키지를 설치합니다:

```python
# Install package
pip install -qU langchain-robocorp
```

위의 quickstart를 따라 새로운 `Action Server`를 생성하면,

`action.py`를 포함한 파일들이 있는 디렉토리가 생성됩니다.

[여기](https://github.com/robocorp/robocorp/tree/master/actions#describe-your-action)에 표시된 대로 python 함수를 action으로 추가할 수 있습니다.

`action.py`에 더미 함수를 추가해 보겠습니다.

```python
@action
def get_weather_forecast(city: str, days: int, scale: str = "celsius") -> str:
    """
    Returns weather conditions forecast for a given city.

    Args:
        city (str): Target city to get the weather conditions for
        days: How many day forecast to return
        scale (str): Temperature scale to use, should be one of "celsius" or "fahrenheit"

    Returns:
        str: The requested weather conditions forecast
    """
    return "75F and sunny :)"
```

그런 다음 서버를 시작합니다:

```bash
action-server start
```

그러면 다음과 같이 표시됩니다:

```
Found new action: get_weather_forecast

```

`http://localhost:8080`에서 실행 중인 서버로 이동하여 UI를 사용해 함수를 실행하여 로컬에서 테스트합니다.

## 환경 설정

선택적으로 다음 환경 변수를 설정할 수 있습니다:

- `LANGSMITH_TRACING=true`: 각 Action Server action 실행 로그에 바인딩할 수 있는 LangSmith 로그 실행 추적을 활성화합니다. 자세한 내용은 [LangSmith documentation](https://docs.smith.langchain.com/tracing#log-runs)을 참조하세요.

## 사용법

위에서 `http://localhost:8080`에서 실행되는 로컬 action server를 시작했습니다.

```python
from langchain.agents import AgentExecutor, OpenAIFunctionsAgent
from langchain.messages import SystemMessage
from langchain_openai import ChatOpenAI
from langchain_robocorp import ActionServerToolkit

# Initialize LLM chat model
llm = ChatOpenAI(model="gpt-4", temperature=0)

# Initialize Action Server Toolkit
toolkit = ActionServerToolkit(url="http://localhost:8080", report_trace=True)
tools = toolkit.get_tools()

# Initialize Agent
system_message = SystemMessage(content="You are a helpful assistant")
prompt = OpenAIFunctionsAgent.create_prompt(system_message)
agent = OpenAIFunctionsAgent(llm=llm, prompt=prompt, tools=tools)

executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

executor.invoke("What is the current weather today in San Francisco in fahrenheit?")
```

```output
> Entering new AgentExecutor chain...

Invoking: `robocorp_action_server_get_weather_forecast` with `{'city': 'San Francisco', 'days': 1, 'scale': 'fahrenheit'}`


"75F and sunny :)"The current weather today in San Francisco is 75F and sunny.

> Finished chain.
```

```output
{'input': 'What is the current weather today in San Francisco in fahrenheit?',
 'output': 'The current weather today in San Francisco is 75F and sunny.'}
```

### Single input tools

기본적으로 `toolkit.get_tools()`는 action을 Structured Tools로 반환합니다.

single input tool을 반환하려면 입력 처리에 사용할 Chat model을 전달하세요.

```python
# Initialize single input Action Server Toolkit
toolkit = ActionServerToolkit(url="http://localhost:8080")
tools = toolkit.get_tools(llm=llm)
```