---
title: Runtime
---



## 개요

:::python
LangChain의 @[`create_agent`]는 내부적으로 LangGraph의 runtime에서 실행됩니다.
:::
:::js
LangChain의 `createAgent`는 내부적으로 LangGraph의 runtime에서 실행됩니다.
:::
LangGraph는 다음 정보를 포함하는 @[`Runtime`] 객체를 제공합니다:

1. **Context**: 사용자 ID, 데이터베이스 연결 또는 에이전트 호출을 위한 기타 종속성과 같은 정적 정보
2. **Store**: [장기 메모리](/oss/langchain/long-term-memory)에 사용되는 @[BaseStore] 인스턴스
3. **Stream writer**: `"custom"` stream mode를 통해 정보를 스트리밍하는 데 사용되는 객체

[도구](#inside-tools) 및 [미들웨어](#inside-middleware) 내에서 runtime 정보에 액세스할 수 있습니다.

## 액세스

:::python
@[`create_agent`]로 에이전트를 생성할 때, `context_schema`를 지정하여 에이전트 @[`Runtime`]에 저장된 `context`의 구조를 정의할 수 있습니다.
:::
:::js
`createAgent`로 에이전트를 생성할 때, `contextSchema`를 지정하여 에이전트 @[`Runtime`]에 저장된 `context`의 구조를 정의할 수 있습니다.
:::

에이전트를 호출할 때, 실행에 필요한 구성과 함께 `context` 인수를 전달합니다:

:::python
```python
from dataclasses import dataclass

from langchain.agents import create_agent


@dataclass
class Context:
    user_name: str

agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[...],
    context_schema=Context  # [!code highlight]
)

agent.invoke(
    {"messages": [{"role": "user", "content": "What's my name?"}]},
    context=Context(user_name="John Smith")  # [!code highlight]
)
```
:::
:::js
```ts
import * as z from "zod";
import { createAgent } from "langchain";

const contextSchema = z.object({ // [!code highlight]
  userName: z.string(), // [!code highlight]
}); // [!code highlight]

const agent = createAgent({
  model: "openai:gpt-4o",
  tools: [
    /* ... */
  ],
  contextSchema, // [!code highlight]
});

const result = await agent.invoke(
  { messages: [{ role: "user", content: "What's my name?" }] },
  { context: { userName: "John Smith" } } // [!code highlight]
);
```
:::

### 도구 내부

도구 내부에서 runtime 정보에 액세스하여 다음을 수행할 수 있습니다:

* context에 액세스
* 장기 메모리 읽기 또는 쓰기
* [custom stream](/oss/langchain/streaming#custom-updates)에 쓰기 (예: 도구 진행 상황 / 업데이트)

:::python
`ToolRuntime` 매개변수를 사용하여 도구 내부에서 @[`Runtime`] 객체에 액세스합니다.

```python
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime  # [!code highlight]

@dataclass
class Context:
    user_id: str

@tool
def fetch_user_email_preferences(runtime: ToolRuntime[Context]) -> str:  # [!code highlight]
    """Fetch the user's email preferences from the store."""
    user_id = runtime.context.user_id  # [!code highlight]

    preferences: str = "The user prefers you to write a brief and polite email."
    if runtime.store:  # [!code highlight]
        if memory := runtime.store.get(("users",), user_id):  # [!code highlight]
            preferences = memory.value["preferences"]

    return preferences
```
:::
:::js
`runtime` 매개변수를 사용하여 도구 내부에서 @[`Runtime`] 객체에 액세스합니다.

```ts
import * as z from "zod";
import { tool } from "langchain";
import { type Runtime } from "@langchain/langgraph"; // [!code highlight]

const contextSchema = z.object({
  userName: z.string(),
});

const fetchUserEmailPreferences = tool(
  async (_, runtime: Runtime<z.infer<typeof contextSchema>>) => { // [!code highlight]
    const userName = runtime.context?.userName; // [!code highlight]
    if (!userName) {
      throw new Error("userName is required");
    }

    let preferences = "The user prefers you to write a brief and polite email.";
    if (runtime.store) { // [!code highlight]
      const memory = await runtime.store?.get(["users"], userName); // [!code highlight]
      if (memory) {
        preferences = memory.value.preferences;
      }
    }
    return preferences;
  },
  {
    name: "fetch_user_email_preferences",
    description: "Fetch the user's email preferences.",
    schema: z.object({}),
  }
);
```
:::

### 미들웨어 내부

미들웨어에서 runtime 정보에 액세스하여 동적 프롬프트를 생성하거나, 메시지를 수정하거나, 사용자 context를 기반으로 에이전트 동작을 제어할 수 있습니다.

:::python
`request.runtime`을 사용하여 미들웨어 데코레이터 내부에서 @[`Runtime`] 객체에 액세스합니다. runtime 객체는 미들웨어 함수에 전달되는 @[`ModelRequest`] 매개변수에서 사용할 수 있습니다.

```python
from dataclasses import dataclass

from langchain.messages import AnyMessage
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import dynamic_prompt, ModelRequest, before_model, after_model
from langgraph.runtime import Runtime


@dataclass
class Context:
    user_name: str

# Dynamic prompts
@dynamic_prompt
def dynamic_system_prompt(request: ModelRequest) -> str:
    user_name = request.runtime.context.user_name  # [!code highlight]
    system_prompt = f"You are a helpful assistant. Address the user as {user_name}."
    return system_prompt

# Before model hook
@before_model
def log_before_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  # [!code highlight]
    print(f"Processing request for user: {runtime.context.user_name}")  # [!code highlight]
    return None

# After model hook
@after_model
def log_after_model(state: AgentState, runtime: Runtime[Context]) -> dict | None:  # [!code highlight]
    print(f"Completed request for user: {runtime.context.user_name}")  # [!code highlight]
    return None

agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[...],
    middleware=[dynamic_system_prompt, log_before_model, log_after_model],  # [!code highlight]
    context_schema=Context
)

agent.invoke(
    {"messages": [{"role": "user", "content": "What's my name?"}]},
    context=Context(user_name="John Smith")
)
```
:::
:::js
`runtime` 매개변수를 사용하여 미들웨어 내부에서 @[`Runtime`] 객체에 액세스합니다.

```ts
import * as z from "zod";
import { createAgent, createMiddleware, type AgentState, SystemMessage } from "langchain";
import { type Runtime } from "@langchain/langgraph"; // [!code highlight]

const contextSchema = z.object({
  userName: z.string(),
});

// Dynamic prompt middleware
const dynamicPromptMiddleware = createMiddleware({
  name: "DynamicPrompt",
  beforeModel: (state: AgentState, runtime: Runtime<z.infer<typeof contextSchema>>) => {  // [!code highlight]
    const userName = runtime.context?.userName;  // [!code highlight]
    if (!userName) {
      throw new Error("userName is required");
    }

    const systemMsg = `You are a helpful assistant. Address the user as ${userName}.`;
    return {
      messages: [new SystemMessage(systemMsg), ...state.messages]
    };
  }
});

// Logging middleware
const loggingMiddleware = createMiddleware({
  name: "Logging",
  beforeModel: (state: AgentState, runtime: Runtime<z.infer<typeof contextSchema>>) => {  // [!code highlight]
    console.log(`Processing request for user: ${runtime.context?.userName}`);  // [!code highlight]
    return;
  },
  afterModel: (state: AgentState, runtime: Runtime<z.infer<typeof contextSchema>>) => {  // [!code highlight]
    console.log(`Completed request for user: ${runtime.context?.userName}`);  // [!code highlight]
    return;
  }
});

const agent = createAgent({
  model: "openai:gpt-4o",
  tools: [
    /* ... */
  ],
  middleware: [dynamicPromptMiddleware, loggingMiddleware],  // [!code highlight]
  contextSchema,
});

const result = await agent.invoke(
  { messages: [{ role: "user", content: "What's my name?" }] },
  { context: { userName: "John Smith" } }
);
```
:::