---
title: Datadog LLM Observability
---

<Warning>
LLM Observability는 공개 베타 버전이며, API는 변경될 수 있습니다.
</Warning>

[Datadog LLM Observability](https://docs.datadoghq.com/llm_observability/)를 사용하면 챗봇과 같은 LLM 기반 애플리케이션을 모니터링하고, 문제를 해결하며, 평가할 수 있습니다. 문제의 근본 원인을 조사하고, 운영 성능을 모니터링하며, LLM 애플리케이션의 품질, 개인정보 보호 및 안전성을 평가할 수 있습니다.

이것은 실험적인 커뮤니티 구현이며, Datadog에서 공식적으로 지원하지 않습니다. [Datadog LLM Observability API](https://docs.datadoghq.com/llm_observability/api)를 기반으로 합니다.

## Setup

<Tip>
LangChain 패키지 설치에 대한 일반적인 지침은 [이 섹션](/oss/langchain/install)을 참조하세요.
</Tip>

```bash npm
npm install @langchain/community @langchain/core
```

## Usage

```typescript
import { OpenAI } from "@langchain/openai";
import { DatadogLLMObsTracer } from "@langchain/community/experimental/callbacks/handlers/datadog";

/**
 * This example demonstrates how to use the DatadogLLMObsTracer with the OpenAI model.
 * It will produce a "llm" span with the input and output of the model inside the meta field.
 *
 * To run this example, you need to have a valid Datadog API key and OpenAI API key.
 */
export const run = async () => {
  const model = new OpenAI({
    model: "gpt-4",
    temperature: 0.7,
    maxTokens: 1000,
    maxRetries: 5,
  });

  const res = await model.invoke(
    "Question: What would be a good company name a company that makes colorful socks?\nAnswer:",
    {
      callbacks: [
        new DatadogLLMObsTracer({
          mlApp: "my-ml-app",
        }),
      ],
    }
  );

  console.log({ res });
};
```