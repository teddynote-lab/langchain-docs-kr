---
title: ChatTencentHunyuan
---

LangChain.js는 Tencent Hunyuan 모델 제품군을 지원합니다.

https://cloud.tencent.com/document/product/1729/104753

## Setup

1. [여기](https://cloud.tencent.com/register)에서 Tencent Cloud 계정에 가입하세요.
2. [여기](https://console.cloud.tencent.com/cam/capi)에서 SecretID와 SecretKey를 생성하세요.
3. SecretID와 SecretKey를 각각 `TENCENT_SECRET_ID`와 `TENCENT_SECRET_KEY`라는 이름의 환경 변수로 설정하세요.

<Tip>
LangChain 패키지 설치에 대한 일반적인 지침은 [이 섹션](/oss/langchain/install)을 참조하세요.
</Tip>

```bash npm
npm install @langchain/community @langchain/core
```
브라우저 환경에서 LangChain.js를 사용하는 경우, 다음 종속성도 설치해야 합니다:

```bash npm
npm install crypto-js
```

그런 다음 아래와 같이 `web`에서 import하는지 확인하세요.

## Usage

다음은 예제입니다:

```typescript
// in nodejs environment
import { ChatTencentHunyuan } from "@langchain/community/chat_models/tencent_hunyuan";

// in browser environment
// import { ChatTencentHunyuan } from "@langchain/community/chat_models/tencent_hunyuan/web";

import { HumanMessage } from "@langchain/core/messages";
import type { LLMResult } from "@langchain/core/outputs";

const messages = [new HumanMessage("Hello")];

// Default model is hunyuan-pro
const hunyuanPro = new ChatTencentHunyuan({
  streaming: false,
  temperature: 1,
});

let res = await hunyuanPro.invoke(messages);
console.log(res);
/*
AIMessage {
  content: 'Hello! How can I help you today?Is there anything I can do for you?',
  name: undefined,
  additional_kwargs: {},
  response_metadata: {
    tokenUsage: { totalTokens: 20, promptTokens: 1, completionTokens: 19 }
  },
  tool_calls: [],
  invalid_tool_calls: []
}
*/

// Use hunyuan-lite
const hunyuanLite = new ChatTencentHunyuan({
  model: "hunyuan-lite",
  streaming: false,
});

res = await hunyuanLite.invoke(messages);
console.log(res);
/*
AIMessage {
  content: '你好！很高兴为你提供服务~有什么我可以帮助你的吗？',
  name: undefined,
  additional_kwargs: {},
  response_metadata: {
    tokenUsage: { totalTokens: 14, promptTokens: 1, completionTokens: 13 }
  },
  tool_calls: [],
  invalid_tool_calls: []
}
*/

// Use hunyuan-lite with streaming
const hunyuanLiteStream = new ChatTencentHunyuan({
  model: "hunyuan-lite",
  streaming: true,
  temperature: 1,
});

hunyuanLiteStream.invoke(messages, {
  callbacks: [
    {
      handleLLMEnd(output: LLMResult) {
        console.log(output);
        /*
        {
          generations: [
            [
              [Object], [Object],
              [Object], [Object],
              [Object], [Object],
              [Object], [Object],
              [Object]
            ]
          ],
          llmOutput: {
            tokenUsage: { totalTokens: 9, promptTokens: 1, completionTokens: 8 }
          }
        }
      */
      },
      handleLLMNewToken(token: string) {
        console.log(`token: ${token}`);
        /*
        token: 你好
        token: ！
        token: 很高兴
        token: 能
        token: 为您
        token: 解答
        token: 问题
        token: 和建议
        token: 方案
        token: .
        token:  如果您
        token: 有其他
        token: 需要帮助
        token: 的地方
        token: ,
        token:
        token: 随时
        token: 告诉我
        token: 哦
        token: ~
        token:
        */
      },
    },
  ],
});
```

## Related

- Chat model [개념 가이드](/oss/langchain/models)
- Chat model [사용 방법 가이드](/oss/langchain/models)
```