---
title: ChatCerebras
---

[Cerebras](https://cerebras.ai/)는 속도를 강조하여 오픈 소스 모델을 제공하는 모델 제공업체입니다. Wafer-Scale Engine-3(WSE-3)로 구동되는 Cerebras CS-3 시스템은 비교할 수 없는 성능과 확장성으로 생성형 AI 학습 및 추론의 표준을 설정하는 새로운 클래스의 AI 슈퍼컴퓨터를 나타냅니다.

Cerebras를 추론 제공업체로 사용하면 다음을 수행할 수 있습니다:

- AI 추론 워크로드에 대한 전례 없는 속도 달성
- 높은 처리량으로 상업적 구축
- 원활한 클러스터링 기술로 AI 워크로드를 손쉽게 확장

우리의 CS-3 시스템은 빠르고 쉽게 클러스터링되어 세계에서 가장 큰 AI 슈퍼컴퓨터를 만들 수 있으며, 가장 큰 모델을 배치하고 실행하는 것을 간단하게 만듭니다. 선도적인 기업, 연구 기관 및 정부는 이미 Cerebras 솔루션을 사용하여 독점 모델을 개발하고 인기 있는 오픈 소스 모델을 학습하고 있습니다.

이 문서는 ChatCerebras [chat models](/oss/langchain/models) 시작하는 데 도움이 됩니다. 모든 ChatCerebras 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/_langchain_cerebras.ChatCerebras.html)를 참조하세요.

## Overview

### Integration details

| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/chat/cerebras) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [ChatCerebras](https://api.js.langchain.com/classes/langchain_cerebras.ChatCerebras.html) | [`@langchain/cerebras`](https://www.npmjs.com/package/@langchain/cerebras) | ❌ | ❌ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/cerebras?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/cerebras?style=flat-square&label=%20&) |

### Model features

특정 기능을 사용하는 방법에 대한 가이드는 아래 표 헤더의 링크를 참조하세요.

| [Tool calling](/oss/langchain/tools) | [Structured output](/oss/langchain/structured-output) | JSON mode | [Image input](/oss/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/langchain/streaming/) | [Token usage](/oss/langchain/models#token-usage) | [Logprobs](/oss/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ❌ | ❌ | ❌ | ✅ | ✅ | ❌ |

## Setup

ChatCerebras 모델에 액세스하려면 Cerebras 계정을 생성하고 API 키를 받은 다음 `@langchain/cerebras` 통합 패키지를 설치해야 합니다.

### Credentials

[cloud.cerebras.ai](https://cloud.cerebras.ai)에서 API Key를 받아 환경 변수에 추가하세요:

```bash
export CEREBRAS_API_KEY="your-api-key"
```

모델 호출에 대한 자동 추적을 원하면 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정할 수도 있습니다:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

LangChain ChatCerebras 통합은 `@langchain/cerebras` 패키지에 있습니다:

<CodeGroup>
```bash npm
npm install @langchain/cerebras @langchain/core
```
```bash yarn
yarn add @langchain/cerebras @langchain/core
```
```bash pnpm
pnpm add @langchain/cerebras @langchain/core
```
</CodeGroup>

## Instantiation

이제 모델 객체를 인스턴스화하고 채팅 완성을 생성할 수 있습니다:

```typescript
import { ChatCerebras } from "@langchain/cerebras"

const llm = new ChatCerebras({
    model: "llama-3.3-70b",
    temperature: 0,
    maxTokens: undefined,
    maxRetries: 2,
    // other params...
})
```

## Invocation

```typescript
const aiMsg = await llm.invoke([
    {
      role: "system",
      content: "You are a helpful assistant that translates English to French. Translate the user sentence.",
    },
    { role: "user", content: "I love programming." },
])
aiMsg
```

```output
AIMessage {
  "id": "run-17c7d62d-67ac-4677-b33a-18298fc85e35",
  "content": "J'adore la programmation.",
  "additional_kwargs": {},
  "response_metadata": {
    "id": "chatcmpl-2d1e2de5-4239-46fb-af2a-6200d89d7dde",
    "created": 1735785598,
    "model": "llama-3.3-70b",
    "system_fingerprint": "fp_2e2a2a083c",
    "object": "chat.completion",
    "time_info": {
      "queue_time": 0.00009063,
      "prompt_time": 0.002163031,
      "completion_time": 0.012339628,
      "total_time": 0.01640915870666504,
      "created": 1735785598
    }
  },
  "tool_calls": [],
  "invalid_tool_calls": [],
  "usage_metadata": {
    "input_tokens": 55,
    "output_tokens": 9,
    "total_tokens": 64
  }
}
```

```typescript
console.log(aiMsg.content)
```

```output
J'adore la programmation.
```

## Json invocation

```typescript
const messages = [
  {
    role: "system",
    content: "You are a math tutor that handles math exercises and makes output in json in format { result: number }.",
  },
  { role: "user",  content: "2 + 2" },
];

const aiInvokeMsg = await llm.invoke(messages, { response_format: { type: "json_object" } });

// if you want not to pass response_format in every invoke, you can bind it to the instance
const llmWithResponseFormat = llm.bind({ response_format: { type: "json_object" } });
const aiBindMsg = await llmWithResponseFormat.invoke(messages);

// they are the same
console.log({ aiInvokeMsgContent: aiInvokeMsg.content, aiBindMsg: aiBindMsg.content });
```

```output
{ aiInvokeMsgContent: '{"result":4}', aiBindMsg: '{"result":4}' }
```

## API reference

모든 ChatCerebras 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/_langchain_cerebras.ChatCerebras.html)를 참조하세요.