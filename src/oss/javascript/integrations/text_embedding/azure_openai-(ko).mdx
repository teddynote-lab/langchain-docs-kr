---
title: AzureOpenAIEmbeddings
---

[Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service/)는 OpenAI, Meta 등에서 제공하는 다양한 사전 빌드·큐레이션된 모델로 생성형 AI 경험을 빠르게 개발할 수 있도록 돕는 클라우드 서비스입니다.

LangChain.js는 [OpenAI SDK](https://github.com/openai/openai-node)의 새로운 Azure 통합을 사용하여 [Azure OpenAI](https://azure.microsoft.com/products/ai-services/openai-service/)와의 통합을 지원합니다.

Azure OpenAI와 OpenAI API의 차이에 대해서는 [이 페이지](https://learn.microsoft.com/azure/ai-services/openai/overview)에서 더 알아보세요. Azure 계정이 없다면 [무료 계정 만들기](https://azure.microsoft.com/free/)로 시작할 수 있습니다.

이 문서는 LangChain을 사용해 AzureOpenAIEmbeddings [embedding models](/oss/integrations/text_embedding)을 시작하는 데 도움을 줍니다. `AzureOpenAIEmbeddings`의 기능과 설정 옵션에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_openai.AzureOpenAIEmbeddings.html)를 참고하세요.


<Info>
**이전에는 LangChain.js가 전용 [Azure OpenAI SDK](https://github.com/Azure/azure-sdk-for-js/tree/main/sdk/openai/openai)를 통해 Azure OpenAI 통합을 지원했습니다. 해당 SDK는 이제 더 이상 사용되지 않으며, OpenAI SDK의 새로운 Azure 통합이 권장됩니다. 이를 통해 최신 OpenAI 모델과 기능을 출시 당일에 바로 사용하고, OpenAI API와 Azure OpenAI 간에 원활히 전환할 수 있습니다.**


더 이상 사용되지 않는 SDK로 Azure OpenAI를 사용 중이라면, 새로운 API로 업데이트하기 위해 [migration guide](#migration-from-azure-openai-sdk)를 확인하세요.

</Info>


## 개요

### 통합 세부 정보

| 클래스 | 패키지 | 로컬 | [Python 지원](https://python.langchain.com/docs/integrations/text_embedding/azure_openai/) | 다운로드 | 버전 |
| :--- | :--- | :---: | :---: |  :---: | :---: |
| [AzureOpenAIEmbeddings](https://api.js.langchain.com/classes/langchain_openai.AzureOpenAIEmbeddings.html) | [@langchain/openai](https://api.js.langchain.com/modules/langchain_openai.html) | ❌ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/openai?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/openai?style=flat-square&label=%20&) |

## 설정

Azure OpenAI embedding 모델에 접근하려면 Azure 계정을 만들고, API 키를 발급받고, `@langchain/openai` 통합 패키지를 설치해야 합니다.

### 자격 증명

Azure OpenAI 인스턴스가 배포되어 있어야 합니다. [이 가이드](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource?pivots=web-portal)를 따라 Azure Portal에서 인스턴스를 배포할 수 있습니다.

인스턴스가 실행 중이면 인스턴스 이름과 키를 준비하세요. 키는 Azure Portal의 인스턴스 "Keys and Endpoint" 섹션에서 확인할 수 있습니다.

Node.js를 사용하는 경우, 아래 환경 변수를 정의해 서비스를 사용할 수 있습니다:

```bash
AZURE_OPENAI_API_INSTANCE_NAME=<YOUR_INSTANCE_NAME>
AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=<YOUR_EMBEDDINGS_DEPLOYMENT_NAME>
AZURE_OPENAI_API_KEY=<YOUR_KEY>
AZURE_OPENAI_API_VERSION="2024-02-01"
```

모델 호출의 자동 추적을 원한다면 아래의 주석을 해제하고 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정할 수도 있습니다:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### 설치

LangChain의 AzureOpenAIEmbeddings 통합은 `@langchain/openai` 패키지에 포함되어 있습니다:

<CodeGroup>
```bash npm
npm install @langchain/openai @langchain/core
```
```bash yarn
yarn add @langchain/openai @langchain/core
```
```bash pnpm
pnpm add @langchain/openai @langchain/core
```
</CodeGroup>


<Info>
**지원되는 API 버전 목록은 [Azure OpenAI 문서](https://learn.microsoft.com/azure/ai-services/openai/reference)에서 확인할 수 있습니다.**


</Info>

<Tip>
**`AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME`이 정의되지 않은 경우, 배포 이름으로 `AZURE_OPENAI_API_DEPLOYMENT_NAME` 값을 사용합니다. `AzureOpenAIEmbeddings` 생성자의 `azureOpenAIApiEmbeddingsDeploymentName` 파라미터도 동일하게 동작하며, 정의되지 않으면 `azureOpenAIApiDeploymentName` 값으로 대체됩니다.**


</Tip>

```

## Instantiation

Now we can instantiate our model object and embed text:

```typescript
// Azure OpenAI Embeddings 클라이언트 생성 예시
// 각 옵션은 Node.js 환경에서 대응하는 환경 변수 기본값을 사용합니다.
import { AzureOpenAIEmbeddings } from "@langchain/openai";

const embeddings = new AzureOpenAIEmbeddings({
  azureOpenAIApiKey: "<your_key>", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY
  azureOpenAIApiInstanceName: "<your_instance_name>", // In Node.js defaults to process.env.AZURE_OPENAI_API_INSTANCE_NAME
  azureOpenAIApiEmbeddingsDeploymentName: "<your_embeddings_deployment_name>", // In Node.js defaults to process.env.AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME
  azureOpenAIApiVersion: "<api_version>", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION
  maxRetries: 1,
});
```

## Indexing and Retrieval

Embedding models are often used in retrieval-augmented generation (RAG) flows, both as part of indexing data as well as later retrieving it. For more detailed instructions, please see our RAG tutorials under the [**Learn** tab](/oss/learn/).

Below, see how to index and retrieve data using the `embeddings` object we initialized above. In this example, we will index and retrieve a sample document using the demo [`MemoryVectorStore`](/oss/integrations/vectorstores/memory).

```typescript
// 샘플 텍스트로 Vector Store 생성
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";

const text = "LangChain is the framework for building context-aware reasoning applications";

const vectorstore = await MemoryVectorStore.fromDocuments(
  [{ pageContent: text, metadata: {} }],
  embeddings,
);

// 단일 문서를 반환하도록 Retriever 구성
const retriever = vectorstore.asRetriever(1);

// 가장 유사한 텍스트 검색
const retrievedDocuments = await retriever.invoke("What is LangChain?");

retrievedDocuments[0].pageContent;
```

```output
LangChain is the framework for building context-aware reasoning applications
```

## Direct Usage

Under the hood, the vectorstore and retriever implementations are calling `embeddings.embedDocument(...)` and `embeddings.embedQuery(...)` to create embeddings for the text(s) used in `fromDocuments` and the retriever's `invoke` operations, respectively.

You can directly call these methods to get embeddings for your own use cases.

### Embed single texts

You can embed queries for search with `embedQuery`. This generates a vector representation specific to the query:

```typescript
// 단일 쿼리 텍스트를 embedding 벡터로 변환
const singleVector = await embeddings.embedQuery(text);

console.log(singleVector.slice(0, 100));
```

```output
[
   -0.024253517, -0.0054218727,   0.048715446,   0.020580322,    0.03180832,
   0.0028770117,  -0.012367731,   0.037383243,  -0.054915592,   0.032225136,
     0.00825818,  -0.023888804,   -0.01184671,   0.012257014,   0.016294925,
    0.009254632,  0.0051353113,  -0.008889917,   0.016855022,    0.04207243,
  0.00082589936,  -0.011664353,    0.00818654,   0.029020859,  -0.012335167,
   -0.019603407,  0.0013945447,    0.05538451,  -0.011625277,  -0.008153976,
    0.038607642,   -0.03811267, -0.0074440846,   0.047647353,   -0.00927417,
    0.024201415, -0.0069230637,  -0.008538228,   0.003910912,   0.052805457,
   -0.023159374,  0.0014352495,  -0.038659744,   0.017141584,   0.005587948,
    0.007971618,  -0.016920151,    0.06658646, -0.0016916894,   0.045667473,
   -0.042202685,   -0.03983204,   -0.04160351,  -0.011729481,  -0.055905532,
    0.012543576,  0.0038848612,   0.007919516,   0.010915386,  0.0033117384,
   -0.007548289,  -0.030427614,  -0.041890074,   0.036002535,  -0.023771575,
   -0.008792226,  -0.049444873,   0.016490309, -0.0060568666,   0.040196754,
    0.014106638,  -0.014575557, -0.0017356506,  -0.011234511,  -0.012517525,
    0.008362384,    0.01253055,   0.036158845,   0.008297256, -0.0010908874,
   -0.014888169,  -0.020489143,   0.018965157,  -0.057937514, -0.0037122732,
    0.004402626,   -0.00840146,   0.042984217,   -0.04936672,   -0.03714878,
    0.004969236,    0.03707063,   0.015396165,   -0.02055427,    0.01988997,
    0.030219207,  -0.021257648,    0.01340326,   0.003692735,   0.012595678
]
```

### Embed multiple texts

You can embed multiple texts for indexing with `embedDocuments`. The internals used for this method may (but do not have to) differ from embedding queries:

```typescript
// 여러 문서를 embedding 벡터로 변환
const text2 = "LangGraph is a library for building stateful, multi-actor applications with LLMs";

const vectors = await embeddings.embedDocuments([text, text2]);

// 각 문서의 벡터 일부 미리보기
console.log(vectors[0].slice(0, 100));
console.log(vectors[1].slice(0, 100));
```

```output
[
   -0.024253517, -0.0054218727,   0.048715446,   0.020580322,    0.03180832,
   0.0028770117,  -0.012367731,   0.037383243,  -0.054915592,   0.032225136,
     0.00825818,  -0.023888804,   -0.01184671,   0.012257014,   0.016294925,
    0.009254632,  0.0051353113,  -0.008889917,   0.016855022,    0.04207243,
  0.00082589936,  -0.011664353,    0.00818654,   0.029020859,  -0.012335167,
   -0.019603407,  0.0013945447,    0.05538451,  -0.011625277,  -0.008153976,
    0.038607642,   -0.03811267, -0.0074440846,   0.047647353,   -0.00927417,
    0.024201415, -0.0069230637,  -0.008538228,   0.003910912,   0.052805457,
   -0.023159374,  0.0014352495,  -0.038659744,   0.017141584,   0.005587948,
    0.007971618,  -0.016920151,    0.06658646, -0.0016916894,   0.045667473,
   -0.042202685,   -0.03983204,   -0.04160351,  -0.011729481,  -0.055905532,
    0.012543576,  0.0038848612,   0.007919516,   0.010915386,  0.0033117384,
   -0.007548289,  -0.030427614,  -0.041890074,   0.036002535,  -0.023771575,
   -0.008792226,  -0.049444873,   0.016490309, -0.0060568666,   0.040196754,
    0.014106638,  -0.014575557, -0.0017356506,  -0.011234511,  -0.012517525,
    0.008362384,    0.01253055,   0.036158845,   0.008297256, -0.0010908874,
   -0.014888169,  -0.020489143,   0.018965157,  -0.057937514, -0.0037122732,
    0.004402626,   -0.00840146,   0.042984217,   -0.04936672,   -0.03714878,
    0.004969236,    0.03707063,   0.015396165,   -0.02055427,    0.01988997,
    0.030219207,  -0.021257648,    0.01340326,   0.003692735,   0.012595678
]
[
   -0.033366997,   0.010419146,  0.0118083665,  -0.040441725, 0.0020355924,
   -0.015808804,  -0.023629595, -0.0066180876,  -0.040004376,  0.020053642,
  -0.0010797002,   -0.03900105,  -0.009956073,  0.0027896944,  0.003305828,
   -0.034010153,   0.009833873,  0.0061164247,   0.022536227,  0.029147884,
    0.017789727,    0.03182342,   0.010869357,   0.031849146, -0.028093107,
    0.008283865, -0.0145610785,    0.01645196,  -0.029430874,  -0.02508313,
    0.046178687,   -0.01722375,  -0.010046115,   0.013101112, 0.0044538635,
     0.02197025,    0.03985002,   0.007955855,  0.0008819293,  0.012657333,
    0.014368132,  -0.014007963,   -0.03722594,   0.031617608, -0.011570398,
    0.039052505,  0.0020018267,   0.023706773, -0.0046950476,  0.056083307,
    -0.08412496,  -0.043425974,  -0.015512952,   0.015950298,  -0.03624834,
  -0.0053317733,  -0.037251666,  0.0046339477,    0.04193385,  0.023475237,
   -0.021378545,   0.013699248,  -0.026009277,   0.050757967,   -0.0494202,
   0.0007874656,   -0.07208506,   0.015885983,  -0.003259199,  0.015127057,
   0.0068946453,  -0.035373647,  -0.005875241, -0.0032238255,  -0.04185667,
   -0.022047428,  0.0014326327, -0.0070940237, -0.0027864785, -0.016271876,
    0.005097021,   0.034473225,   0.012361481,  -0.026498076, 0.0067274245,
   -0.026330855,  -0.006132504,   0.008180959,  -0.049368747, -0.032337945,
    0.011049441,    0.00186194,  -0.012097787,    0.01930758,   0.07059293,
    0.029713862,    0.04337452, -0.0048461896,  -0.019976463,  0.011473924
]
```

## Using Azure Managed Identity

If you're using Azure Managed Identity, you can configure the credentials like this:

```typescript
// Azure Managed Identity를 사용하여 인증하기
import {
  DefaultAzureCredential,
  getBearerTokenProvider,
} from "@azure/identity";
import { AzureOpenAIEmbeddings } from "@langchain/openai";

const credentials = new DefaultAzureCredential();
const azureADTokenProvider = getBearerTokenProvider(
  credentials,
  "https://cognitiveservices.azure.com/.default"
);

const modelWithManagedIdentity = new AzureOpenAIEmbeddings({
  azureADTokenProvider,
  azureOpenAIApiInstanceName: "<your_instance_name>",
  azureOpenAIApiEmbeddingsDeploymentName: "<your_embeddings_deployment_name>",
  azureOpenAIApiVersion: "<api_version>",
});
```

## Using a different domain

If your instance is hosted under a domain other than the default `openai.azure.com`, you'll need to use the alternate `AZURE_OPENAI_BASE_PATH` environment variable.
For example, here's how you would connect to the domain `https://westeurope.api.microsoft.com/openai/deployments/{DEPLOYMENT_NAME}`:

```typescript
// 사용자 지정 도메인(엔드포인트 경로)으로 호출하기
import { AzureOpenAIEmbeddings } from "@langchain/openai";

const embeddingsDifferentDomain = new AzureOpenAIEmbeddings({
  azureOpenAIApiKey: "<your_key>", // In Node.js defaults to process.env.AZURE_OPENAI_API_KEY
  azureOpenAIApiEmbeddingsDeploymentName: "<your_embedding_deployment_name>", // In Node.js defaults to process.env.AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME
  azureOpenAIApiVersion: "<api_version>", // In Node.js defaults to process.env.AZURE_OPENAI_API_VERSION
  azureOpenAIBasePath:
    "https://westeurope.api.microsoft.com/openai/deployments", // In Node.js defaults to process.env.AZURE_OPENAI_BASE_PATH
});
```

## Custom headers

You can specify custom headers by passing in a `configuration` field:

```typescript
// 사용자 지정 HTTP 헤더 추가하기
import { AzureOpenAIEmbeddings } from "@langchain/openai";

const embeddingsWithCustomHeaders = new AzureOpenAIEmbeddings({
  azureOpenAIApiKey: "<your_key>",
  azureOpenAIApiInstanceName: "<your_instance_name>",
  azureOpenAIApiEmbeddingsDeploymentName: "<your_embeddings_deployment_name>",
  azureOpenAIApiVersion: "<api_version>",
  configuration: {
    defaultHeaders: {
      "x-custom-header": `SOME_VALUE`,
    },
  },
});
```

The `configuration` field also accepts other `ClientOptions` parameters accepted by the official SDK.

**Note:** The specific header `api-key` currently cannot be overridden in this manner and will pass through the value from `azureOpenAIApiKey`.

## Migration from Azure OpenAI SDK

If you are using the deprecated Azure OpenAI SDK with the `@langchain/azure-openai` package, you can update your code to use the new Azure integration following these steps:

1. Install the new `@langchain/openai` package and remove the previous `@langchain/azure-openai` package:

   ```bash npm
   # 패키지 전환: 새로운 @langchain/openai 설치 및 이전 @langchain/azure-openai 제거
   npm install @langchain/openai
   npm uninstall @langchain/azure-openai
   ```

2. Update your imports to use the new `AzureOpenAIEmbeddings` classe from the `@langchain/openai` package:

   ```typescript
   // 새로운 패키지에서 AzureOpenAIEmbeddings 임포트
   import { AzureOpenAIEmbeddings } from "@langchain/openai";
   ```

3. Update your code to use the new `AzureOpenAIEmbeddings` class and pass the required parameters:

   ```typescript
   // 새로운 생성자 옵션으로 인스턴스화
   const model = new AzureOpenAIEmbeddings({
     azureOpenAIApiKey: "<your_key>",
     azureOpenAIApiInstanceName: "<your_instance_name>",
     azureOpenAIApiEmbeddingsDeploymentName:
       "<your_embeddings_deployment_name>",
     azureOpenAIApiVersion: "<api_version>",
   });

   이제 생성자는 `azureOpenAIApiEndpoint` 파라미터 대신 `azureOpenAIApiInstanceName` 파라미터가 필요하며, API 버전을 지정하기 위한 `azureOpenAIApiVersion` 파라미터가 추가되었습니다.

   - Azure Managed Identity를 사용 중이었다면, 이제 생성자에 `credentials` 대신 `azureADTokenProvider` 파라미터를 사용해야 합니다. 자세한 내용은 [Azure Managed Identity](#using-azure-managed-identity) 섹션을 참고하세요.

   - 환경 변수를 사용 중이었다면, `AZURE_OPENAI_API_ENDPOINT` 대신 `AZURE_OPENAI_API_INSTANCE_NAME` 환경 변수를 설정해야 하며, API 버전을 지정하기 위해 `AZURE_OPENAI_API_VERSION` 환경 변수를 추가로 설정해야 합니다.

## API reference

모든 AzureOpenAIEmbeddings 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_openai.AzureOpenAIEmbeddings.html)에서 확인하세요.