---
title: Vectara
---

Vectara는 GenAI 애플리케이션을 구축하기 위한 플랫폼입니다. Vectara가 관리하며 성능과 정확도에 최적화된 문서 인덱싱 및 쿼리를 위한 사용하기 쉬운 API를 제공합니다.

LangChain.js와 함께 Vectara를 vector store로 사용할 수 있습니다.

## 👉 Embeddings 포함

Vectara는 내부적으로 자체 embeddings를 사용하므로, 직접 제공하거나 embeddings를 얻기 위해 다른 서비스를 호출할 필요가 없습니다.

이는 또한 자체 embeddings를 제공하더라도 아무 작업도 수행되지 않음을 의미합니다.

```typescript
const store = await VectaraStore.fromTexts(
  ["hello world", "hi there"],
  [{ foo: "bar" }, { foo: "baz" }],
  // This won't have an effect. Provide a FakeEmbeddings instance instead for clarity.
  new OpenAIEmbeddings(),
  args
);
```

## Setup

다음이 필요합니다:

- [무료 Vectara 계정](https://vectara.com/integrations/langchain) 생성
- 데이터를 저장할 [corpus](https://docs.vectara.com/docs/console-ui/creating-a-corpus) 생성
- 이 corpus에 액세스할 수 있도록 QueryService 및 IndexService 권한이 있는 [API key](https://docs.vectara.com/docs/common-use-cases/app-authn-authz/api-keys) 생성

`.env` 파일을 구성하거나 LangChain을 Vectara corpus에 연결하기 위한 인자를 제공하세요:

```
VECTARA_CUSTOMER_ID=your_customer_id
VECTARA_CORPUS_ID=your_corpus_id
VECTARA_API_KEY=your-vectara-api-key
```

여러 corpus를 동시에 쿼리하기 위해 쉼표로 구분된 여러 corpus ID를 제공할 수 있습니다. 예: `VECTARA_CORPUS_ID=3,8,9,43`.
여러 corpus를 인덱싱하려면 각 corpus에 대해 별도의 VectaraStore 인스턴스를 생성해야 합니다.

## Usage

```typescript
import { VectaraStore } from "@langchain/community/vectorstores/vectara";
import { VectaraSummaryRetriever } from "@langchain/community/retrievers/vectara_summary";
import { Document } from "@langchain/core/documents";

// Create the Vectara store.
const store = new VectaraStore({
  customerId: Number(process.env.VECTARA_CUSTOMER_ID),
  corpusId: Number(process.env.VECTARA_CORPUS_ID),
  apiKey: String(process.env.VECTARA_API_KEY),
  verbose: true,
});

// Add two documents with some metadata.
const doc_ids = await store.addDocuments([
  new Document({
    pageContent: "Do I dare to eat a peach?",
    metadata: {
      foo: "baz",
    },
  }),
  new Document({
    pageContent: "In the room the women come and go talking of Michelangelo",
    metadata: {
      foo: "bar",
    },
  }),
]);

// Perform a similarity search.
const resultsWithScore = await store.similaritySearchWithScore(
  "What were the women talking about?",
  1,
  {
    lambda: 0.025,
  }
);

// Print the results.
console.log(JSON.stringify(resultsWithScore, null, 2));
/*
[
  [
    {
      "pageContent": "In the room the women come and go talking of Michelangelo",
      "metadata": {
        "lang": "eng",
        "offset": "0",
        "len": "57",
        "foo": "bar"
      }
    },
    0.4678752
  ]
]
*/

const retriever = new VectaraSummaryRetriever({ vectara: store, topK: 3 });
const documents = await retriever.invoke("What were the women talking about?");

console.log(JSON.stringify(documents, null, 2));
/*
[
  {
    "pageContent": "<b>In the room the women come and go talking of Michelangelo</b>",
    "metadata": {
      "lang": "eng",
      "offset": "0",
      "len": "57",
      "foo": "bar"
    }
  },
  {
    "pageContent": "<b>In the room the women come and go talking of Michelangelo</b>",
    "metadata": {
      "lang": "eng",
      "offset": "0",
      "len": "57",
      "foo": "bar"
    }
  },
  {
    "pageContent": "<b>In the room the women come and go talking of Michelangelo</b>",
    "metadata": {
      "lang": "eng",
      "offset": "0",
      "len": "57",
      "foo": "bar"
    }
  }
]
*/

// Delete the documents.
await store.deleteDocuments(doc_ids);
```

`lambda`는 Vectara의 hybrid search 기능과 관련된 매개변수로, [여기](https://docs.vectara.com/docs/api-reference/search-apis/lexical-matching)에 설명된 대로 neural search와 boolean/exact match 간의 균형을 제공합니다. 기본값으로 0.025를 권장하며, 고급 사용자가 필요에 따라 이 값을 사용자 정의할 수 있는 방법을 제공합니다.

## APIs

Vectara의 LangChain vector store는 Vectara의 핵심 API를 사용합니다:

- [Indexing API](https://docs.vectara.com/docs/indexing-apis/indexing) - Vectara corpus에 문서를 저장합니다.
- [Search API](https://docs.vectara.com/docs/search-apis/search) - 이 데이터를 쿼리합니다. 이 API는 hybrid search를 지원합니다.

## Related

- Vector store [개념 가이드](/oss/integrations/vectorstores)
- Vector store [사용 방법 가이드](/oss/integrations/vectorstores)