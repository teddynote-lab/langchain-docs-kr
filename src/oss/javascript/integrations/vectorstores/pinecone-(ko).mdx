---
title: PineconeStore
---

[Pinecone](https://www.pinecone.io/)은 세계 최고의 기업들의 AI를 지원하는 벡터 데이터베이스입니다.

이 가이드는 Pinecone [vector store](/oss/integrations/vectorstores) 시작하기에 대한 간단한 개요를 제공합니다. 모든 `PineconeStore` 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_pinecone.PineconeStore.html)를 참조하세요.

## Overview

### Integration details

| Class | Package | [PY support](https://python.langchain.com/docs/integrations/vectorstores/pinecone/) | Version |
| :--- | :--- | :---: | :---: |
| [`PineconeStore`](https://api.js.langchain.com/classes/langchain_pinecone.PineconeStore.html) | [`@langchain/pinecone`](https://npmjs.com/@langchain/pinecone) | ✅ |  ![NPM - Version](https://img.shields.io/npm/v/@langchain/pinecone?style=flat-square&label=%20&) |

## Setup

Pinecone vector store를 사용하려면 Pinecone 계정을 생성하고, index를 초기화하고, `@langchain/pinecone` integration package를 설치해야 합니다. 또한 [공식 Pinecone SDK](https://www.npmjs.com/package/@pinecone-database/pinecone)를 설치하여 `PineconeStore` instance에 전달할 client를 초기화해야 합니다.

이 가이드는 [OpenAI embeddings](/oss/integrations/text_embedding/openai)도 사용하므로 `@langchain/openai` integration package를 설치해야 합니다. 원하는 경우 [다른 지원되는 embeddings model](/oss/integrations/text_embedding)을 사용할 수도 있습니다.

<CodeGroup>
```bash npm
npm install @langchain/pinecone @langchain/openai @langchain/core @pinecone-database/pinecone@5
```
```bash yarn
yarn add @langchain/pinecone @langchain/openai @langchain/core @pinecone-database/pinecone@5
```
```bash pnpm
pnpm add @langchain/pinecone @langchain/openai @langchain/core @pinecone-database/pinecone@5
```
</CodeGroup>

### Credentials

[Pinecone](https://www.pinecone.io/) 계정에 가입하고 index를 생성하세요. dimension이 사용하려는 embedding의 dimension과 일치하는지 확인하세요(OpenAI의 `text-embedding-3-small`의 기본값은 1536입니다). 완료되면 `PINECONE_INDEX`, `PINECONE_API_KEY`, 그리고 (선택적으로) `PINECONE_ENVIRONMENT` 환경 변수를 설정하세요:

```typescript
process.env.PINECONE_API_KEY = "your-pinecone-api-key";
process.env.PINECONE_INDEX = "your-pinecone-index";

// Optional
process.env.PINECONE_ENVIRONMENT = "your-pinecone-environment";
```

이 가이드에서 OpenAI embedding을 사용하는 경우 OpenAI key도 설정해야 합니다:

```typescript
process.env.OPENAI_API_KEY = "YOUR_API_KEY";
```

model 호출에 대한 자동 추적을 원하는 경우 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API key를 설정할 수도 있습니다:

```typescript
// process.env.LANGSMITH_TRACING="true"
// process.env.LANGSMITH_API_KEY="your-api-key"
```

## Instantiation

```typescript
import { PineconeStore } from "@langchain/pinecone";
import { OpenAIEmbeddings } from "@langchain/openai";

import { Pinecone as PineconeClient } from "@pinecone-database/pinecone";

const embeddings = new OpenAIEmbeddings({
  model: "text-embedding-3-small",
});

const pinecone = new PineconeClient();
// Will automatically read the PINECONE_API_KEY and PINECONE_ENVIRONMENT env vars
const pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);

const vectorStore = await PineconeStore.fromExistingIndex(
  embeddings,
  {
    pineconeIndex,
    // Maximum number of batch requests to allow at once. Each batch is 1000 vectors.
    maxConcurrency: 5,
    // You can pass a namespace here too
    // namespace: "foo",
  }
);
```

## Manage vector store

### Add items to vector store

```typescript
import type { Document } from "@langchain/core/documents";

const document1: Document = {
  pageContent: "The powerhouse of the cell is the mitochondria",
  metadata: { source: "https://example.com" }
};

const document2: Document = {
  pageContent: "Buildings are made out of brick",
  metadata: { source: "https://example.com" }
};

const document3: Document = {
  pageContent: "Mitochondria are made out of lipids",
  metadata: { source: "https://example.com" }
};

const document4: Document = {
  pageContent: "The 2024 Olympics are in Paris",
  metadata: { source: "https://example.com" }
}

const documents = [document1, document2, document3, document4];

await vectorStore.addDocuments(documents, { ids: ["1", "2", "3", "4"] });
```

```output
[ '1', '2', '3', '4' ]
```

**참고:** document를 추가한 후 쿼리 가능해지기까지 약간의 지연이 있습니다.

### Delete items from vector store

```typescript
await vectorStore.delete({ ids: ["4"] });
```

## Query vector store

vector store가 생성되고 관련 document가 추가되면 chain 또는 agent를 실행하는 동안 쿼리하고 싶을 것입니다.

### Query directly

간단한 유사도 검색은 다음과 같이 수행할 수 있습니다:

```typescript
// Optional filter
const filter = { source: "https://example.com" };

const similaritySearchResults = await vectorStore.similaritySearch("biology", 2, filter);

for (const doc of similaritySearchResults) {
  console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);
}
```

```output
* The powerhouse of the cell is the mitochondria [{"source":"https://example.com"}]
* Mitochondria are made out of lipids [{"source":"https://example.com"}]
```

유사도 검색을 실행하고 해당 score를 받으려면 다음을 실행할 수 있습니다:

```typescript
const similaritySearchWithScoreResults = await vectorStore.similaritySearchWithScore("biology", 2, filter)

for (const [doc, score] of similaritySearchWithScoreResults) {
  console.log(`* [SIM=${score.toFixed(3)}] ${doc.pageContent} [${JSON.stringify(doc.metadata)}]`);
}
```

```output
* [SIM=0.165] The powerhouse of the cell is the mitochondria [{"source":"https://example.com"}]
* [SIM=0.148] Mitochondria are made out of lipids [{"source":"https://example.com"}]
```

### Query by turning into retriever

vector store를 [retriever](/oss/langchain/retrieval)로 변환하여 chain에서 더 쉽게 사용할 수도 있습니다.

```typescript
const retriever = vectorStore.asRetriever({
  // Optional filter
  filter: filter,
  k: 2,
});

await retriever.invoke("biology");
```

```output
[
  Document {
    pageContent: 'The powerhouse of the cell is the mitochondria',
    metadata: { source: 'https://example.com' },
    id: undefined
  },
  Document {
    pageContent: 'Mitochondria are made out of lipids',
    metadata: { source: 'https://example.com' },
    id: undefined
  }
]
```

### Usage for retrieval-augmented generation

retrieval-augmented generation (RAG)에 이 vector store를 사용하는 방법에 대한 가이드는 다음 섹션을 참조하세요:

- [LangChain으로 RAG 앱 만들기](/oss/langchain/rag)
- [Agentic RAG](/oss/langgraph/agentic-rag)
- [Retrieval 문서](/oss/langchain/retrieval)

## API reference

모든 `PineconeStore` 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_pinecone.PineconeStore.html)를 참조하세요.