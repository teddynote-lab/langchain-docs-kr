---
title: Ollama
---


<Warning>
**현재 Ollama 모델을 text completion 모델로 사용하는 방법을 설명하는 페이지를 보고 계십니다. Ollama에서 사용 가능한 많은 인기 모델은 [chat completion 모델](/oss/langchain/models)입니다.**


[이 페이지](/oss/integrations/chat/ollama/)를 찾고 계실 수 있습니다.
</Warning>


이 문서는 LangChain을 사용하여 Ollama text completion 모델(LLM)을 시작하는 데 도움을 드립니다. `Ollama` 기능 및 구성 옵션에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html)를 참조하세요.

## Overview

### Integration details

[Ollama](https://ollama.ai/)를 사용하면 Llama 3와 같은 오픈 소스 대규모 언어 모델을 로컬에서 실행할 수 있습니다.

Ollama는 모델 가중치, 구성 및 데이터를 Modelfile로 정의된 단일 패키지로 번들링합니다. GPU 사용을 포함한 설정 및 구성 세부 사항을 최적화합니다.

이 예제는 LangChain을 사용하여 Ollama로 실행되는 Llama 2 7b 인스턴스와 상호 작용하는 방법을 다룹니다.
지원되는 모델 및 모델 변형의 전체 목록은 [Ollama model library](https://github.com/jmorganca/ollama#model-library)를 참조하세요.

| Class | Package | Local | Serializable | [PY support](https://python.langchain.com/docs/integrations/llms/ollama/) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`Ollama`](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html) | [`@langchain/ollama`](https://npmjs.com/@langchain/ollama) | ✅ | ❌ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/ollama?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/ollama?style=flat-square&label=%20&) |

## Setup

Ollama embedding 모델에 액세스하려면 [이 지침](https://github.com/jmorganca/ollama)을 따라 Ollama를 설치하고 `@langchain/ollama` integration package를 설치해야 합니다.

### Credentials

모델 호출에 대한 자동 추적을 원하시면 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API key를 설정할 수 있습니다:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

LangChain Ollama integration은 `@langchain/ollama` package에 있습니다:

<CodeGroup>
```bash npm
npm install @langchain/ollama @langchain/core
```
```bash yarn
yarn add @langchain/ollama @langchain/core
```
```bash pnpm
pnpm add @langchain/ollama @langchain/core
```
</CodeGroup>

## Instantiation

이제 모델 객체를 인스턴스화하고 chat completion을 생성할 수 있습니다:

```typescript
import { Ollama } from "@langchain/ollama"

const llm = new Ollama({
  model: "llama3", // Default value
  temperature: 0,
  maxRetries: 2,
  // other params...
})
```

## Invocation

```typescript
const inputText = "Ollama is an AI company that "

const completion = await llm.invoke(inputText)
completion
```

```output
I think you meant to say "Olivia" instead of "Ollama". Olivia is not a well-known AI company, but there are several other AI companies with similar names. Here are a few examples:

* Oliva AI: A startup that uses artificial intelligence to help businesses optimize their operations and improve customer experiences.
* Olivia Technologies: A company that develops AI-powered solutions for industries such as healthcare, finance, and education.
* Olivia.ai: A platform that uses AI to help businesses automate their workflows and improve productivity.

If you meant something else by "Ollama", please let me know and I'll do my best to help!
```

## Multimodal models

Ollama는 버전 0.1.15 이상에서 [LLaVA](https://ollama.ai/library/llava)와 같은 오픈 소스 multimodal 모델을 지원합니다.
다음과 같이 base64로 인코딩된 이미지 데이터를 multimodal 지원 모델에 바인딩하여 컨텍스트로 사용할 수 있습니다:

```typescript
import { Ollama } from "@langchain/ollama";
import * as fs from "node:fs/promises";

const imageData = await fs.readFile("../../../../../examples/hotdog.jpg");

const model = new Ollama({
  model: "llava",
}).bind({
  images: [imageData.toString("base64")],
});

const res = await model.invoke("What's in this image?");
console.log(res);
```

```output
 The image shows a hot dog placed inside what appears to be a bun that has been specially prepared to resemble a hot dog bun. This is an example of a creative or novelty food item, where the bread used for the bun looks similar to a cooked hot dog itself, playing on the name "hot dog." The image also shows the typical garnishes like ketchup and mustard on the side.
```

## Related


- [Models guide](/oss/langchain/models)

## API reference

모든 `Ollama` 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_ollama.Ollama.html)를 참조하세요