---
title: Persistence
---



LangGraph는 checkpointer를 통해 구현되는 내장 persistence layer를 가지고 있습니다. checkpointer와 함께 graph를 compile하면, checkpointer는 모든 super-step마다 graph state의 `checkpoint`를 저장합니다. 이러한 checkpoint들은 `thread`에 저장되며, graph 실행 후에 접근할 수 있습니다. `thread`는 실행 후 graph의 state에 대한 접근을 허용하기 때문에, human-in-the-loop, memory, time travel, fault-tolerance를 포함한 여러 강력한 기능들이 모두 가능합니다. 아래에서 이러한 각 개념에 대해 더 자세히 설명하겠습니다.

![Checkpoints](/oss/images/checkpoints.jpg)

<Info>
**LangGraph API는 checkpointing을 자동으로 처리합니다**
LangGraph API를 사용할 때는 checkpointer를 수동으로 구현하거나 구성할 필요가 없습니다. API가 백그라운드에서 모든 persistence 인프라를 처리합니다.
</Info>

## Threads

thread는 checkpointer에 의해 저장된 각 checkpoint에 할당된 고유 ID 또는 thread identifier입니다. 이것은 [run](/langsmith/assistants#execution) 시퀀스의 누적된 state를 포함합니다. run이 실행되면, assistant의 기본 graph의 [state](/oss/javascript/langgraph/graph-api#state)가 thread에 저장됩니다.

checkpointer와 함께 graph를 invoke할 때, config의 `configurable` 부분에 `thread_id`를 **반드시** 지정해야 합니다.



```typescript
{
  configurable: {
    thread_id: "1";
  }
}
```


thread의 현재 및 과거 state를 검색할 수 있습니다. state를 유지하려면 run을 실행하기 전에 thread를 생성해야 합니다. LangSmith API는 thread와 thread state를 생성하고 관리하기 위한 여러 endpoint를 제공합니다. 자세한 내용은 [API reference](https://langchain-ai.github.io/langgraph/cloud/reference/api/)를 참조하세요.

## Checkpoints

특정 시점의 thread state를 checkpoint라고 합니다. Checkpoint는 각 super-step에서 저장된 graph state의 스냅샷이며 다음과 같은 주요 속성을 가진 `StateSnapshot` 객체로 표현됩니다:

* `config`: 이 checkpoint와 연관된 Config.
* `metadata`: 이 checkpoint와 연관된 Metadata.
* `values`: 이 시점의 state channel들의 값.
* `next`: graph에서 다음에 실행할 node 이름들의 tuple.
* `tasks`: 다음에 실행할 task에 대한 정보를 포함하는 `PregelTask` 객체들의 tuple. 이전에 step이 시도되었다면 error 정보를 포함합니다. graph가 node 내에서 [동적으로](/oss/javascript/langgraph/interrupts#pause-using-interrupt) 중단된 경우, task는 interrupt와 관련된 추가 데이터를 포함합니다.

Checkpoint는 유지되며 나중에 thread의 state를 복원하는 데 사용할 수 있습니다.

간단한 graph가 다음과 같이 invoke될 때 어떤 checkpoint들이 저장되는지 살펴보겠습니다:



```typescript
import { StateGraph, START, END, MemoryServer } from "@langchain/langgraph";
import { registry } from "@langchain/langgraph/zod";
import * as z from "zod";

const State = z.object({
  foo: z.string(),
  bar: z.array(z.string()).register(registry, {
    reducer: {
      fn: (x, y) => x.concat(y),
    },
    default: () => [] as string[],
  }),
});

const workflow = new StateGraph(State)
  .addNode("nodeA", (state) => {
    return { foo: "a", bar: ["a"] };
  })
  .addNode("nodeB", (state) => {
    return { foo: "b", bar: ["b"] };
  })
  .addEdge(START, "nodeA")
  .addEdge("nodeA", "nodeB")
  .addEdge("nodeB", END);

const checkpointer = new MemorySaver();
const graph = workflow.compile({ checkpointer });

const config = { configurable: { thread_id: "1" } };
await graph.invoke({ foo: "" }, config);
```


```typescript
import { StateGraph, START, END, MemoryServer } from "@langchain/langgraph";
import { registry } from "@langchain/langgraph/zod";
import * as z from "zod";

const State = z.object({
  foo: z.string(),
  bar: z.array(z.string()).register(registry, {
    reducer: {
      fn: (x, y) => x.concat(y),
    },
    default: () => [] as string[],
  }),
});

const workflow = new StateGraph(State)
  .addNode("nodeA", (state) => {
    return { foo: "a", bar: ["a"] };
  })
  .addNode("nodeB", (state) => {
    return { foo: "b", bar: ["b"] };
  })
  .addEdge(START, "nodeA")
  .addEdge("nodeA", "nodeB")
  .addEdge("nodeB", END);

const checkpointer = new MemorySaver();
const graph = workflow.compile({ checkpointer });

const config = { configurable: { thread_id: "1" } };
await graph.invoke({ foo: "" }, config);
```




graph를 실행한 후, 정확히 4개의 checkpoint를 볼 수 있습니다:

* 다음에 실행될 node로 [`START`](https://langchain-ai.github.io/langgraphjs/reference/variables/langgraph.START.html)를 가진 빈 checkpoint
* 사용자 입력 `{'foo': '', 'bar': []}`과 다음에 실행될 node로 `nodeA`를 가진 checkpoint
* `nodeA`의 출력 `{'foo': 'a', 'bar': ['a']}`과 다음에 실행될 node로 `nodeB`를 가진 checkpoint
* `nodeB`의 출력 `{'foo': 'b', 'bar': ['a', 'b']}`과 다음에 실행될 node가 없는 checkpoint

`bar` channel에 대한 reducer가 있기 때문에 `bar` channel 값에는 두 node의 출력이 모두 포함됩니다.


### Get state



저장된 graph state와 상호작용할 때, [thread identifier](#threads)를 **반드시** 지정해야 합니다. `graph.getState(config)`를 호출하여 graph의 _최신_ state를 볼 수 있습니다. 이것은 config에 제공된 thread ID와 연관된 최신 checkpoint에 해당하는 `StateSnapshot` 객체를 반환하거나, 제공된 경우 thread의 checkpoint ID와 연관된 checkpoint를 반환합니다.

```typescript
// get the latest state snapshot
const config = { configurable: { thread_id: "1" } };
await graph.getState(config);

// get a state snapshot for a specific checkpoint_id
const config = {
  configurable: {
    thread_id: "1",
    checkpoint_id: "1ef663ba-28fe-6528-8002-5a559208592c",
  },
};
await graph.getState(config);
```




예제에서 `getState`의 출력은 다음과 같습니다:

```
StateSnapshot {
  values: { foo: 'b', bar: ['a', 'b'] },
  next: [],
  config: {
    configurable: {
      thread_id: '1',
      checkpoint_ns: '',
      checkpoint_id: '1ef663ba-28fe-6528-8002-5a559208592c'
    }
  },
  metadata: {
    source: 'loop',
    writes: { nodeB: { foo: 'b', bar: ['b'] } },
    step: 2
  },
  createdAt: '2024-08-29T19:19:38.821749+00:00',
  parentConfig: {
    configurable: {
      thread_id: '1',
      checkpoint_ns: '',
      checkpoint_id: '1ef663ba-28f9-6ec4-8001-31981c2c39f8'
    }
  },
  tasks: []
}
```


### Get state history



`graph.getStateHistory(config)`를 호출하여 주어진 thread에 대한 graph 실행의 전체 history를 가져올 수 있습니다. 이것은 config에 제공된 thread ID와 연관된 `StateSnapshot` 객체들의 list를 반환합니다. 중요한 점은, checkpoint들이 시간순으로 정렬되며 가장 최근의 checkpoint / `StateSnapshot`이 list의 첫 번째에 위치한다는 것입니다.

```typescript
const config = { configurable: { thread_id: "1" } };
for await (const state of graph.getStateHistory(config)) {
  console.log(state);
}
```




예제에서 `getStateHistory`의 출력은 다음과 같습니다:

```
[
  StateSnapshot {
    values: { foo: 'b', bar: ['a', 'b'] },
    next: [],
    config: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28fe-6528-8002-5a559208592c'
      }
    },
    metadata: {
      source: 'loop',
      writes: { nodeB: { foo: 'b', bar: ['b'] } },
      step: 2
    },
    createdAt: '2024-08-29T19:19:38.821749+00:00',
    parentConfig: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f9-6ec4-8001-31981c2c39f8'
      }
    },
    tasks: []
  },
  StateSnapshot {
    values: { foo: 'a', bar: ['a'] },
    next: ['nodeB'],
    config: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f9-6ec4-8001-31981c2c39f8'
      }
    },
    metadata: {
      source: 'loop',
      writes: { nodeA: { foo: 'a', bar: ['a'] } },
      step: 1
    },
    createdAt: '2024-08-29T19:19:38.819946+00:00',
    parentConfig: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f4-6b4a-8000-ca575a13d36a'
      }
    },
    tasks: [
      PregelTask {
        id: '6fb7314f-f114-5413-a1f3-d37dfe98ff44',
        name: 'nodeB',
        error: null,
        interrupts: []
      }
    ]
  },
  StateSnapshot {
    values: { foo: '', bar: [] },
    next: ['node_a'],
    config: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f4-6b4a-8000-ca575a13d36a'
      }
    },
    metadata: {
      source: 'loop',
      writes: null,
      step: 0
    },
    createdAt: '2024-08-29T19:19:38.817813+00:00',
    parentConfig: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f0-6c66-bfff-6723431e8481'
      }
    },
    tasks: [
      PregelTask {
        id: 'f1b14528-5ee5-579c-949b-23ef9bfbed58',
        name: 'node_a',
        error: null,
        interrupts: []
      }
    ]
  },
  StateSnapshot {
    values: { bar: [] },
    next: ['__start__'],
    config: {
      configurable: {
        thread_id: '1',
        checkpoint_ns: '',
        checkpoint_id: '1ef663ba-28f0-6c66-bfff-6723431e8481'
      }
    },
    metadata: {
      source: 'input',
      writes: { foo: '' },
      step: -1
    },
    createdAt: '2024-08-29T19:19:38.816205+00:00',
    parentConfig: null,
    tasks: [
      PregelTask {
        id: '6d27aa2e-d72b-5504-a36f-8620e54a76dd',
        name: '__start__',
        error: null,
        interrupts: []
      }
    ]
  }
]
```


![State](/oss/images/get_state.jpg)

### Replay

이전 graph 실행을 재생하는 것도 가능합니다. `thread_id`와 `checkpoint_id`로 graph를 `invoke`하면, `checkpoint_id`에 해당하는 checkpoint _이전_에 실행된 step들을 _재생_하고, checkpoint _이후_의 step들만 실행합니다.

* `thread_id`는 thread의 ID입니다.
* `checkpoint_id`는 thread 내의 특정 checkpoint를 참조하는 식별자입니다.

graph를 invoke할 때 config의 `configurable` 부분에 이것들을 전달해야 합니다:



```typescript
const config = {
  configurable: {
    thread_id: "1",
    checkpoint_id: "0c62ca34-ac19-445d-bbb0-5b4984975b2a",
  },
};
await graph.invoke(null, config);
```


중요한 점은, LangGraph는 특정 step이 이전에 실행되었는지 여부를 알고 있다는 것입니다. 실행되었다면, LangGraph는 단순히 graph의 해당 step을 _재생_하고 step을 다시 실행하지 않지만, 이는 제공된 `checkpoint_id` _이전_의 step들에만 해당됩니다. `checkpoint_id` _이후_의 모든 step들은 이전에 실행되었더라도 실행됩니다(즉, 새로운 fork). replay에 대한 자세한 내용은 [time-travel 사용 방법 가이드](/oss/javascript/langgraph/use-time-travel)를 참조하세요.

![Replay](/oss/images/re_play.png)

### Update state



특정 `checkpoint`에서 graph를 재생하는 것 외에도, graph state를 _편집_할 수도 있습니다. 이는 `graph.updateState()`를 사용하여 수행합니다. 이 method는 세 가지 다른 인수를 받습니다:


#### `config`

config는 업데이트할 thread를 지정하는 `thread_id`를 포함해야 합니다. `thread_id`만 전달되면 현재 state를 업데이트(또는 fork)합니다. 선택적으로 `checkpoint_id` 필드를 포함하면 선택한 checkpoint를 fork합니다.

#### `values`

이것들은 state를 업데이트하는 데 사용될 값들입니다. 이 업데이트는 node의 모든 업데이트가 처리되는 것과 정확히 동일하게 처리됩니다. 즉, 이러한 값들은 graph state의 일부 channel에 대해 정의된 경우 [reducer](/oss/javascript/langgraph/graph-api#reducers) function에 전달됩니다. 이는 [`update_state`](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph.CompiledStateGraph.html#updateState)가 모든 channel의 channel 값을 자동으로 덮어쓰지 않고, reducer가 없는 channel에 대해서만 덮어쓴다는 것을 의미합니다. 예제를 살펴보겠습니다.

다음 schema로 graph의 state를 정의했다고 가정해봅시다(전체 예제는 위 참조):



```typescript
import { registry } from "@langchain/langgraph/zod";
import * as z from "zod";

const State = z.object({
  foo: z.number(),
  bar: z.array(z.string()).register(registry, {
    reducer: {
      fn: (x, y) => x.concat(y),
    },
    default: () => [] as string[],
  }),
});
```


이제 graph의 현재 state가 다음과 같다고 가정해봅시다:



```typescript
{ foo: 1, bar: ["a"] }
```


다음과 같이 state를 업데이트하면:



```typescript
await graph.updateState(config, { foo: 2, bar: ["b"] });
```


graph의 새로운 state는 다음과 같습니다:



```typescript
{ foo: 2, bar: ["a", "b"] }
```

`foo` key(channel)는 완전히 변경됩니다(해당 channel에 대해 지정된 reducer가 없기 때문에 `updateState`가 덮어씁니다). 그러나 `bar` key에 대해서는 reducer가 지정되어 있으므로 `bar`의 state에 `"b"`를 추가합니다.


#### `as_node`



`updateState`를 호출할 때 선택적으로 지정할 수 있는 마지막 항목은 `asNode`입니다. 제공하면 업데이트가 node `asNode`에서 온 것처럼 적용됩니다. `asNode`가 제공되지 않으면, 모호하지 않은 경우 state를 업데이트한 마지막 node로 설정됩니다. 이것이 중요한 이유는 다음에 실행할 step이 업데이트를 제공한 마지막 node에 따라 달라지기 때문이며, 이를 사용하여 다음에 실행할 node를 제어할 수 있습니다. state forking에 대한 자세한 내용은 [time-travel 사용 방법 가이드](/oss/javascript/langgraph/use-time-travel)를 참조하세요.


![Update](/oss/images/checkpoints_full_story.jpg)

## Memory Store

![Model of shared state](/oss/images/shared_state.png)

[state schema](/oss/javascript/langgraph/graph-api#schema)는 graph가 실행될 때 채워지는 key들의 집합을 지정합니다. 위에서 논의한 바와 같이, state는 각 graph step에서 checkpointer에 의해 thread에 기록될 수 있어 state persistence를 가능하게 합니다.

하지만 thread _간에_ 일부 정보를 유지하려면 어떻게 해야 할까요? 사용자와의 _모든_ 대화(예: thread)에서 사용자에 대한 특정 정보를 유지하려는 chatbot의 경우를 생각해보세요!

checkpointer만으로는 thread 간에 정보를 공유할 수 없습니다. 이것이 [`Store`](https://python.langchain.com/api_reference/langgraph/index.html#module-langgraph.store) interface의 필요성을 야기합니다. 예를 들어, thread 간에 사용자에 대한 정보를 저장하기 위해 `InMemoryStore`를 정의할 수 있습니다. 이전과 같이 checkpointer와 함께 graph를 compile하고, 새로운 `in_memory_store` 변수와 함께 compile합니다.

<Info>
**LangGraph API는 store를 자동으로 처리합니다**
LangGraph API를 사용할 때는 store를 수동으로 구현하거나 구성할 필요가 없습니다. API가 백그라운드에서 모든 storage 인프라를 처리합니다.
</Info>

### Basic Usage

먼저, LangGraph를 사용하지 않고 독립적으로 이것을 보여드리겠습니다.



```typescript
import { MemoryStore } from "@langchain/langgraph";

const memoryStore = new MemoryStore();
```


Memory는 `tuple`로 namespace가 지정되며, 이 특정 예제에서는 `(<user_id>, "memories")`가 됩니다. namespace는 임의의 길이가 될 수 있고 무엇이든 나타낼 수 있으며, 사용자별로 지정될 필요는 없습니다.



```typescript
const userId = "1";
const namespaceForMemory = [userId, "memories"];
```


`store.put` method를 사용하여 store의 namespace에 memory를 저장합니다. 이렇게 할 때, 위에서 정의한 대로 namespace와 memory의 key-value 쌍을 지정합니다: key는 단순히 memory의 고유 식별자(`memory_id`)이고 value(dictionary)는 memory 자체입니다.



```typescript
import { v4 as uuidv4 } from "uuid";

const memoryId = uuidv4();
const memory = { food_preference: "I like pizza" };
await memoryStore.put(namespaceForMemory, memoryId, memory);
```


`store.search` method를 사용하여 namespace의 memory를 읽을 수 있으며, 이는 주어진 사용자에 대한 모든 memory를 list로 반환합니다. 가장 최근의 memory는 list의 마지막에 있습니다.



```typescript
const memories = await memoryStore.search(namespaceForMemory);
memories[memories.length - 1];

// {
//   value: { food_preference: 'I like pizza' },
//   key: '07e0caf4-1631-47b7-b15f-65515d4c1843',
//   namespace: ['1', 'memories'],
//   createdAt: '2024-10-02T17:22:31.590602+00:00',
//   updatedAt: '2024-10-02T17:22:31.590605+00:00'
// }
```

가지고 있는 속성은 다음과 같습니다:

* `value`: 이 memory의 값
* `key`: 이 namespace에서 이 memory의 고유 key
* `namespace`: 이 memory type의 namespace인 문자열 list
* `createdAt`: 이 memory가 생성된 시간의 Timestamp
* `updatedAt`: 이 memory가 업데이트된 시간의 Timestamp


### Semantic Search

단순 검색 외에도, store는 semantic search를 지원하여 정확한 일치가 아닌 의미를 기반으로 memory를 찾을 수 있습니다. 이를 활성화하려면 embedding model로 store를 구성하세요:



```typescript
import { OpenAIEmbeddings } from "@langchain/openai";

const store = new InMemoryStore({
  index: {
    embeddings: new OpenAIEmbeddings({ model: "text-embedding-3-small" }),
    dims: 1536,
    fields: ["food_preference", "$"], // Fields to embed
  },
});
```


이제 검색할 때 자연어 쿼리를 사용하여 관련 memory를 찾을 수 있습니다:



```typescript
// Find memories about food preferences
// (This can be done after putting memories into the store)
const memories = await store.search(namespaceForMemory, {
  query: "What does the user like to eat?",
  limit: 3, // Return top 3 matches
});
```


`fields` parameter를 구성하거나 memory를 저장할 때 `index` parameter를 지정하여 memory의 어느 부분이 embedding될지 제어할 수 있습니다:



```typescript
// Store with specific fields to embed
await store.put(
  namespaceForMemory,
  uuidv4(),
  {
    food_preference: "I love Italian cuisine",
    context: "Discussing dinner plans",
  },
  { index: ["food_preference"] } // Only embed "food_preferences" field
);

// Store without embedding (still retrievable, but not searchable)
await store.put(
  namespaceForMemory,
  uuidv4(),
  { system_info: "Last updated: 2024-01-01" },
  { index: false }
);
```


### Using in LangGraph



이 모든 것이 준비되면 LangGraph에서 `memoryStore`를 사용합니다. `memoryStore`는 checkpointer와 함께 작동합니다: checkpointer는 위에서 논의한 대로 thread에 state를 저장하고, `memoryStore`는 thread _간에_ 접근할 수 있도록 임의의 정보를 저장할 수 있게 합니다. 다음과 같이 checkpointer와 `memoryStore` 모두와 함께 graph를 compile합니다.

```typescript
import { MemorySaver } from "@langchain/langgraph";

// We need this because we want to enable threads (conversations)
const checkpointer = new MemorySaver();

// ... Define the graph ...

// Compile the graph with the checkpointer and store
const graph = workflow.compile({ checkpointer, store: memoryStore });
```


이전과 같이 `thread_id`로 graph를 invoke하고, 위에서 보여준 것처럼 이 특정 사용자에게 memory를 namespace하는 데 사용할 `user_id`도 함께 invoke합니다.



```typescript
// Invoke the graph
const userId = "1";
const config = { configurable: { thread_id: "1", user_id: userId } };

// First let's just say hi to the AI
for await (const update of await graph.stream(
  { messages: [{ role: "user", content: "hi" }] },
  { ...config, streamMode: "updates" }
)) {
  console.log(update);
}
```




node 인수로 `config`와 `store`에 접근하여 _모든 node_에서 `memoryStore`와 `user_id`에 접근할 수 있습니다. node에서 semantic search를 사용하여 관련 memory를 찾는 방법은 다음과 같습니다:

```typescript
import { MessagesZodMeta, Runtime } from "@langchain/langgraph";
import { BaseMessage } from "@langchain/core/messages";
import { registry } from "@langchain/langgraph/zod";
import * as z from "zod";

const MessagesZodState = z.object({
  messages: z
    .array(z.custom<BaseMessage>())
    .register(registry, MessagesZodMeta),
});

const updateMemory = async (
  state: z.infer<typeof MessagesZodState>,
  runtime: Runtime<{ user_id: string }>,
) => {
  // Get the user id from the config
  const userId = runtime.context?.user_id;
  if (!userId) throw new Error("User ID is required");

  // Namespace the memory
  const namespace = [userId, "memories"];

  // ... Analyze conversation and create a new memory

  // Create a new memory ID
  const memoryId = uuidv4();

  // We create a new memory
  await runtime.store?.put(namespace, memoryId, { memory });
};
```


위에서 보여준 것처럼, 모든 node에서 store에 접근하고 `store.search` method를 사용하여 memory를 가져올 수 있습니다. memory는 dictionary로 변환할 수 있는 객체의 list로 반환됩니다.



```typescript
memories[memories.length - 1];
// {
//   value: { food_preference: 'I like pizza' },
//   key: '07e0caf4-1631-47b7-b15f-65515d4c1843',
//   namespace: ['1', 'memories'],
//   createdAt: '2024-10-02T17:22:31.590602+00:00',
//   updatedAt: '2024-10-02T17:22:31.590605+00:00'
// }
```


memory에 접근하여 model 호출에 사용할 수 있습니다.



```typescript
const callModel = async (
  state: z.infer<typeof MessagesZodState>,
  config: LangGraphRunnableConfig,
  store: BaseStore
) => {
  // Get the user id from the config
  const userId = config.configurable?.user_id;

  // Namespace the memory
  const namespace = [userId, "memories"];

  // Search based on the most recent message
  const memories = await store.search(namespace, {
    query: state.messages[state.messages.length - 1].content,
    limit: 3,
  });
  const info = memories.map((d) => d.value.memory).join("\n");

  // ... Use memories in the model call
};
```


새 thread를 생성하더라도 `user_id`가 동일하면 동일한 memory에 접근할 수 있습니다.



```typescript
// Invoke the graph
const config = { configurable: { thread_id: "2", user_id: "1" } };

// Let's say hi again
for await (const update of await graph.stream(
  { messages: [{ role: "user", content: "hi, tell me about my memories" }] },
  { ...config, streamMode: "updates" }
)) {
  console.log(update);
}
```


LangSmith를 사용할 때, 로컬(예: [Studio](/langsmith/studio)) 또는 [LangSmith로 호스팅](/langsmith/hosting)하든, base store는 기본적으로 사용 가능하며 graph compilation 중에 지정할 필요가 없습니다. 그러나 semantic search를 활성화하려면 `langgraph.json` 파일에서 indexing 설정을 구성해야 **합니다**. 예를 들어:

```json
{
    ...
    "store": {
        "index": {
            "embed": "openai:text-embeddings-3-small",
            "dims": 1536,
            "fields": ["$"]
        }
    }
}
```

자세한 내용과 구성 옵션은 [deployment guide](/langsmith/semantic-search)를 참조하세요.

## Checkpointer libraries

내부적으로 checkpointing은 [`BaseCheckpointSaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseCheckpointSaver.html) interface를 준수하는 checkpointer 객체에 의해 구동됩니다. LangGraph는 모두 독립적이고 설치 가능한 library를 통해 구현된 여러 checkpointer 구현을 제공합니다:



* `@langchain/langgraph-checkpoint`: checkpointer saver의 base interface([`BaseCheckpointSaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseCheckpointSaver.html))와 serialization/deserialization interface([`SerializerProtocol`](https://langchain-ai.github.io/langgraphjs/reference/interfaces/checkpoint.SerializerProtocol.html)). 실험을 위한 in-memory checkpointer 구현([`MemorySaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.MemorySaver.html))을 포함합니다. LangGraph는 `@langchain/langgraph-checkpoint`를 포함하여 제공됩니다.
* `@langchain/langgraph-checkpoint-sqlite`: SQLite database를 사용하는 LangGraph checkpointer의 구현([`SqliteSaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint_sqlite.SqliteSaver.html)). 실험 및 로컬 workflow에 이상적입니다. 별도로 설치해야 합니다.
* `@langchain/langgraph-checkpoint-postgres`: LangSmith에서 사용되는 Postgres database를 사용하는 고급 checkpointer([`PostgresSaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint_postgres.PostgresSaver.html)). 프로덕션에서 사용하기에 이상적입니다. 별도로 설치해야 합니다.


### Checkpointer interface



각 checkpointer는 [`BaseCheckpointSaver`](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseCheckpointSaver.html) interface를 준수하며 다음 method들을 구현합니다:

* `.put` - checkpoint를 configuration 및 metadata와 함께 저장합니다.
* `.putWrites` - checkpoint에 연결된 중간 write를 저장합니다(즉, [pending writes](#pending-writes)).
* `.getTuple` - 주어진 configuration(`thread_id` 및 `checkpoint_id`)에 대한 checkpoint tuple을 가져옵니다. 이는 `graph.getState()`에서 `StateSnapshot`을 채우는 데 사용됩니다.
* `.list` - 주어진 configuration 및 filter 기준과 일치하는 checkpoint를 나열합니다. 이는 `graph.getStateHistory()`에서 state history를 채우는 데 사용됩니다.


### Serializer

checkpointer가 graph state를 저장할 때, state의 channel 값을 serialize해야 합니다. 이는 serializer 객체를 사용하여 수행됩니다.



`@langchain/langgraph-checkpoint`는 serializer를 구현하기 위한 protocol을 정의하고 LangChain 및 LangGraph primitive, datetime, enum 등을 포함한 다양한 type을 처리하는 기본 구현을 제공합니다.


## Capabilities

### Human-in-the-loop

첫째, checkpointer는 인간이 graph step을 검사, 중단 및 승인할 수 있도록 하여 [human-in-the-loop workflow](/oss/javascript/langgraph/interrupts)를 용이하게 합니다. 인간이 언제든지 graph의 state를 볼 수 있어야 하고, 인간이 state에 업데이트를 한 후 graph가 실행을 재개할 수 있어야 하므로 이러한 workflow에는 checkpointer가 필요합니다. 예제는 [how-to guide](/oss/javascript/langgraph/interrupts)를 참조하세요.

### Memory

둘째, checkpointer는 상호작용 간의 ["memory"](/oss/javascript/concepts/memory)를 허용합니다. 반복되는 인간 상호작용(대화와 같은)의 경우, 후속 메시지를 해당 thread로 보낼 수 있으며, 이는 이전 메시지의 memory를 유지합니다. checkpointer를 사용하여 대화 memory를 추가하고 관리하는 방법에 대한 정보는 [Add memory](/oss/javascript/langgraph/add-memory)를 참조하세요.

### Time Travel

셋째, checkpointer는 ["time travel"](/oss/javascript/langgraph/use-time-travel)을 허용하여 사용자가 이전 graph 실행을 재생하여 특정 graph step을 검토 및/또는 디버그할 수 있게 합니다. 또한 checkpointer는 임의의 checkpoint에서 graph state를 fork하여 대체 경로를 탐색할 수 있게 합니다.

### Fault-tolerance

마지막으로, checkpointing은 fault-tolerance와 error recovery도 제공합니다: 주어진 superstep에서 하나 이상의 node가 실패하면 마지막으로 성공한 step에서 graph를 다시 시작할 수 있습니다. 또한 주어진 superstep에서 graph node가 실행 중에 실패하면, LangGraph는 해당 superstep에서 성공적으로 완료된 다른 node들의 pending checkpoint write를 저장하므로, 해당 superstep에서 graph 실행을 재개할 때마다 성공한 node를 다시 실행하지 않습니다.

#### Pending writes

또한 주어진 superstep에서 graph node가 실행 중에 실패하면, LangGraph는 해당 superstep에서 성공적으로 완료된 다른 node들의 pending checkpoint write를 저장하므로, 해당 superstep에서 graph 실행을 재개할 때마다 성공한 node를 다시 실행하지 않습니다.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langgraph/persistence.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
