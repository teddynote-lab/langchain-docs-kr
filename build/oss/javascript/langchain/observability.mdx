---
title: 관찰 가능성
---

import observability from '/snippets/oss/observability.mdx';

관찰 가능성은 프로덕션 환경에서 에이전트가 어떻게 동작하는지 이해하는 데 매우 중요합니다. LangChain의 @[`create_agent`]를 사용하면 [LangSmith](https://smith.langchain.com/)를 통해 내장된 관찰 가능성을 얻을 수 있습니다. LangSmith는 LLM 애플리케이션을 추적, 디버깅, 평가 및 모니터링하기 위한 강력한 플랫폼입니다.

Trace는 초기 사용자 입력부터 최종 응답까지 에이전트가 수행하는 모든 단계를 캡처하며, 여기에는 모든 tool 호출, model 상호작용 및 의사결정 지점이 포함됩니다. 이를 통해 에이전트를 디버깅하고, 성능을 평가하며, 사용량을 모니터링할 수 있습니다.

## 사전 요구사항

시작하기 전에 다음 사항을 확인하세요:

* [LangSmith 계정](https://smith.langchain.com/) (무료 가입 가능)

## tracing 활성화

모든 LangChain 에이전트는 자동으로 LangSmith tracing을 지원합니다. 이를 활성화하려면 다음 환경 변수를 설정하세요:

```bash
export LANGSMITH_TRACING=true
export LANGSMITH_API_KEY=<your-api-key>
```

<Info>
API key는 [LangSmith 설정](https://smith.langchain.com/settings)에서 얻을 수 있습니다.
</Info>

## 빠른 시작

LangSmith에 trace를 기록하기 위해 추가 코드가 필요하지 않습니다. 평소처럼 에이전트 코드를 실행하기만 하면 됩니다:



```ts
import { createAgent } from "@langchain/agents";

function sendEmail(to: string, subject: string, body: string): string {
    // ... email sending logic
    return `Email sent to ${to}`;
}

function searchWeb(query: string): string {
    // ... web search logic
    return `Search results for: ${query}`;
}

const agent = createAgent({
    model: "openai:gpt-4o",
    tools: [sendEmail, searchWeb],
    systemPrompt: "You are a helpful assistant that can send emails and search the web."
});

// Run the agent - all steps will be traced automatically
const response = await agent.invoke({
    messages: [{ role: "user", content: "Search for the latest AI news and email a summary to john@example.com" }]
});
```


기본적으로 trace는 `default`라는 이름의 프로젝트에 기록됩니다. 사용자 정의 프로젝트 이름을 구성하려면 [프로젝트에 로그 기록하기](#log-to-a-project)를 참조하세요.

<observability />
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/observability.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
