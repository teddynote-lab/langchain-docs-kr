---
title: Tools
---



많은 AI 애플리케이션은 자연어를 통해 사용자와 상호작용합니다. 그러나 일부 사용 사례에서는 모델이 구조화된 입력을 사용하여 API, 데이터베이스 또는 파일 시스템과 같은 외부 시스템과 직접 인터페이스해야 합니다.

Tools는 [agents](/oss/javascript/langchain/agents)가 작업을 수행하기 위해 호출하는 컴포넌트입니다. 잘 정의된 입력과 출력을 통해 모델이 세상과 상호작용할 수 있도록 하여 모델의 기능을 확장합니다. Tools는 호출 가능한 함수와 그 입력 스키마를 캡슐화합니다. 이들은 호환되는 [chat models](/oss/javascript/langchain/models)에 전달될 수 있으며, 모델이 tool을 호출할지 여부와 어떤 인수로 호출할지 결정할 수 있게 합니다. 이러한 시나리오에서 tool calling은 모델이 지정된 입력 스키마에 부합하는 요청을 생성할 수 있도록 합니다.

<Note>
**서버 측 tool 사용**

일부 chat models(예: [OpenAI](/oss/javascript/integrations/chat/openai), [Anthropic](/oss/javascript/integrations/chat/anthropic), [Gemini](/oss/javascript/integrations/chat/google_generative_ai))는 웹 검색 및 코드 인터프리터와 같이 서버 측에서 실행되는 [built-in tools](/oss/javascript/langchain/models#server-side-tool-use)를 제공합니다. 특정 chat model에서 이러한 tools에 액세스하는 방법을 알아보려면 [provider overview](/oss/javascript/integrations/providers/overview)를 참조하세요.
</Note>

## Create tools

### Basic tool definition



tool을 생성하는 가장 간단한 방법은 `langchain` 패키지에서 `tool` 함수를 import하는 것입니다. [zod](https://zod.dev/)를 사용하여 tool의 입력 스키마를 정의할 수 있습니다:

```ts
import * as z from "zod"
import { tool } from "langchain"

const searchDatabase = tool(
  ({ query, limit }) => `Found ${limit} results for '${query}'`,
  {
    name: "search_database",
    description: "Search the customer database for records matching the query.",
    schema: z.object({
      query: z.string().describe("Search terms to look for"),
      limit: z.number().describe("Maximum number of results to return"),
    }),
  }
);
```




## Accessing Context

<Info>
**중요한 이유:** Tools는 agent state, runtime context, 장기 메모리에 액세스할 수 있을 때 가장 강력합니다. 이를 통해 tools는 컨텍스트 인식 결정을 내리고, 응답을 개인화하며, 대화 전반에 걸쳐 정보를 유지할 수 있습니다.
</Info>

Tools는 `ToolRuntime` 매개변수를 통해 런타임 정보에 액세스할 수 있으며, 다음을 제공합니다:

- **State** - 실행을 통해 흐르는 가변 데이터(messages, counters, custom fields)
- **Context** - user IDs, session details 또는 애플리케이션별 구성과 같은 불변 구성
- **Store** - 대화 전반에 걸친 영구적인 장기 메모리
- **Stream Writer** - tools가 실행될 때 사용자 정의 업데이트 스트리밍
- **Config** - 실행을 위한 RunnableConfig
- **Tool Call ID** - 현재 tool call의 ID

### ToolRuntime

`ToolRuntime`을 사용하여 단일 매개변수로 모든 런타임 정보에 액세스하세요. tool 시그니처에 `runtime: ToolRuntime`을 추가하기만 하면 LLM에 노출되지 않고 자동으로 주입됩니다.

<Info>
**`ToolRuntime`**: tools가 state, context, store, streaming, config, tool call ID에 액세스할 수 있도록 하는 통합 매개변수입니다. 이는 별도의 @[`InjectedState`], @[`InjectedStore`], @[`get_runtime`], @[`InjectedToolCallId`] annotations를 사용하는 이전 패턴을 대체합니다.
</Info>



#### Context

`runtime.context`를 통해 user IDs, session details 또는 애플리케이션별 구성과 같은 불변 구성 및 컨텍스트 데이터에 액세스하세요.



Tools는 `config` 매개변수를 통해 agent의 runtime context에 액세스할 수 있습니다:

```ts wrap
import * as z from "zod"
import { ChatOpenAI } from "@langchain/openai"
import { createAgent } from "langchain"

const getUserName = tool(
  (_, config) => {
    return config.context.user_name
  },
  {
    name: "get_user_name",
    description: "Get the user's name.",
    schema: z.object({}),
  }
);

const contextSchema = z.object({
  user_name: z.string(),
});

const agent = createAgent({
  model: new ChatOpenAI({ model: "gpt-4o" }),
  tools: [getUserName],
  contextSchema,
});

const result = await agent.invoke(
  {
    messages: [{ role: "user", content: "What is my name?" }]
  },
  {
    context: { user_name: "John Smith" }
  }
);
```


#### Memory (Store)

store를 사용하여 대화 전반에 걸쳐 영구 데이터에 액세스하세요. store는 `runtime.store`를 통해 액세스되며 사용자별 또는 애플리케이션별 데이터를 저장하고 검색할 수 있습니다.



```ts wrap expandable
import * as z from "zod";
import { createAgent, tool } from "langchain";
import { InMemoryStore } from "@langchain/langgraph";
import { ChatOpenAI } from "@langchain/openai";

const store = new InMemoryStore();

// Access memory
const getUserInfo = tool(
  async ({ user_id }) => {
    const value = await store.get(["users"], user_id);
    console.log("get_user_info", user_id, value);
    return value;
  },
  {
    name: "get_user_info",
    description: "Look up user info.",
    schema: z.object({
      user_id: z.string(),
    }),
  }
);

// Update memory
const saveUserInfo = tool(
  async ({ user_id, name, age, email }) => {
    console.log("save_user_info", user_id, name, age, email);
    await store.put(["users"], user_id, { name, age, email });
    return "Successfully saved user info.";
  },
  {
    name: "save_user_info",
    description: "Save user info.",
    schema: z.object({
      user_id: z.string(),
      name: z.string(),
      age: z.number(),
      email: z.string(),
    }),
  }
);

const agent = createAgent({
  model: new ChatOpenAI({ model: "gpt-4o" }),
  tools: [getUserInfo, saveUserInfo],
  store,
});

// First session: save user info
await agent.invoke({
  messages: [
    {
      role: "user",
      content: "Save the following user: userid: abc123, name: Foo, age: 25, email: foo@langchain.dev",
    },
  ],
});

// Second session: get user info
const result = await agent.invoke({
  messages: [
    { role: "user", content: "Get user info for user with id 'abc123'" },
  ],
});

console.log(result);
// Here is the user info for user with ID "abc123":
// - Name: Foo
// - Age: 25
// - Email: foo@langchain.dev
```


#### Stream Writer

`runtime.stream_writer`를 사용하여 tools가 실행될 때 사용자 정의 업데이트를 스트리밍하세요. 이는 tool이 수행하는 작업에 대한 실시간 피드백을 사용자에게 제공하는 데 유용합니다.



```ts wrap
import * as z from "zod";
import { tool } from "langchain";

const getWeather = tool(
  ({ city }, config) => {
    const writer = config.streamWriter;

    // Stream custom updates as the tool executes
    writer(`Looking up data for city: ${city}`);
    writer(`Acquired data for city: ${city}`);

    return `It's always sunny in ${city}!`;
  },
  {
    name: "get_weather",
    description: "Get weather for a given city.",
    schema: z.object({
      city: z.string(),
    }),
  }
);
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/tools.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
