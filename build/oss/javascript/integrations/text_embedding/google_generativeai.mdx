---
title: GoogleGenerativeAIEmbeddings
---

이 가이드는 LangChain을 사용하여 Google Generative AI [embedding models](/oss/javascript/integrations/text_embedding)를 시작하는 데 도움을 드립니다. `GoogleGenerativeAIEmbeddings`의 기능 및 구성 옵션에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html)를 참조하세요.

## Overview

### Integration details

| Class | Package | Local | [Py support](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/) | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: |
| [`GoogleGenerativeAIEmbeddings`](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html) | [`@langchain/google-genai`](https://npmjs.com/@langchain/google-genai) | ❌ | ✅ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/google-genai?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/google-genai?style=flat-square&label=%20&) |

## Setup

Google Generative AI embedding models에 액세스하려면 Google AI 계정에 가입하고, API 키를 받고, `@langchain/google-genai` integration package를 설치해야 합니다.

### Credentials

여기에서 API 키를 받으세요: [ai.google.dev/tutorials/setup](https://ai.google.dev/tutorials/setup).

다음으로, 키를 `GOOGLE_API_KEY`라는 이름의 environment variable로 설정하세요:

```bash
export GOOGLE_API_KEY="your-api-key"
```

모델 호출에 대한 자동 추적을 원하시면 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정할 수도 있습니다:

```bash
# export LANGSMITH_TRACING="true"
# export LANGSMITH_API_KEY="your-api-key"
```

### Installation

LangChain `GoogleGenerativeAIEmbeddings` integration은 `@langchain/google-genai` package에 있습니다. 공식 SDK도 설치하는 것이 좋습니다:

<CodeGroup>
```bash npm
npm install @langchain/google-genai @langchain/core @google/generative-ai
```
```bash yarn
yarn add @langchain/google-genai @langchain/core @google/generative-ai
```
```bash pnpm
pnpm add @langchain/google-genai @langchain/core @google/generative-ai
```
</CodeGroup>

## Instantiation

이제 model object를 인스턴스화하고 텍스트를 embed할 수 있습니다:

```typescript
import { GoogleGenerativeAIEmbeddings } from "@langchain/google-genai";
import { TaskType } from "@google/generative-ai";

const embeddings = new GoogleGenerativeAIEmbeddings({
  model: "gemini-embedding-001", // 768 dimensions
  taskType: TaskType.RETRIEVAL_DOCUMENT,
  title: "Document title",
});
```

## Indexing and Retrieval

Embedding models는 데이터 인덱싱과 나중에 검색하는 과정 모두에서 retrieval-augmented generation (RAG) 플로우에 자주 사용됩니다. 더 자세한 지침은 [**Learn** 탭](/oss/javascript/learn/)의 RAG 튜토리얼을 참조하세요.

아래에서는 위에서 초기화한 `embeddings` object를 사용하여 데이터를 인덱싱하고 검색하는 방법을 확인할 수 있습니다. 이 예제에서는 데모 [`MemoryVectorStore`](/oss/javascript/integrations/vectorstores/memory)를 사용하여 샘플 문서를 인덱싱하고 검색합니다.

```typescript
// Create a vector store with a sample text
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";

const text = "LangChain is the framework for building context-aware reasoning applications";

const vectorstore = await MemoryVectorStore.fromDocuments(
  [{ pageContent: text, metadata: {} }],
  embeddings,
);

// Use the vector store as a retriever that returns a single document
const retriever = vectorstore.asRetriever(1);

// Retrieve the most similar text
const retrievedDocuments = await retriever.invoke("What is LangChain?");

retrievedDocuments[0].pageContent;
```

```output
LangChain is the framework for building context-aware reasoning applications
```

## Direct Usage

내부적으로 vectorstore와 retriever 구현은 `embeddings.embedDocument(...)`와 `embeddings.embedQuery(...)`를 호출하여 `fromDocuments`와 retriever의 `invoke` 작업에 사용되는 텍스트에 대한 embeddings를 생성합니다.

이러한 메서드를 직접 호출하여 자신의 사용 사례에 맞는 embeddings를 얻을 수 있습니다.

### Embed single texts

검색을 위해 `embedQuery`로 쿼리를 embed할 수 있습니다. 이는 쿼리에 특화된 vector representation을 생성합니다:

```typescript
const singleVector = await embeddings.embedQuery(text);

console.log(singleVector.slice(0, 100));
```

```output
[
  -0.018286658,   0.020051053,  -0.057487167,   0.0059406986, -0.0036901247,
  -0.010400916,    0.03396853,  -0.010867519,    0.015650319,   0.026443942,
   0.012251757,   -0.01581729,    0.02031182, -0.00062176475,  0.0065521155,
   -0.07107355,   0.033614952,    0.07109807,   -0.021078493,   0.048039366,
   0.022973344,    -0.0361746,   -0.04550704,   -0.048807852,    0.03414146,
   0.042450827,    0.02930612,   0.027274853,   -0.027707053,   -0.04167595,
    0.01708843,   0.028532283, -0.0018593844,      -0.096786,  -0.034648854,
  0.0013152987,   0.024425535,    0.04937838,    0.036890924,  -0.074619934,
  -0.028723065,   0.029158255,  -0.023993572,     0.03163398,   -0.02036324,
   -0.02333609,  -0.017407075, -0.0059643993,    -0.05564625,   0.051022638,
    0.03264913,  -0.008254581,  -0.030552095,    0.072952054,   -0.05448913,
   0.012030814,   -0.07978849,  -0.030417662,   0.0038343794,    0.03237516,
  -0.054259773,    -0.0524064,   -0.02145499,    0.006439614,    0.04988943,
   -0.03232189,    0.00990776,   -0.03863326,    -0.04979561,   0.009874035,
   -0.02617946,    0.02135152,  -0.070599854,     0.08655627,   -0.02080979,
  -0.014944934,  0.0034440767,  -0.035236854,    0.027093545,   0.032249685,
   -0.03559674,   0.046849757,    0.06965356,    0.028780492,    0.02865287,
   -0.07999455, -0.0058599655,  -0.050316703,   -0.018346578,  -0.038311094,
    0.08026719,   0.049136136,   -0.05372233,  -0.0062247813,    0.01791339,
   -0.03635157,  -0.031860247,  -0.031322744,    0.044055287,   0.034934316
]
```

### Embed multiple texts

인덱싱을 위해 `embedDocuments`로 여러 텍스트를 embed할 수 있습니다. 이 메서드에 사용되는 내부 구현은 쿼리 embedding과 다를 수 있습니다(반드시 그런 것은 아닙니다):

```typescript
const text2 = "LangGraph is a library for building stateful, multi-actor applications with LLMs";

const vectors = await embeddings.embedDocuments([text, text2]);

console.log(vectors[0].slice(0, 100));
console.log(vectors[1].slice(0, 100));
```

```output
[
  -0.018286658,   0.020051053,  -0.057487167,   0.0059406986, -0.0036901247,
  -0.010400916,    0.03396853,  -0.010867519,    0.015650319,   0.026443942,
   0.012251757,   -0.01581729,    0.02031182, -0.00062176475,  0.0065521155,
   -0.07107355,   0.033614952,    0.07109807,   -0.021078493,   0.048039366,
   0.022973344,    -0.0361746,   -0.04550704,   -0.048807852,    0.03414146,
   0.042450827,    0.02930612,   0.027274853,   -0.027707053,   -0.04167595,
    0.01708843,   0.028532283, -0.0018593844,      -0.096786,  -0.034648854,
  0.0013152987,   0.024425535,    0.04937838,    0.036890924,  -0.074619934,
  -0.028723065,   0.029158255,  -0.023993572,     0.03163398,   -0.02036324,
   -0.02333609,  -0.017407075, -0.0059643993,    -0.05564625,   0.051022638,
    0.03264913,  -0.008254581,  -0.030552095,    0.072952054,   -0.05448913,
   0.012030814,   -0.07978849,  -0.030417662,   0.0038343794,    0.03237516,
  -0.054259773,    -0.0524064,   -0.02145499,    0.006439614,    0.04988943,
   -0.03232189,    0.00990776,   -0.03863326,    -0.04979561,   0.009874035,
   -0.02617946,    0.02135152,  -0.070599854,     0.08655627,   -0.02080979,
  -0.014944934,  0.0034440767,  -0.035236854,    0.027093545,   0.032249685,
   -0.03559674,   0.046849757,    0.06965356,    0.028780492,    0.02865287,
   -0.07999455, -0.0058599655,  -0.050316703,   -0.018346578,  -0.038311094,
    0.08026719,   0.049136136,   -0.05372233,  -0.0062247813,    0.01791339,
   -0.03635157,  -0.031860247,  -0.031322744,    0.044055287,   0.034934316
]
[
    0.011669316,    0.02170385,   -0.07519182,     0.003981285,
   0.0053525288,   0.008397044,   0.036672726,     0.016549919,
    0.061946314,    0.06280753,  -0.009199135,     0.014644887,
    0.046459496,  0.0122919325,  -0.013300706,    -0.051746193,
     -0.0490098,   0.045586824,   -0.05053146,     0.044294067,
   -0.012607168, -0.0071777054,  -0.048455723,    -0.075109236,
    0.013327612,  -0.025612017,   0.050875787,     0.030091539,
   -0.027163379,   -0.05760821,   0.014368641,    0.0044602253,
    0.035219245,  -0.033304706,  -0.045474708,    -0.038022216,
    0.012366698,   0.028978042,   0.038591366,     -0.10646444,
   -0.036803752,   0.018911313,   0.005681761,     0.025365992,
   -0.017165288, -0.0048005017,  -0.011460135,    0.0027811683,
    -0.04971402, -0.0019232291,    0.02141983,   -0.0013272346,
    -0.03337951,   0.030568397,   -0.05704511,     -0.01187748,
   -0.025354648,   0.016188234,  -0.022018699,    0.0096449675,
   -0.027020318,  -0.038059015,  -0.024455398,     0.021858294,
    0.010713859,   -0.07203855,   -0.05562406, 0.0000034690818,
   -0.054289237, -0.0027928432, -0.0010051605,     0.008493095,
   -0.064746305,   0.024419345,  -0.016629996,     -0.02686531,
    -0.02300653,   -0.03263113,   0.019998727,     0.029680967,
    -0.04365641,   0.013594972,   0.056486532,     0.025913332,
    0.025457978,  -0.048536208,   0.020046104,     -0.05857287,
   -0.032664414,  -0.032940287,    0.10053288,    -0.021389635,
  -0.0044220444,   0.037026003,    0.03142132,    -0.048912503,
    -0.07961264,  -0.051056523,   0.048032805,      0.04831778
]
```

## API reference

모든 `GoogleGenerativeAIEmbeddings` 기능 및 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain_google_genai.GoogleGenerativeAIEmbeddings.html)를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/text_embedding/google_generativeai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
