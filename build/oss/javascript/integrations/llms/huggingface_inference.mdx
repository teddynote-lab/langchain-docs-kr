---
title: HuggingFaceInference
---

다음은 HuggingFaceInference 모델을 LLM으로 호출하는 예제입니다:

```bash npm
npm install @langchain/community @langchain/core @huggingface/inference@4
```

<Tip>
모든 패키지에서 model parameter를 통합하고 있습니다. 이제 `modelName` 대신 `model`을 사용하고, API key는 `apiKey`를 사용할 것을 권장합니다.
</Tip>

```typescript
import { HuggingFaceInference } from "@langchain/community/llms/hf";

const model = new HuggingFaceInference({
  model: "gpt2",
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});
const res = await model.invoke("1 + 1 =");
console.log({ res });
```

## 관련 문서


- [Models 가이드](/oss/javascript/langchain/models)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/llms/huggingface_inference.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
