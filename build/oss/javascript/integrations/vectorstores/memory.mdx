---
title: MemoryVectorStore
---

LangChain은 embedding을 메모리에 저장하고 가장 유사한 embedding을 정확하게 선형 검색하는 인메모리, 임시 vectorstore를 제공합니다. 기본 유사도 메트릭은 cosine similarity이지만, [ml-distance](https://mljs.github.io/distance/modules/similarity.html)에서 지원하는 모든 유사도 메트릭으로 변경할 수 있습니다.

데모용으로 설계되었기 때문에 아직 id나 삭제 기능을 지원하지 않습니다.

이 가이드는 인메모리 [`vector stores`](/oss/javascript/integrations/vectorstores) 시작하기에 대한 간단한 개요를 제공합니다. 모든 `MemoryVectorStore` 기능과 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain.vectorstores_memory.MemoryVectorStore.html)를 참조하세요.

## 개요

### Integration 세부 정보

| Class | Package | PY support |  Version |
| :--- | :--- | :---: | :---: |
| [`MemoryVectorStore`](https://api.js.langchain.com/classes/langchain.vectorstores_memory.MemoryVectorStore.html) | [`langchain`](https://www.npmjs.com/package/langchain) | ❌ |  ![NPM - Version](https://img.shields.io/npm/v/langchain?style=flat-square&label=%20&) |

## 설정

인메모리 vector store를 사용하려면 `langchain` 패키지를 설치해야 합니다:

이 가이드는 [OpenAI embeddings](/oss/javascript/integrations/text_embedding/openai)도 사용하며, 이를 위해 `@langchain/openai` integration 패키지를 설치해야 합니다. 원하는 경우 [다른 지원되는 embeddings 모델](/oss/javascript/integrations/text_embedding)을 사용할 수도 있습니다.

<CodeGroup>
```bash npm
npm install langchain @langchain/openai @langchain/core
```
```bash yarn
yarn add langchain @langchain/openai @langchain/core
```
```bash pnpm
pnpm add langchain @langchain/openai @langchain/core
```
</CodeGroup>

### 자격 증명

인메모리 vector store를 사용하는 데 필요한 자격 증명은 없습니다.

이 가이드에서 OpenAI embeddings를 사용하는 경우 OpenAI key도 설정해야 합니다:

```typescript
process.env.OPENAI_API_KEY = "YOUR_API_KEY";
```

모델 호출에 대한 자동 추적을 원하는 경우 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API key를 설정할 수도 있습니다:

```typescript
// process.env.LANGSMITH_TRACING="true"
// process.env.LANGSMITH_API_KEY="your-api-key"
```

## 인스턴스화

```typescript
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";
import { OpenAIEmbeddings } from "@langchain/openai";

const embeddings = new OpenAIEmbeddings({
  model: "text-embedding-3-small",
});

const vectorStore = new MemoryVectorStore(embeddings);
```

## Vector store 관리

### Vector store에 항목 추가

```typescript
import type { Document } from "@langchain/core/documents";

const document1: Document = {
  pageContent: "The powerhouse of the cell is the mitochondria",
  metadata: { source: "https://example.com" }
};

const document2: Document = {
  pageContent: "Buildings are made out of brick",
  metadata: { source: "https://example.com" }
};

const document3: Document = {
  pageContent: "Mitochondria are made out of lipids",
  metadata: { source: "https://example.com" }
};

const documents = [document1, document2, document3];

await vectorStore.addDocuments(documents);
```

## Vector store 쿼리

Vector store가 생성되고 관련 문서가 추가되면 chain이나 agent를 실행하는 동안 쿼리하고 싶을 것입니다.

### 직접 쿼리

간단한 유사도 검색은 다음과 같이 수행할 수 있습니다:

```typescript
const filter = (doc) => doc.metadata.source === "https://example.com";

const similaritySearchResults = await vectorStore.similaritySearch("biology", 2, filter)

for (const doc of similaritySearchResults) {
  console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);
}
```

```output
* The powerhouse of the cell is the mitochondria [{"source":"https://example.com"}]
* Mitochondria are made out of lipids [{"source":"https://example.com"}]
```

filter는 선택 사항이며, 문서를 입력으로 받아 문서를 반환해야 하는지 여부에 따라 `true` 또는 `false`를 반환하는 predicate function이어야 합니다.

유사도 검색을 실행하고 해당 점수를 받으려면 다음을 실행할 수 있습니다:

```typescript
const similaritySearchWithScoreResults = await vectorStore.similaritySearchWithScore("biology", 2, filter)

for (const [doc, score] of similaritySearchWithScoreResults) {
  console.log(`* [SIM=${score.toFixed(3)}] ${doc.pageContent} [${JSON.stringify(doc.metadata)}]`);
}
```

```output
* [SIM=0.165] The powerhouse of the cell is the mitochondria [{"source":"https://example.com"}]
* [SIM=0.148] Mitochondria are made out of lipids [{"source":"https://example.com"}]
```

### Retriever로 변환하여 쿼리

Vector store를 [retriever](/oss/javascript/langchain/retrieval)로 변환하여 chain에서 더 쉽게 사용할 수도 있습니다:

```typescript
const retriever = vectorStore.asRetriever({
  // Optional filter
  filter: filter,
  k: 2,
});

await retriever.invoke("biology");
```

```output
[
  Document {
    pageContent: 'The powerhouse of the cell is the mitochondria',
    metadata: { source: 'https://example.com' },
    id: undefined
  },
  Document {
    pageContent: 'Mitochondria are made out of lipids',
    metadata: { source: 'https://example.com' },
    id: undefined
  }
]
```

### Maximal marginal relevance

이 vector store는 maximal marginal relevance (MMR)도 지원합니다. 이는 먼저 classic similarity search로 더 많은 수의 결과(`searchKwargs.fetchK`로 지정)를 가져온 다음, 다양성을 위해 재순위를 매기고 상위 `k`개의 결과를 반환하는 기술입니다. 이는 중복 정보를 방지하는 데 도움이 됩니다:

```typescript
const mmrRetriever = vectorStore.asRetriever({
  searchType: "mmr",
  searchKwargs: {
    fetchK: 10,
  },
  // Optional filter
  filter: filter,
  k: 2,
});

await mmrRetriever.invoke("biology");
```

```output
[
  Document {
    pageContent: 'The powerhouse of the cell is the mitochondria',
    metadata: { source: 'https://example.com' },
    id: undefined
  },
  Document {
    pageContent: 'Buildings are made out of brick',
    metadata: { source: 'https://example.com' },
    id: undefined
  }
]
```

### Retrieval-augmented generation 사용

이 vector store를 retrieval-augmented generation (RAG)에 사용하는 방법에 대한 가이드는 다음 섹션을 참조하세요:

- [LangChain으로 RAG 앱 구축하기](/oss/javascript/langchain/rag)
- [Agentic RAG](/oss/javascript/langgraph/agentic-rag)
- [Retrieval 문서](/oss/javascript/langchain/retrieval)

## API reference

모든 `MemoryVectorStore` 기능과 구성에 대한 자세한 문서는 [API reference](https://api.js.langchain.com/classes/langchain.vectorstores_memory.MemoryVectorStore.html)를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/vectorstores/memory.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
