```markdown
---
title: Bedrock (Knowledge Bases)
---

이 가이드는 AWS Knowledge Bases [retriever](/oss/python/langchain/retrieval)를 시작하는 데 도움을 드립니다.

[Knowledge Bases for Amazon Bedrock](https://aws.amazon.com/bedrock/knowledge-bases/)은 Amazon Web Services(AWS)에서 제공하는 서비스로, 비공개 데이터를 사용하여 FM 응답을 커스터마이징함으로써 RAG 애플리케이션을 빠르게 구축할 수 있게 해줍니다.

`RAG`를 구현하려면 조직은 데이터를 embedding(벡터)으로 변환하고, embedding을 특수한 vector database에 저장하며, 사용자의 쿼리와 관련된 텍스트를 검색하고 가져오기 위해 데이터베이스에 대한 커스텀 통합을 구축하는 등 여러 번거로운 단계를 수행해야 합니다. 이는 시간이 많이 걸리고 비효율적일 수 있습니다.

`Knowledge Bases for Amazon Bedrock`을 사용하면 `Amazon S3`에서 데이터의 위치를 지정하기만 하면 되며, `Knowledge Bases for Amazon Bedrock`이 vector database로의 전체 수집 워크플로우를 처리합니다. 기존 vector database가 없는 경우, Amazon Bedrock이 Amazon OpenSearch Serverless vector store를 자동으로 생성합니다. 검색을 위해서는 Retrieve API를 통해 LangChain - Amazon Bedrock 통합을 사용하여 knowledge base에서 사용자 쿼리에 대한 관련 결과를 검색할 수 있습니다.

### Integration 세부 정보

<ItemTable category="document_retrievers" item="AmazonKnowledgeBasesRetriever" />

## Setup

Knowledge Bases는 [AWS Console](https://aws.amazon.com/console/)을 통해 또는 [AWS SDKs](https://aws.amazon.com/developer/tools/)를 사용하여 구성할 수 있습니다. retriever를 인스턴스화하려면 `knowledge_base_id`가 필요합니다.

개별 쿼리에서 자동화된 추적을 원하는 경우, 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API key를 설정할 수도 있습니다:

```python
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

이 retriever는 `langchain-aws` 패키지에 포함되어 있습니다:

```python
pip install -qU langchain-aws
```

## Instantiation

이제 retriever를 인스턴스화할 수 있습니다:

```python
from langchain_aws.retrievers import AmazonKnowledgeBasesRetriever

retriever = AmazonKnowledgeBasesRetriever(
    knowledge_base_id="PUIJP4EQUA",
    retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 4}},
)
```

## Usage

```python
query = "What did the president say about Ketanji Brown?"

retriever.invoke(query)
```

## chain 내에서 사용하기

```python
from botocore.client import Config
from langchain.chains import RetrievalQA
from langchain_aws import Bedrock

model_kwargs_claude = {"temperature": 0, "top_k": 10, "max_tokens_to_sample": 3000}

llm = Bedrock(model_id="anthropic.claude-v2", model_kwargs=model_kwargs_claude)

qa = RetrievalQA.from_chain_type(
    llm=llm, retriever=retriever, return_source_documents=True
)

qa(query)
```

## API reference

모든 `AmazonKnowledgeBasesRetriever` 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/aws/retrievers/langchain_aws.retrievers.bedrock.AmazonKnowledgeBasesRetriever.html)를 참조하세요.
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/retrievers/bedrock.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
