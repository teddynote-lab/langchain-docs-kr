---
title: GreenNodeEmbeddings
---

>[GreenNode](https://greennode.ai/)는 글로벌 AI 솔루션 제공업체이자 **NVIDIA Preferred Partner**로, 미국, MENA, APAC 지역의 기업들에게 인프라부터 애플리케이션까지 풀스택 AI 역량을 제공합니다. **세계적 수준의 인프라**(LEED Gold, TIA‑942, Uptime Tier III)를 기반으로 운영되는 GreenNode는 기업, 스타트업, 연구자들에게 포괄적인 AI 서비스 제품군을 제공합니다.

이 가이드는 `GreenNodeEmbeddings` 시작하기를 위한 안내를 제공합니다. 다양한 내장 connector 또는 사용자 정의 데이터 소스를 사용하여 고품질 텍스트 벡터 표현을 생성함으로써 의미론적 문서 검색을 수행할 수 있습니다.

## Overview

### Integration details

| Provider | Package |
|:--------:|:-------:|
| [GreenNode](/oss/python/integrations/providers/greennode/) | [langchain-greennode](https://python.langchain.com/v0.2/api_reference/langchain_greennode/embeddings/langchain_greennode.embeddingsGreenNodeEmbeddings.html) |

## Setup

GreenNode embedding model에 액세스하려면 GreenNode 계정을 생성하고, API key를 받고, `langchain-greennode` integration package를 설치해야 합니다.

### Credentials

GreenNode는 인증을 위해 API key가 필요하며, 초기화 시 `api_key` parameter로 제공하거나 환경 변수 `GREENNODE_API_KEY`로 설정할 수 있습니다. [GreenNode Serverless AI](https://aiplatform.console.greennode.ai/playground)에서 계정을 등록하여 API key를 얻을 수 있습니다.

```python
import getpass
import os

if not os.getenv("GREENNODE_API_KEY"):
    os.environ["GREENNODE_API_KEY"] = getpass.getpass("Enter your GreenNode API key: ")
```

model 호출에 대한 자동 추적을 원하시면 아래 주석을 해제하여 [LangSmith](https://docs.smith.langchain.com/) API key를 설정할 수도 있습니다:

```python
os.environ["LANGSMITH_TRACING"] = "true"
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
```

### Installation

LangChain GreenNode integration은 `langchain-greennode` package에 있습니다:

```python
pip install -qU langchain-greennode
```

```output
Note: you may need to restart the kernel to use updated packages.
```

## Instantiation

`GreenNodeEmbeddings` class는 API key와 model 이름에 대한 선택적 parameter로 인스턴스화할 수 있습니다:

```python
from langchain_greennode import GreenNodeEmbeddings

# Initialize the embeddings model
embeddings = GreenNodeEmbeddings(
    # api_key="YOUR_API_KEY",  # You can pass the API key directly
    model="BAAI/bge-m3"  # The default embedding model
)
```

## Indexing and Retrieval

Embedding model은 콘텐츠의 indexing과 효율적인 retrieval을 가능하게 함으로써 retrieval-augmented generation (RAG) workflow에서 핵심적인 역할을 합니다.
아래에서 위에서 초기화한 `embeddings` 객체를 사용하여 데이터를 index하고 retrieve하는 방법을 확인하세요. 이 예제에서는 `InMemoryVectorStore`에서 샘플 문서를 index하고 retrieve합니다.

```python
# Create a vector store with a sample text
from langchain_core.vectorstores import InMemoryVectorStore

text = "LangChain is the framework for building context-aware reasoning applications"

vectorstore = InMemoryVectorStore.from_texts(
    [text],
    embedding=embeddings,
)

# Use the vectorstore as a retriever
retriever = vectorstore.as_retriever()

# Retrieve the most similar text
retrieved_documents = retriever.invoke("What is LangChain?")

# show the retrieved document's content
retrieved_documents[0].page_content
```

```output
'LangChain is the framework for building context-aware reasoning applications'
```

## Direct Usage

`GreenNodeEmbeddings` class는 vector store 없이도 독립적으로 텍스트 embedding을 생성하는 데 사용할 수 있습니다. 이는 유사도 점수 계산, 클러스터링 또는 사용자 정의 처리 pipeline과 같은 작업에 유용합니다.

### Embed single texts

`embed_query`로 단일 텍스트 또는 문서를 embed할 수 있습니다:

```python
single_vector = embeddings.embed_query(text)
print(str(single_vector)[:100])  # Show the first 100 characters of the vector
```

```output
[-0.01104736328125, -0.0281982421875, 0.0035858154296875, -0.0311279296875, -0.0106201171875, -0.039
```

### Embed multiple texts

`embed_documents`로 여러 텍스트를 embed할 수 있습니다:

```python
text2 = (
    "LangGraph is a library for building stateful, multi-actor applications with LLMs"
)
two_vectors = embeddings.embed_documents([text, text2])
for vector in two_vectors:
    print(str(vector)[:100])  # Show the first 100 characters of the vector
```

```output
[-0.01104736328125, -0.0281982421875, 0.0035858154296875, -0.0311279296875, -0.0106201171875, -0.039
[-0.07177734375, -0.00017452239990234375, -0.002044677734375, -0.0299072265625, -0.0184326171875, -0
```

### Async Support

GreenNodeEmbeddings는 async 작업을 지원합니다:

```python
import asyncio


async def generate_embeddings_async():
    # Embed a single query
    query_result = await embeddings.aembed_query("What is the capital of France?")
    print(f"Async query embedding dimension: {len(query_result)}")

    # Embed multiple documents
    docs = [
        "Paris is the capital of France",
        "Berlin is the capital of Germany",
        "Rome is the capital of Italy",
    ]
    docs_result = await embeddings.aembed_documents(docs)
    print(f"Async document embeddings count: {len(docs_result)}")


await generate_embeddings_async()
```

```output
Async query embedding dimension: 1024
Async document embeddings count: 3
```

### Document Similarity Example

```python
import numpy as np
from scipy.spatial.distance import cosine

# Create some documents
documents = [
    "Machine learning algorithms build mathematical models based on sample data",
    "Deep learning uses neural networks with many layers",
    "Climate change is a major global environmental challenge",
    "Neural networks are inspired by the human brain's structure",
]

# Embed the documents
embeddings_list = embeddings.embed_documents(documents)


# Function to calculate similarity
def calculate_similarity(embedding1, embedding2):
    return 1 - cosine(embedding1, embedding2)


# Print similarity matrix
print("Document Similarity Matrix:")
for i, emb_i in enumerate(embeddings_list):
    similarities = []
    for j, emb_j in enumerate(embeddings_list):
        similarity = calculate_similarity(emb_i, emb_j)
        similarities.append(f"{similarity:.4f}")
    print(f"Document {i + 1}: {similarities}")
```

```output
Document Similarity Matrix:
Document 1: ['1.0000', '0.6005', '0.3542', '0.5788']
Document 2: ['0.6005', '1.0000', '0.4154', '0.6170']
Document 3: ['0.3542', '0.4154', '1.0000', '0.3528']
Document 4: ['0.5788', '0.6170', '0.3528', '1.0000']
```

## API reference

GreenNode Serverless AI API에 대한 자세한 내용은 [GreenNode Serverless AI Documentation](https://aiplatform.console.greennode.ai/api-docs/maas)을 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/text_embedding/greennode.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
