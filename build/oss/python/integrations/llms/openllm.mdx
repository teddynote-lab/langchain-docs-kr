---
title: OpenLLM
---

[ğŸ¦¾ OpenLLM](https://github.com/bentoml/OpenLLM)ì€ ê°œë°œìê°€ **ë‹¨ì¼ ëª…ë ¹**ìœ¼ë¡œ ëª¨ë“  **ì˜¤í”ˆì†ŒìŠ¤ LLM**ì„ **OpenAI í˜¸í™˜ API** endpointë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.

- ğŸ”¬ ë¹ ë¥´ê³  í”„ë¡œë•ì…˜ ì‚¬ìš©ì„ ìœ„í•´ êµ¬ì¶•ë¨
- ğŸš‚ llama3, qwen2, gemma ë“±ê³¼ ë§ì€ **ì–‘ìí™”ëœ** ë²„ì „ ì§€ì› [ì „ì²´ ëª©ë¡](https://github.com/bentoml/openllm-models)
- â›“ï¸ OpenAI í˜¸í™˜ API
- ğŸ’¬ ë‚´ì¥ëœ ChatGPT ìŠ¤íƒ€ì¼ UI
- ğŸ”¥ ìµœì²¨ë‹¨ inference backendë¥¼ í†µí•œ ê°€ì†í™”ëœ LLM ë””ì½”ë”©
- ğŸŒ¥ï¸ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ í´ë¼ìš°ë“œ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ (Kubernetes, Docker ë° BentoCloud)

## ì„¤ì¹˜

[PyPI](https://pypi.org/project/openllm/)ë¥¼ í†µí•´ `openllm` ì„¤ì¹˜

```python
pip install -qU  openllm
```

## ë¡œì»¬ì—ì„œ OpenLLM server ì‹¤í–‰í•˜ê¸°

LLM serverë¥¼ ì‹œì‘í•˜ë ¤ë©´ `openllm hello` ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”:

```bash
openllm hello
```

## Wrapper

```python
from langchain_community.llms import OpenLLM

server_url = "http://localhost:3000"  # Replace with remote host if you are running on a remote server
llm = OpenLLM(base_url=server_url, api_key="na")
```

```python
llm("To build a LLM from scratch, the following are the steps:")
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/llms/openllm.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
