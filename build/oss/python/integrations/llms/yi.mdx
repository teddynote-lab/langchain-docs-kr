---
title: Yi
---

[01.AI](https://www.lingyiwanwu.com/en)는 Dr. Kai-Fu Lee가 설립한 AI 2.0의 최전선에 있는 글로벌 기업입니다. 6B부터 수천억 개의 parameter에 이르는 Yi 시리즈를 포함한 최첨단 large language model을 제공합니다. 01.AI는 또한 multimodal model, open API platform, 그리고 Yi-34B/9B/6B 및 Yi-VL과 같은 open-source 옵션을 제공합니다.

```python
## Installing the langchain packages needed to use the integration
pip install -qU langchain-community
```

## 사전 요구사항

Yi LLM API에 접근하려면 API key가 필요합니다. [www.lingyiwanwu.com/](https://www.lingyiwanwu.com/)을 방문하여 API key를 발급받으세요. API key를 신청할 때 국내(중국) 또는 국제 사용 여부를 지정해야 합니다.

## Yi LLM 사용하기

```python
import os

os.environ["YI_API_KEY"] = "YOUR_API_KEY"

from langchain_community.llms import YiLLM

# Load the model
llm = YiLLM(model="yi-large")

# You can specify the region if needed (default is "auto")
# llm = YiLLM(model="yi-large", region="domestic")  # or "international"

# Basic usage
res = llm.invoke("What's your name?")
print(res)
```

```python
# Generate method
res = llm.generate(
    prompts=[
        "Explain the concept of large language models.",
        "What are the potential applications of AI in healthcare?",
    ]
)
print(res)
```

```python
# Streaming
for chunk in llm.stream("Describe the key features of the Yi language model series."):
    print(chunk, end="", flush=True)
```

```python
# Asynchronous streaming
import asyncio


async def run_aio_stream():
    async for chunk in llm.astream(
        "Write a brief on the future of AI according to Dr. Kai-Fu Lee's vision."
    ):
        print(chunk, end="", flush=True)


asyncio.run(run_aio_stream())
```

```python
# Adjusting parameters
llm_with_params = YiLLM(
    model="yi-large",
    temperature=0.7,
    top_p=0.9,
)

res = llm_with_params(
    "Propose an innovative AI application that could benefit society."
)
print(res)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/llms/yi.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
