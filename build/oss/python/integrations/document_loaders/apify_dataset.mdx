---
title: Apify Dataset
---

>[Apify Dataset](https://docs.apify.com/platform/storage/dataset)은 구조화된 웹 스크래핑 결과(예: 제품 목록 또는 Google SERP)를 저장하고 JSON, CSV, Excel과 같은 다양한 형식으로 내보낼 수 있도록 설계된 순차 액세스 기반의 확장 가능한 추가 전용 스토리지입니다. Dataset은 주로 다양한 웹 스크래핑, 크롤링 및 데이터 추출 사용 사례를 위한 서버리스 클라우드 프로그램인 [Apify Actors](https://apify.com/store)의 결과를 저장하는 데 사용됩니다.

이 노트북은 Apify dataset을 LangChain으로 로드하는 방법을 보여줍니다.

## Prerequisites

Apify 플랫폼에 기존 dataset이 있어야 합니다. 이 예제는 [Website Content Crawler](https://apify.com/apify/website-content-crawler)에서 생성된 dataset을 로드하는 방법을 보여줍니다.

```python
pip install -qU langchain langchain-apify langchain-openai
```

먼저, 소스 코드에 `ApifyDatasetLoader`를 import합니다:

```python
from langchain_apify import ApifyDatasetLoader
from langchain_core.documents import Document
```

[Apify API token](https://console.apify.com/account/integrations)과 [OpenAI API key](https://platform.openai.com/account/api-keys)를 찾아서 환경 변수로 초기화합니다:

```python
import os

os.environ["APIFY_API_TOKEN"] = "your-apify-api-token"
os.environ["OPENAI_API_KEY"] = "your-openai-api-key"
```

그런 다음 Apify dataset 레코드 필드를 LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) 형식으로 매핑하는 함수를 제공합니다.

예를 들어, dataset 항목이 다음과 같이 구조화되어 있는 경우:

```json
{
    "url": "https://apify.com",
    "text": "Apify is the best web scraping and automation platform."
}
```

아래 코드의 매핑 함수는 이를 LangChain [`Document`](https://reference.langchain.com/python/langchain_core/documents/#langchain_core.documents.base.Document) 형식으로 변환하여, 모든 LLM 모델(예: 질문 답변)과 함께 사용할 수 있도록 합니다.

```python
loader = ApifyDatasetLoader(
    dataset_id="your-dataset-id",
    dataset_mapping_function=lambda dataset_item: Document(
        page_content=dataset_item["text"], metadata={"source": dataset_item["url"]}
    ),
)
```

```python
data = loader.load()
```

## 질문 답변 예제

이 예제에서는 dataset의 데이터를 사용하여 질문에 답변합니다.

```python
from langchain.indexes import VectorstoreIndexCreator
from langchain_apify import ApifyWrapper
from langchain_core.documents import Document
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_openai import ChatOpenAI
from langchain_openai.embeddings import OpenAIEmbeddings
```

```python
loader = ApifyDatasetLoader(
    dataset_id="your-dataset-id",
    dataset_mapping_function=lambda item: Document(
        page_content=item["text"] or "", metadata={"source": item["url"]}
    ),
)
```

```python
index = VectorstoreIndexCreator(
    vectorstore_cls=InMemoryVectorStore, embedding=OpenAIEmbeddings()
).from_loaders([loader])
```

```python
llm = ChatOpenAI(model="gpt-4o-mini")
```

```python
query = "What is Apify?"
result = index.query_with_sources(query, llm=llm)
```

```python
print(result["answer"])
print(result["sources"])
```

```output
 Apify is a platform for developing, running, and sharing serverless cloud programs. It enables users to create web scraping and automation tools and publish them on the Apify platform.

https://docs.apify.com/platform/actors, https://docs.apify.com/platform/actors/running/actors-in-store, https://docs.apify.com/platform/security, https://docs.apify.com/platform/actors/examples
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/document_loaders/apify_dataset.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
