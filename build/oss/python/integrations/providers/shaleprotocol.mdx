---
title: Shale Protocol
---

[Shale Protocol](https://shaleprotocol.com)은 오픈 LLM을 위한 프로덕션 준비가 완료된 inference API를 제공합니다. 확장성이 뛰어난 GPU 클라우드 인프라에서 호스팅되는 Plug & Play API입니다.

무료 티어는 키당 일일 최대 1K 요청을 지원하며, 누구나 LLM으로 genAI 앱을 구축할 수 있도록 진입 장벽을 없애고자 합니다.

Shale Protocol을 통해 개발자/연구자는 무료로 앱을 만들고 오픈 LLM의 기능을 탐색할 수 있습니다.

이 페이지에서는 Shale-Serve API를 LangChain과 통합하는 방법을 다룹니다.

2023년 6월 기준으로 API는 기본적으로 Vicuna-13B를 지원합니다. 향후 릴리스에서 Falcon-40B와 같은 더 많은 LLM을 지원할 예정입니다.

## 사용 방법

### 1. https://shaleprotocol.com에서 Discord 링크를 찾으세요. Discord의 "Shale Bot"을 통해 API 키를 생성하세요. 신용카드가 필요하지 않으며 무료 체험판도 없습니다. API 키당 일일 1K 제한이 있는 영구 무료 티어입니다

### 2. https://shale.live/v1을 OpenAI API 대체용으로 사용하세요

예시

```python
from langchain_openai import OpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

import os
os.environ['OPENAI_API_BASE'] = "https://shale.live/v1"
os.environ['OPENAI_API_KEY'] = "ENTER YOUR API KEY"

llm = OpenAI()

template = """Question: {question}

# Answer: Let's think step by step."""

prompt = PromptTemplate.from_template(template)


llm_chain = prompt | llm | StrOutputParser()

question = "What NFL team won the Super Bowl in the year Justin Beiber was born?"

llm_chain.invoke(question)

```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/shaleprotocol.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
