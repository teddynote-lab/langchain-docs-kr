---
title: LlamaEdge
---

>[LlamaEdge](https://llamaedge.com/docs/intro/)는 커스터마이징되고 파인튜닝된 LLM을 로컬 또는 엣지에서 실행하는 가장 쉽고 빠른 방법입니다.
>
>* 경량 추론 앱. `LlamaEdge`는 GB가 아닌 MB 단위입니다
>* 네이티브 및 GPU 가속 성능
>* 다양한 GPU 및 하드웨어 가속기 지원
>* 다양한 최적화된 추론 라이브러리 지원
>* 다양한 AI / LLM 모델 선택 가능



## 설치 및 설정

[설치 지침](https://llamaedge.com/docs/user-guide/quick-start-command)을 참조하세요.

## Chat models

[사용 예제](/oss/python/integrations/chat/llama_edge)를 참조하세요.

```python
from langchain_community.chat_models.llama_edge import LlamaEdgeChatService
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/llamaedge.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
