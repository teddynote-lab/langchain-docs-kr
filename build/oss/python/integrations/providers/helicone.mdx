---
title: Helicone
---

이 페이지는 LangChain 내에서 [Helicone](https://helicone.ai) 생태계를 사용하는 방법을 다룹니다.

## Helicone이란?

Helicone은 OpenAI 트래픽을 프록시하고 비용, 지연 시간 및 사용량에 대한 주요 인사이트를 제공하는 [오픈 소스](https://github.com/Helicone/helicone) 관찰성 플랫폼입니다.


## 빠른 시작

LangChain 환경에서 다음 파라미터를 추가하기만 하면 됩니다.

```bash
export OPENAI_API_BASE="https://oai.hconeai.com/v1"
```

이제 [helicone.ai](https://www.helicone.ai/signup)로 이동하여 계정을 생성하고, 대시보드에 OpenAI API key를 추가하여 로그를 확인하세요.


## Helicone caching 활성화 방법

```python
from langchain_openai import OpenAI
import openai
openai.api_base = "https://oai.hconeai.com/v1"

llm = OpenAI(temperature=0.9, headers={"Helicone-Cache-Enabled": "true"})
text = "What is a helicone?"
print(llm.invoke(text))
```

[Helicone caching 문서](https://docs.helicone.ai/advanced-usage/caching)

## Helicone custom properties 사용 방법

```python
from langchain_openai import OpenAI
import openai
openai.api_base = "https://oai.hconeai.com/v1"

llm = OpenAI(temperature=0.9, headers={
        "Helicone-Property-Session": "24",
        "Helicone-Property-Conversation": "support_issue_2",
        "Helicone-Property-App": "mobile",
      })
text = "What is a helicone?"
print(llm.invoke(text))
```

[Helicone property 문서](https://docs.helicone.ai/advanced-usage/custom-properties)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/helicone.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
