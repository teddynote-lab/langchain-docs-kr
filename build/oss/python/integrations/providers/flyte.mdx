---
title: Flyte
---

> [Flyte](https://github.com/flyteorg/flyte)는 프로덕션 수준의 데이터 및 ML 파이프라인 구축을 용이하게 하는 오픈 소스 orchestrator입니다.
> 확장성과 재현성을 위해 구축되었으며, Kubernetes를 기본 플랫폼으로 활용합니다.

이 노트북의 목적은 Flyte task에 `FlyteCallback`을 통합하여 LangChain 실험을 효과적으로 모니터링하고 추적할 수 있도록 하는 방법을 보여주는 것입니다.

## Installation & Setup

- `pip install flytekit` 명령을 실행하여 Flytekit 라이브러리를 설치합니다.
- `pip install flytekitplugins-envd` 명령을 실행하여 Flytekit-Envd plugin을 설치합니다.
- `pip install langchain` 명령을 실행하여 LangChain을 설치합니다.
- 시스템에 [Docker](https://docs.docker.com/engine/install/)를 설치합니다.

## Flyte Tasks

Flyte [task](https://docs.flyte.org/en/latest/user_guide/basics/tasks.html)는 Flyte의 기본 구성 요소 역할을 합니다.
LangChain 실험을 실행하려면 관련된 특정 단계와 작업을 정의하는 Flyte task를 작성해야 합니다.

참고: [시작 가이드](https://docs.flyte.org/projects/cookbook/en/latest/index.html)는 Flyte를 로컬에 설치하고 첫 번째 Flyte 파이프라인을 실행하는 방법에 대한 자세한 단계별 지침을 제공합니다.

먼저, LangChain 실험을 지원하는 데 필요한 종속성을 import합니다.

```python
import os

from flytekit import ImageSpec, task
from langchain.agents import AgentType, initialize_agent, load_tools
from langchain.callbacks import FlyteCallbackHandler
from langchain.chains import LLMChain
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.messages import HumanMessage
```

OpenAI API와 Serp API를 활용하기 위해 필요한 환경 변수를 설정합니다:

```python
# Set OpenAI API key
os.environ["OPENAI_API_KEY"] = "<your_openai_api_key>"

# Set Serp API key
os.environ["SERPAPI_API_KEY"] = "<your_serp_api_key>"
```

`<your_openai_api_key>`와 `<your_serp_api_key>`를 OpenAI와 Serp API에서 얻은 각각의 API key로 교체하세요.

파이프라인의 재현성을 보장하기 위해 Flyte task는 컨테이너화됩니다.
각 Flyte task는 image와 연결되어야 하며, 이는 전체 Flyte [workflow](https://docs.flyte.org/en/latest/user_guide/basics/workflows.html)에서 공유되거나 각 task에 대해 개별적으로 제공될 수 있습니다.

각 Flyte task에 필요한 종속성을 제공하는 프로세스를 간소화하기 위해 [`ImageSpec`](https://docs.flyte.org/en/latest/user_guide/customizing_dependencies/imagespec.html) 객체를 초기화할 수 있습니다.
이 접근 방식은 자동으로 Docker 빌드를 트리거하여 사용자가 수동으로 Docker image를 생성할 필요가 없습니다.

```python
custom_image = ImageSpec(
    name="langchain-flyte",
    packages=[
        "langchain",
        "openai",
        "spacy",
        "https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0.tar.gz",
        "textstat",
        "google-search-results",
    ],
    registry="<your-registry>",
)
```

원하는 registry에 Docker image를 push할 수 있는 유연성이 있습니다.
[Docker Hub](https://hub.docker.com/) 또는 [GitHub Container Registry (GHCR)](https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry)는 시작하기에 편리한 옵션입니다.

registry를 선택한 후, LangChain metrics를 Flyte Deck에 기록하는 Flyte task를 생성할 수 있습니다.

다음 예제는 OpenAI LLM, chain 및 tool이 있는 agent와 관련된 task를 보여줍니다:

### LLM

```python
@task(disable_deck=False, container_image=custom_image)
def langchain_llm() -> str:
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0.2,
        callbacks=[FlyteCallbackHandler()],
    )
    return llm.invoke([HumanMessage(content="Tell me a joke")]).content
```

### Chain

```python
@task(disable_deck=False, container_image=custom_image)
def langchain_chain() -> list[dict[str, str]]:
    template = """You are a playwright. Given the title of play, it is your job to write a synopsis for that title.
Title: {title}
Playwright: This is a synopsis for the above play:"""
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0,
        callbacks=[FlyteCallbackHandler()],
    )
    prompt_template = PromptTemplate(input_variables=["title"], template=template)
    synopsis_chain = LLMChain(
        llm=llm, prompt=prompt_template, callbacks=[FlyteCallbackHandler()]
    )
    test_prompts = [
        {
            "title": "documentary about good video games that push the boundary of game design"
        },
    ]
    return synopsis_chain.apply(test_prompts)
```

### Agent

```python
@task(disable_deck=False, container_image=custom_image)
def langchain_agent() -> str:
    llm = OpenAI(
        model_name="gpt-3.5-turbo",
        temperature=0,
        callbacks=[FlyteCallbackHandler()],
    )
    tools = load_tools(
        ["serpapi", "llm-math"], llm=llm, callbacks=[FlyteCallbackHandler()]
    )
    agent = initialize_agent(
        tools,
        llm,
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        callbacks=[FlyteCallbackHandler()],
        verbose=True,
    )
    return agent.run(
        "Who is Leonardo DiCaprio's girlfriend? Could you calculate her current age and raise it to the power of 0.43?"
    )
```

이러한 task는 Flyte 내에서 LangChain 실험을 실행하기 위한 시작점 역할을 합니다.

## Execute the Flyte Tasks on Kubernetes

구성된 Flyte backend에서 Flyte task를 실행하려면 다음 명령을 사용하세요:

```bash
pyflyte run --image <your-image> langchain_flyte.py langchain_llm
```

이 명령은 Flyte backend에서 `langchain_llm` task의 실행을 시작합니다. 나머지 두 task도 유사한 방식으로 트리거할 수 있습니다.

metrics는 다음과 같이 Flyte UI에 표시됩니다:

![LangChain metrics와 종속성 트리 시각화를 보여주는 Flyte Deck 스크린샷.](https://ik.imagekit.io/c8zl7irwkdda/Screenshot_2023-06-20_at_1.23.29_PM_MZYeG0dKa.png?updatedAt=1687247642993 "Flyte Deck Metrics 표시")

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/flyte.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
