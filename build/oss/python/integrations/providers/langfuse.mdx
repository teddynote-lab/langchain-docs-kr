---
title: Langfuse
---

> **Langfuseë€ ë¬´ì—‡ì¸ê°€ìš”?** [Langfuse](https://langfuse.com)ëŠ” íŒ€ì´ API í˜¸ì¶œì„ ì¶”ì í•˜ê³ , ì„±ëŠ¥ì„ ëª¨ë‹ˆí„°ë§í•˜ë©°, AI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¬¸ì œë¥¼ ë””ë²„ê¹…í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ LLM ì—”ì§€ë‹ˆì–´ë§ í”Œë«í¼ì…ë‹ˆë‹¤.

## LangChain Tracing

[Langfuse Tracing](https://langfuse.com/docs/tracing)ì€ LangChain Callbacks([Python](https://python.langchain.com/docs/how_to/#callbacks), [JS](https://js.langchain.com/docs/how_to/#callbacks))ë¥¼ ì‚¬ìš©í•˜ì—¬ LangChainê³¼ í†µí•©ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Langfuse SDKëŠ” LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ì‹¤í–‰ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ì¤‘ì²©ëœ traceë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë¡œê¹…í•˜ê³ , ë¶„ì„í•˜ê³ , ë””ë²„ê¹…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

(1) constructor ì¸ì ë˜ëŠ” (2) í™˜ê²½ ë³€ìˆ˜ë¥¼ í†µí•´ í†µí•©ì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. [cloud.langfuse.com](https://cloud.langfuse.com)ì— ê°€ì…í•˜ê±°ë‚˜ [Langfuseë¥¼ ìì²´ í˜¸ìŠ¤íŒ…](https://langfuse.com/self-hosting)í•˜ì—¬ Langfuse ìê²© ì¦ëª…ì„ ë°›ìœ¼ì„¸ìš”.

### Constructor ì¸ì

```python
pip install langfuse
```

```python
from langfuse import Langfuse, get_client
from langfuse.langchain import CallbackHandler
from langchain_openai import ChatOpenAI  # Example LLM
from langchain_core.prompts import ChatPromptTemplate

# Initialize Langfuse client with constructor arguments
Langfuse(
    public_key="your-public-key",
    secret_key="your-secret-key",
    host="https://cloud.langfuse.com"  # Optional: defaults to https://cloud.langfuse.com
)

# Get the configured client instance
langfuse = get_client()

# Initialize the Langfuse handler
langfuse_handler = CallbackHandler()

# Create your LangChain components
llm = ChatOpenAI(model_name="gpt-4o")
prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
chain = prompt | llm

# Run your chain with Langfuse tracing
response = chain.invoke({"topic": "cats"}, config={"callbacks": [langfuse_handler]})
print(response.content)

# Flush events to Langfuse in short-lived applications
langfuse.flush()
```

### í™˜ê²½ ë³€ìˆ˜

```bash filename=".env"
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_PUBLIC_KEY="pk-lf-..."
# ğŸ‡ªğŸ‡º EU region
LANGFUSE_HOST="https://cloud.langfuse.com"
# ğŸ‡ºğŸ‡¸ US region
# LANGFUSE_HOST="https://us.cloud.langfuse.com"
```
```python
# Initialize Langfuse handler
from langfuse.langchain import CallbackHandler
langfuse_handler = CallbackHandler()

# Your LangChain code

# Add Langfuse handler as callback (classic and LCEL)
chain.invoke({"input": "<user_input>"}, config={"callbacks": [langfuse_handler]})
```

ì´ í†µí•©ì„ ë‹¤ë¥¸ Langfuse ê¸°ëŠ¥ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë³´ë ¤ë©´ [ì´ end-to-end ì˜ˆì œ](https://langfuse.com/docs/integrations/langchain/example-python)ë¥¼ í™•ì¸í•˜ì„¸ìš”.

## LangGraph Tracing

ì´ ë¶€ë¶„ì—ì„œëŠ” [Langfuse](https://langfuse.com/docs)ê°€ [LangChain í†µí•©](https://langfuse.com/docs/integrations/langchain/tracing)ì„ ì‚¬ìš©í•˜ì—¬ LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë””ë²„ê¹…í•˜ê³ , ë¶„ì„í•˜ê³ , ë°˜ë³µí•˜ëŠ” ë° ì–´ë–»ê²Œ ë„ì›€ì´ ë˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤.

### Langfuse ì´ˆê¸°í™”

**ì°¸ê³ :** ìµœì†Œí•œ Python 3.11ì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤([GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)).

Langfuse UIì˜ í”„ë¡œì íŠ¸ ì„¤ì •ì—ì„œ [API keys](https://langfuse.com/faq/all/where-are-langfuse-api-keys)ë¥¼ ì‚¬ìš©í•˜ì—¬ Langfuse í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³  í™˜ê²½ì— ì¶”ê°€í•˜ì„¸ìš”.


```python
pip install langfuse
pip install langchain langgraph langchain_openai langchain_community
```


```python
import os

# get keys for your project from https://cloud.langfuse.com
os.environ["LANGFUSE_PUBLIC_KEY"] = "pk-lf-***"
os.environ["LANGFUSE_SECRET_KEY"] = "sk-lf-***"
os.environ["LANGFUSE_HOST"] = "https://cloud.langfuse.com" # for EU data region
# os.environ["LANGFUSE_HOST"] = "https://us.cloud.langfuse.com" # for US data region

# your openai key
os.environ["OPENAI_API_KEY"] = "***"
```

### LangGraphë¥¼ ì‚¬ìš©í•œ ê°„ë‹¨í•œ ì±„íŒ… ì•±

**ì´ ì„¹ì…˜ì—ì„œ ìˆ˜í–‰í•  ì‘ì—…:**

*   ì¼ë°˜ì ì¸ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì§€ì› ì±—ë´‡ì„ LangGraphë¡œ êµ¬ì¶•
*   Langfuseë¥¼ ì‚¬ìš©í•˜ì—¬ ì±—ë´‡ì˜ ì…ë ¥ ë° ì¶œë ¥ ì¶”ì 

ê¸°ë³¸ ì±—ë´‡ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ë” ê³ ê¸‰ multi agent ì„¤ì •ì„ êµ¬ì¶•í•˜ë©´ì„œ ì£¼ìš” LangGraph ê°œë…ì„ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

#### Agent ìƒì„±

`StateGraph`ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤. `StateGraph` ê°ì²´ëŠ” ì±—ë´‡ì˜ êµ¬ì¡°ë¥¼ ìƒíƒœ ë¨¸ì‹ ìœ¼ë¡œ ì •ì˜í•©ë‹ˆë‹¤. LLMê³¼ ì±—ë´‡ì´ í˜¸ì¶œí•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” nodeë¥¼ ì¶”ê°€í•˜ê³ , ë´‡ì´ ì´ëŸ¬í•œ í•¨ìˆ˜ ê°„ì— ì „í™˜í•˜ëŠ” ë°©ë²•ì„ ì§€ì •í•˜ëŠ” edgeë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.


```python
from typing import Annotated

from langchain_openai import ChatOpenAI
from langchain.messages import HumanMessage
from typing_extensions import TypedDict

from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages

class State(TypedDict):
    # Messages have the type "list". The `add_messages` function in the annotation defines how this state key should be updated
    # (in this case, it appends messages to the list, rather than overwriting them)
    messages: Annotated[list, add_messages]

graph_builder = StateGraph(State)

llm = ChatOpenAI(model = "gpt-4o", temperature = 0.2)

# The chatbot node function takes the current State as input and returns an updated messages list. This is the basic pattern for all LangGraph node functions.
def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

# Add a "chatbot" node. Nodes represent units of work. They are typically regular python functions.
graph_builder.add_node("chatbot", chatbot)

# Add an entry point. This tells our graph where to start its work each time we run it.
graph_builder.set_entry_point("chatbot")

# Set a finish point. This instructs the graph "any time this node is run, you can exit."
graph_builder.set_finish_point("chatbot")

# To be able to run our graph, call "compile()" on the graph builder. This creates a "CompiledGraph" we can use invoke on our state.
graph = graph_builder.compile()
```

#### í˜¸ì¶œì— Langfuseë¥¼ callbackìœ¼ë¡œ ì¶”ê°€

ì´ì œ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë‹¨ê³„ë¥¼ ì¶”ì í•˜ê¸° ìœ„í•´ [LangChainìš© Langfuse callback handler](https://langfuse.com/docs/integrations/langchain/tracing)ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤: `config={"callbacks": [langfuse_handler]}`


```python
from langfuse.langchain import CallbackHandler

# Initialize Langfuse CallbackHandler for LangChain (tracing)
langfuse_handler = CallbackHandler()

for s in graph.stream({"messages": [HumanMessage(content = "What is Langfuse?")]},
                      config={"callbacks": [langfuse_handler]}):
    print(s)
```

```
{'chatbot': {'messages': [AIMessage(content='Langfuse is a tool designed to help developers monitor and observe the performance of their Large Language Model (LLM) applications. It provides detailed insights into how these applications are functioning, allowing for better debugging, optimization, and overall management. Langfuse offers features such as tracking key metrics, visualizing data, and identifying potential issues in real-time, making it easier for developers to maintain and improve their LLM-based solutions.', response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 13, 'total_tokens': 99}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_400f27fa1f', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a0c97cb-ccfe-463e-902c-5a5900b796b4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 86, 'total_tokens': 99})]}}
```


#### Langfuseì—ì„œ trace ë³´ê¸°

Langfuseì˜ ì˜ˆì œ trace: https://cloud.langfuse.com/project/cloramnkj0002jz088vzn1ja4/traces/d109e148-d188-4d6e-823f-aac0864afbab

![Langfuseì˜ ì±„íŒ… ì•± Trace ë·°](https://langfuse.com/images/cookbook/integration-langgraph/integration_langgraph_chatapp_trace.png)

- ë” ë§ì€ ì˜ˆì œë¥¼ ë³´ë ¤ë©´ [ì „ì²´ notebook](https://langfuse.com/docs/integrations/langchain/example-python-langgraph)ì„ í™•ì¸í•˜ì„¸ìš”.
- LangGraph ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ë ¤ë©´ [LangGraph í‰ê°€ ê°€ì´ë“œ](https://langfuse.com/docs/integrations/langchain/example-langgraph-agents)ë¥¼ í™•ì¸í•˜ì„¸ìš”.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/providers/langfuse.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
