---
title: Slack
---

이 노트북은 Slack chat loader를 사용하는 방법을 보여줍니다. 이 클래스는 내보낸 Slack 대화를 LangChain chat message로 매핑하는 데 도움을 줍니다.

프로세스는 세 단계로 구성됩니다:

1. [여기의 지침](https://slack.com/help/articles/1500001548241-Request-to-export-all-conversations)을 따라 원하는 대화 스레드를 내보냅니다.
2. json 파일 또는 JSON 파일 디렉토리를 가리키는 파일 경로로 `SlackChatLoader`를 생성합니다.
3. `loader.load()` (또는 `loader.lazy_load()`)를 호출하여 변환을 수행합니다. 선택적으로 `merge_chat_runs`를 사용하여 동일한 발신자의 연속된 메시지를 결합하거나, `map_ai_messages`를 사용하여 지정된 발신자의 메시지를 "AIMessage" 클래스로 변환할 수 있습니다.

## 1. message dump 생성

현재(2023/08/23) 기준으로, 이 loader는 Slack에서 다이렉트 메시지 대화를 내보낼 때 생성되는 형식의 zip 디렉토리 파일을 가장 잘 지원합니다. Slack의 최신 지침을 따라 내보내기를 수행하세요.

LangChain repo에 예제가 있습니다.

```python
import requests

permalink = "https://raw.githubusercontent.com/langchain-ai/langchain/342087bdfa3ac31d622385d0f2d09cf5e06c8db3/libs/langchain/tests/integration_tests/examples/slack_export.zip"
response = requests.get(permalink)
with open("slack_dump.zip", "wb") as f:
    f.write(response.content)
```

## 2. Chat Loader 생성

loader에 zip 디렉토리의 파일 경로를 제공합니다. 선택적으로 AI message에 매핑되는 user id를 지정하고 message run을 병합할지 여부를 구성할 수 있습니다.

```python
from langchain_community.chat_loaders.slack import SlackChatLoader
```

```python
loader = SlackChatLoader(
    path="slack_dump.zip",
)
```

## 3. message 로드

`load()` (또는 `lazy_load`) 메서드는 현재 로드된 대화당 message 목록을 포함하는 "ChatSessions" 목록을 반환합니다.

```python
from typing import List

from langchain_community.chat_loaders.utils import (
    map_ai_messages,
    merge_chat_runs,
)
from langchain_core.chat_sessions import ChatSession

raw_messages = loader.lazy_load()
# Merge consecutive messages from the same sender into a single message
merged_messages = merge_chat_runs(raw_messages)
# Convert messages from "U0500003428" to AI messages
messages: List[ChatSession] = list(
    map_ai_messages(merged_messages, sender="U0500003428")
)
```

### 다음 단계

그런 다음 모델 fine-tuning, few-shot 예제 선택 또는 다음 메시지에 대한 직접 예측 등 원하는 방식으로 이러한 message를 사용할 수 있습니다.

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI()

for chunk in llm.stream(messages[1]["messages"]):
    print(chunk.content, end="", flush=True)
```

```output
Hi,

I hope you're doing well. I wanted to reach out and ask if you'd be available to meet up for coffee sometime next week. I'd love to catch up and hear about what's been going on in your life. Let me know if you're interested and we can find a time that works for both of us.

Looking forward to hearing from you!

Best, [Your Name]
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat_loaders/slack.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
