---
title: ChatBaseten
---

이 가이드는 Baseten [chat model](/oss/python/langchain/models) 시작하기에 대한 간단한 개요를 제공합니다. 모든 ChatBaseten 기능, 매개변수 및 구성에 대한 자세한 목록은 [ChatBaseten API reference](https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html)를 참조하세요.

Baseten은 프로덕션 애플리케이션을 위해 설계된 추론을 제공합니다. Baseten Inference Stack을 기반으로 구축된 이러한 API는 주요 오픈소스 또는 커스텀 모델에 대해 엔터프라이즈급 성능과 안정성을 제공합니다: https://www.baseten.co/library/.

## Overview

### Details

| Class | Package | Local | Serializable | JS support | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [ChatBaseten](https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html) | [langchain-baseten](https://python.langchain.com/api_reference/baseten/index.html) | ❌ | beta | ❌ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-baseten?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-baseten?style=flat-square&label=%20) |

### Features

| [Tool calling](/oss/python/langchain/tools) | [Structured output](/oss/python/langchain/structured-output) | JSON mode | [Image input](/oss/python/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/python/langchain/streaming/) | Native async | [Token usage](/oss/python/langchain/models#token-usage) | [Logprobs](/oss/python/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ✅ | ❌ | ✅ | ✅ | ✅ | ❌ |

Model API는 텍스트 입력만 지원하지만, 일부 전용 배포는 모델에 따라 이미지 및 오디오 입력을 지원합니다. 자세한 내용은 Baseten 모델 라이브러리를 확인하세요: https://www.baseten.co/library/

---

## Setup

Baseten 모델에 액세스하려면 Baseten 계정을 생성하고 API 키를 받은 다음 `langchain-baseten` integration package를 설치해야 합니다.

[이 페이지](https://app.baseten.co)로 이동하여 Baseten 계정을 생성하고 API 키를 생성하세요. 완료되면 BASETEN_API_KEY environment variable을 설정하세요:

### Credentials

```python Set API key icon="key"
import getpass
import os

if "BASETEN_API_KEY" not in os.environ:
    os.environ["BASETEN_API_KEY"] = getpass.getpass("Enter your Baseten API key: ")
```

모델 호출에 대한 자동화된 <Tooltip tip="모델 실행의 각 단계를 로깅하여 디버그하고 개선합니다">tracing</Tooltip>을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API 키를 설정하세요:

```python Enable tracing icon="flask"
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

### Installation

LangChain Baseten integration은 `langchain-baseten` package에 있습니다:

<CodeGroup>
    ```python pip
    pip install -U langchain-baseten
    ```
    ```python uv
    uv add langchain-baseten
    ```
</CodeGroup>

---

## Instantiation

Baseten은 chat model에 액세스하는 두 가지 방법을 제공합니다:

1. **Model APIs**: 최신의 가장 인기 있는 오픈소스 모델에 대한 액세스.
2. **Dedicated URLs**: 전용 리소스가 있는 특정 모델 배포 사용.

두 접근 방식 모두 자동 endpoint 정규화와 함께 지원됩니다.


```python Initialize with model slug icon="robot"
from langchain_baseten import ChatBaseten

# Option 1: Use Model APIs with model slug
model = ChatBaseten(
    model="moonshotai/Kimi-K2-Instruct-0905",  # Choose from available model slugs: https://docs.baseten.co/development/model-apis/overview#supported-models
    api_key="your-api-key",  # Or set BASETEN_API_KEY env var
)
```

```python Initialize with model URL icon="link"
from langchain_baseten import ChatBaseten

# Option 2: Use dedicated deployments with model url
model = ChatBaseten(
    model_url="https://model-<id>.api.baseten.co/environments/production/predict",
    api_key="your-api-key",  # Or set BASETEN_API_KEY env var
)
```

---

## Invocation

```python Basic invocation icon="play"
# Use the chat model
response = model.invoke("Hello, how are you?")
print(response.content)
```

```output
content="Hello! I'm doing well, thank you for asking! How about you?" additional_kwargs={} response_metadata={'finish_reason': 'stop'} id='run--908651ec-00d7-4992-a320-864397c14e37-0'
```

더 복잡한 대화를 위해 message object를 사용할 수도 있습니다:

<CodeGroup>
    ```python Dictionary format icon="book"
    messages = [
        {"role": "system", "content": "You are a poetry expert"},
        {"role": "user", "content": "Write a haiku about spring"},
    ]
    response = model.invoke(messages)
    print(response)
    ```
</CodeGroup>
```output
content='Buds yawn open wide—  \na robin stitches the hush  \nwith threads of first light.' additional_kwargs={} response_metadata={'finish_reason': 'stop'} id='run--6f7d1db7-daae-4628-a40a-2ab7323e8f15-0'
```


<Tip>
    [chat model invocation types](/oss/python/langchain/models#invocation), [message types](/oss/python/langchain/messages#message-types), [content blocks](/oss/python/langchain/messages#standard-content-blocks)에 대한 전체 가이드를 확인할 수 있습니다.
</Tip>

---

## API reference

모든 ChatBaseten 기능 및 구성에 대한 자세한 문서는 [API reference](https://python.langchain.com/api_reference/baseten/chat_models/langchain_baseten.chat_models.ChatBaseten.html)를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/baseten.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
