---
title: AzureChatOpenAI
---

이 가이드는 Azure의 OpenAI [chat models](/oss/python/langchain/models)를 시작하기 위한 간단한 개요를 제공합니다.

Azure OpenAI의 최신 모델과 비용, context window, 지원되는 입력 타입에 대한 정보는 [Azure 문서](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)에서 확인할 수 있습니다.

<Info>
    **Azure OpenAI vs OpenAI**

    Azure OpenAI는 [Microsoft Azure 플랫폼](https://azure.microsoft.com/en-us/products/ai-services/openai-service)에서 호스팅되는 OpenAI 모델을 의미합니다. OpenAI는 자체 모델 API도 제공합니다. OpenAI 서비스에 직접 액세스하려면 [`ChatOpenAI` integration](/oss/python/integrations/chat/openai/)을 사용하세요.
</Info>

<Tip>
    **API Reference**

    모든 기능과 구성 옵션에 대한 자세한 문서는 [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) API reference를 참조하세요.
</Tip>

<Note>
    [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/)는 OpenAI 서비스와 직접 인터페이스하는 [`ChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/ChatOpenAI/)와 동일한 기본 구현을 공유합니다.

    이 페이지는 Azure OpenAI 서비스를 인증하고 LangChain chat model에 연결하기 위한 빠른 시작 가이드입니다.

    사용 가능한 기능에 대한 자세한 내용은 [`ChatOpenAI` 문서](/oss/python/integrations/chat/openai/)를 참조하거나 [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) API reference를 확인하세요.
</Note>

## Overview

### Integration details

| Class | Package | <Tooltip tip="로컬 하드웨어에서 실행 가능" cta="자세히 알아보기" href="/oss/python/langchain/models#local-models">Local</Tooltip> | Serializable | JS/TS Support | Downloads | Latest Version |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) | [`langchain-openai`](https://reference.langchain.com/python/integrations/langchain_openai) | ❌ | beta | ✅ [(npm)](https://js.langchain.com/docs/integrations/chat/openai) | <a href="https://pypi.org/project/langchain-openai/" target="_blank"><img src="https://static.pepy.tech/badge/langchain-openai/month" alt="Downloads per month" noZoom height="100" class="rounded" /></a> | <a href="https://pypi.org/project/langchain-openai/" target="_blank"><img src="https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20&color=orange" alt="PyPI - Latest version" noZoom height="100" class="rounded" /></a> |

### Model features

| [Tool calling](/oss/python/langchain/tools) | [Structured output](/oss/python/langchain/structured-output) | JSON mode | [Image input](/oss/python/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/python/langchain/streaming/) | Native async | [Token usage](/oss/python/langchain/models#token-usage) | [Logprobs](/oss/python/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| ✅ | ✅ | ✅ | ✅ | ❌ | ❌ | ✅ | ✅ | ✅ | ✅ |

## Setup

[`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) 모델에 액세스하려면 Azure 계정을 생성하고, Azure OpenAI 모델의 배포를 생성하고, 배포의 이름과 endpoint를 가져오고, Azure OpenAI API key를 가져오고, `langchain-openai` integration package를 설치해야 합니다.

### Installation

<CodeGroup>
    ```bash pip
    pip install -U langchain-openai
    ```
    ```bash uv
    uv add langchain-openai
    ```
</CodeGroup>

### Credentials

배포를 생성하고 API key를 생성하려면 [Azure 문서](https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python)를 참조하세요. 완료한 후 `AZURE_OPENAI_API_KEY`와 `AZURE_OPENAI_ENDPOINT` 환경 변수를 설정하세요:

```python
import getpass
import os

if "AZURE_OPENAI_API_KEY" not in os.environ:
    os.environ["AZURE_OPENAI_API_KEY"] = getpass.getpass(
        "Enter your AzureOpenAI API key: "
    )
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://YOUR-ENDPOINT.openai.azure.com/"
```

모델 호출의 자동 추적을 활성화하려면 [LangSmith](https://docs.smith.langchain.com/) API key를 설정하세요:

```python
os.environ["LANGSMITH_API_KEY"] = getpass.getpass("Enter your LangSmith API key: ")
os.environ["LANGSMITH_TRACING"] = "true"
```

## Instantiation

이제 모델 객체를 인스턴스화하고 chat completion을 생성할 수 있습니다.

- `azure_deployment`를 배포 이름으로 교체하세요,
- 최신 지원 `api_version`은 여기에서 확인할 수 있습니다: [learn.microsoft.com/en-us/azure/ai-services/openai/reference](https://learn.microsoft.com/en-us/azure/ai-services/openai/reference).

```python
from langchain_openai import AzureChatOpenAI

llm = AzureChatOpenAI(
    azure_deployment="gpt-35-turbo",  # or your deployment
    api_version="2023-06-01-preview",  # or your api version
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    # other params...
)
```

## Invocation

```python
messages = [
    (
        "system",
        "You are a helpful assistant that translates English to French. Translate the user sentence.",
    ),
    ("human", "I love programming."),
]
ai_msg = llm.invoke(messages)
ai_msg
```

```output
AIMessage(content="J'adore la programmation.", response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 31, 'total_tokens': 39}, 'model_name': 'gpt-35-turbo', 'system_fingerprint': None, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-bea4b46c-e3e1-4495-9d3a-698370ad963d-0', usage_metadata={'input_tokens': 31, 'output_tokens': 8, 'total_tokens': 39})
```

```python
print(ai_msg.content)
```

```output
J'adore la programmation.
```

## Specifying model version

Azure OpenAI 응답에는 응답을 생성하는 데 사용된 모델의 이름인 `model_name` 응답 메타데이터 속성이 포함됩니다. 그러나 네이티브 OpenAI 응답과 달리 Azure의 배포에 설정된 모델의 특정 버전은 포함되지 않습니다. 예를 들어 `gpt-35-turbo-0125`와 `gpt-35-turbo-0301`을 구분하지 않습니다. 이로 인해 응답을 생성하는 데 사용된 모델 버전을 알기 어렵고, 결과적으로 `OpenAICallbackHandler`를 사용한 총 비용 계산이 잘못될 수 있습니다.

이 문제를 해결하기 위해 [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) 클래스에 `model_version` 매개변수를 전달할 수 있으며, 이는 llm output의 모델 이름에 추가됩니다. 이렇게 하면 모델의 다른 버전을 쉽게 구분할 수 있습니다.

```python
pip install -qU langchain-community
```

```python
from langchain_community.callbacks import get_openai_callback

with get_openai_callback() as cb:
    llm.invoke(messages)
    print(
        f"Total Cost (USD): ${format(cb.total_cost, '.6f')}"
    )  # without specifying the model version, flat-rate 0.002 USD per 1k input and output tokens is used
```

```output
Total Cost (USD): $0.000063
```

```python
llm_0301 = AzureChatOpenAI(
    azure_deployment="gpt-35-turbo",  # or your deployment
    api_version="2023-06-01-preview",  # or your api version
    model_version="0301",
)
with get_openai_callback() as cb:
    llm_0301.invoke(messages)
    print(f"Total Cost (USD): ${format(cb.total_cost, '.6f')}")
```

```output
Total Cost (USD): $0.000074
```

## API reference

모든 기능과 구성 옵션에 대한 자세한 문서는 [`AzureChatOpenAI`](https://reference.langchain.com/python/integrations/langchain_openai/AzureChatOpenAI/) API reference를 참조하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/azure_chat_openai.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
