---
title: LlamaEdge
---

[LlamaEdge](https://github.com/second-state/LlamaEdge)를 사용하면 [GGUF](https://github.com/ggerganov/llama.cpp/blob/master/gguf-py/README.md) 형식의 LLM과 로컬 및 채팅 서비스를 통해 대화할 수 있습니다.

- `LlamaEdgeChatService`는 개발자에게 HTTP 요청을 통해 LLM과 채팅할 수 있는 OpenAI API 호환 서비스를 제공합니다.

- `LlamaEdgeChatLocal`은 개발자가 로컬에서 LLM과 채팅할 수 있도록 합니다(곧 출시 예정).

`LlamaEdgeChatService`와 `LlamaEdgeChatLocal` 모두 [WasmEdge Runtime](https://wasmedge.org/)을 기반으로 하는 인프라에서 실행되며, LLM 추론 작업을 위한 경량 및 이식 가능한 WebAssembly 컨테이너 환경을 제공합니다.

## API Service를 통한 채팅

`LlamaEdgeChatService`는 `llama-api-server`에서 작동합니다. [llama-api-server quick-start](https://github.com/second-state/llama-utils/tree/main/api-server#readme)의 단계를 따라 자체 API 서비스를 호스팅하면 인터넷이 가능한 한 어디서든 원하는 모든 장치에서 원하는 모든 모델과 채팅할 수 있습니다.

```python
from langchain_community.chat_models.llama_edge import LlamaEdgeChatService
from langchain.messages import HumanMessage, SystemMessage
```

### 비스트리밍 모드에서 LLM과 채팅하기

```python
# service url
service_url = "https://b008-54-186-154-209.ngrok-free.app"

# create wasm-chat service instance
chat = LlamaEdgeChatService(service_url=service_url)

# create message sequence
system_message = SystemMessage(content="You are an AI assistant")
user_message = HumanMessage(content="What is the capital of France?")
messages = [system_message, user_message]

# chat with wasm-chat service
response = chat.invoke(messages)

print(f"[Bot] {response.content}")
```

```output
[Bot] Hello! The capital of France is Paris.
```

### 스트리밍 모드에서 LLM과 채팅하기

```python
# service url
service_url = "https://b008-54-186-154-209.ngrok-free.app"

# create wasm-chat service instance
chat = LlamaEdgeChatService(service_url=service_url, streaming=True)

# create message sequence
system_message = SystemMessage(content="You are an AI assistant")
user_message = HumanMessage(content="What is the capital of Norway?")
messages = [
    system_message,
    user_message,
]

output = ""
for chunk in chat.stream(messages):
    # print(chunk.content, end="", flush=True)
    output += chunk.content

print(f"[Bot] {output}")
```

```output
[Bot]   Hello! I'm happy to help you with your question. The capital of Norway is Oslo.
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/llama_edge.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
