---
title: ChatSeekrFlow
---

> [Seekr](https://www.seekr.com/)ëŠ” êµ¬ì¡°í™”ë˜ê³  ì„¤ëª… ê°€ëŠ¥í•˜ë©° íˆ¬ëª…í•œ AI ìƒí˜¸ì‘ìš©ì„ ìœ„í•œ AI ê¸°ë°˜ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

ì´ ê°€ì´ë“œëŠ” Seekr [chat models](/oss/python/langchain/models) ì‹œì‘í•˜ê¸°ì— ëŒ€í•œ ê°„ë‹¨í•œ ê°œìš”ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  `ChatSeekrFlow` ê¸°ëŠ¥ ë° êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ë¬¸ì„œëŠ” [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## Overview

`ChatSeekrFlow` classëŠ” SeekrFlowì—ì„œ í˜¸ìŠ¤íŒ…ë˜ëŠ” chat model endpointë¥¼ ë˜í•‘í•˜ì—¬ LangChain ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ì˜ ì›í™œí•œ í†µí•©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### Integration Details

| Class | Package | Local | Serializable | Downloads | Version |
| :--- | :--- | :---: | :---: |  :---: | :---: |
| [ChatSeekrFlow](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.seekrflow.ChatSeekrFlow.html) | [seekrai](https://python.langchain.com/docs/integrations/providers/seekr/) | âŒ | beta | ![PyPI - Downloads](https://img.shields.io/pypi/dm/seekrai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/seekrai?style=flat-square&label=%20) |

### Model Features

| [Tool calling](/oss/python/langchain/tools/) | [Structured output](/oss/python/langchain/structured-output) | JSON mode | [Image input](/oss/python/langchain/messages#multimodal) | Audio input | Video input | [Token-level streaming](/oss/python/langchain/streaming/) | Native async | [Token usage](/oss/python/langchain/models#token-usage) | [Logprobs](/oss/python/langchain/models#log-probabilities) |
| :---: | :---: | :---: | :---: |  :---: | :---: | :---: | :---: | :---: | :---: |
| âœ… | âœ… | âœ… | âŒ | âŒ | âŒ | âœ… | âŒ | âœ… | âŒ |

### Supported Methods

`ChatSeekrFlow`ëŠ” **async APIë¥¼ ì œì™¸í•œ** `ChatModel`ì˜ ëª¨ë“  ë©”ì„œë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

### Endpoint Requirements

`ChatSeekrFlow`ê°€ ë˜í•‘í•˜ëŠ” serving endpointëŠ” **ë°˜ë“œì‹œ** OpenAI í˜¸í™˜ chat input/output í˜•ì‹ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **Fine-tuned Seekr models**
2. **Custom SeekrFlow models**
3. **Seekrì˜ retrieval systemì„ ì‚¬ìš©í•˜ëŠ” RAG-enabled models**

async ì‚¬ìš©ì— ëŒ€í•´ì„œëŠ” `AsyncChatSeekrFlow`ë¥¼ ì°¸ì¡°í•˜ì„¸ìš” (ê³§ ì¶œì‹œ ì˜ˆì •).

# LangChainì—ì„œ ChatSeekrFlow ì‹œì‘í•˜ê¸°

ì´ ë…¸íŠ¸ë¶ì€ LangChainì—ì„œ SeekrFlowë¥¼ chat modelë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## Setup

í•„ìš”í•œ dependenciesê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:

```bash
pip install seekrai langchain langchain-community
```

ìš”ì²­ì„ ì¸ì¦í•˜ë ¤ë©´ Seekrì˜ API keyë„ í•„ìš”í•©ë‹ˆë‹¤.

```python
# Standard library
import getpass
import os

# Third-party
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage
from langchain_core.runnables import RunnableSequence

# OSS SeekrFlow integration
from langchain_seekrflow import ChatSeekrFlow
from seekrai import SeekrFlow
```

## API Key Setup

ìš”ì²­ì„ ì¸ì¦í•˜ë ¤ë©´ API keyë¥¼ environment variableë¡œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.

ë˜ëŠ” ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ìˆ˜ë™ìœ¼ë¡œ í• ë‹¹í•˜ì„¸ìš”:

```python
SEEKR_API_KEY = "your-api-key-here"
```

```python
os.environ["SEEKR_API_KEY"] = getpass.getpass("Enter your Seekr API key:")
```

## Instantiation

```python
os.environ["SEEKR_API_KEY"]
seekr_client = SeekrFlow(api_key=SEEKR_API_KEY)

llm = ChatSeekrFlow(
    client=seekr_client, model_name="meta-llama/Meta-Llama-3-8B-Instruct"
)
```

## Invocation

```python
response = llm.invoke([HumanMessage(content="Hello, Seekr!")])
print(response.content)
```

```output
Hello there! I'm Seekr, nice to meet you! What brings you here today? Do you have a question, or are you looking for some help with something? I'm all ears (or rather, all text)!
```

## Chaining

```python
prompt = ChatPromptTemplate.from_template("Translate to French: {text}")

chain: RunnableSequence = prompt | llm
result = chain.invoke({"text": "Good morning"})
print(result)
```

```output
content='The translation of "Good morning" in French is:\n\n"Bonne journÃ©e"' additional_kwargs={} response_metadata={}
```

```python
def test_stream():
    """Test synchronous invocation in streaming mode."""
    print("\nğŸ”¹ Testing Sync `stream()` (Streaming)...")

    for chunk in llm.stream([HumanMessage(content="Write me a haiku.")]):
        print(chunk.content, end="", flush=True)


# âœ… Ensure streaming is enabled
llm = ChatSeekrFlow(
    client=seekr_client,
    model_name="meta-llama/Meta-Llama-3-8B-Instruct",
    streaming=True,  # âœ… Enable streaming
)

# âœ… Run sync streaming test
test_stream()
```

```output
ğŸ”¹ Testing Sync `stream()` (Streaming)...
Here is a haiku:

Golden sunset fades
Ripples on the quiet lake
Peaceful evening sky
```

## Error Handling & Debugging

```python
# Define a minimal mock SeekrFlow client
class MockSeekrClient:
    """Mock SeekrFlow API client that mimics the real API structure."""

    class MockChat:
        """Mock Chat object with a completions method."""

        class MockCompletions:
            """Mock Completions object with a create method."""

            def create(self, *args, **kwargs):
                return {
                    "choices": [{"message": {"content": "Mock response"}}]
                }  # Mimic API response

        completions = MockCompletions()

    chat = MockChat()


def test_initialization_errors():
    """Test that invalid ChatSeekrFlow initializations raise expected errors."""

    test_cases = [
        {
            "name": "Missing Client",
            "args": {"client": None, "model_name": "seekrflow-model"},
            "expected_error": "SeekrFlow client cannot be None.",
        },
        {
            "name": "Missing Model Name",
            "args": {"client": MockSeekrClient(), "model_name": ""},
            "expected_error": "A valid model name must be provided.",
        },
    ]

    for test in test_cases:
        try:
            print(f"Running test: {test['name']}")
            faulty_llm = ChatSeekrFlow(**test["args"])

            # If no error is raised, fail the test
            print(f"âŒ Test '{test['name']}' failed: No error was raised!")
        except Exception as e:
            error_msg = str(e)
            assert test["expected_error"] in error_msg, f"Unexpected error: {error_msg}"
            print(f"âœ… Expected Error: {error_msg}")


# Run test
test_initialization_errors()
```

```output
Running test: Missing Client
âœ… Expected Error: SeekrFlow client cannot be None.
Running test: Missing Model Name
âœ… Expected Error: A valid model name must be provided.
```

## API reference

- `ChatSeekrFlow` class: [`langchain_seekrflow.ChatSeekrFlow`](https://github.com/benfaircloth/langchain-seekrflow/blob/main/langchain_seekrflow/seekrflow.py)
- PyPI package: [`langchain-seekrflow`](https://pypi.org/project/langchain-seekrflow/)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/seekrflow.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
