---
title: Nebula (Symbl.ai)
---

이 노트북은 Symbl.ai의 chat model인 [Nebula](https://docs.symbl.ai/docs/nebula-llm)를 시작하는 방법을 다룹니다.

### Integration 세부사항

자세한 문서는 [API reference](https://docs.symbl.ai/reference/nebula-chat)를 참조하세요.

### Model features: TODO

## Setup

### Credentials

시작하려면 [Nebula API key](https://platform.symbl.ai/#/login)를 요청하고 `NEBULA_API_KEY` environment variable을 설정하세요:

```python
import getpass
import os

os.environ["NEBULA_API_KEY"] = getpass.getpass()
```

### Installation

이 integration은 `langchain-community` package에 설정되어 있습니다.

## Instantiation

```python
from langchain_community.chat_models.symblai_nebula import ChatNebula
from langchain.messages import AIMessage, HumanMessage, SystemMessage
```

```python
chat = ChatNebula(max_tokens=1024, temperature=0.5)
```

## Invocation

```python
messages = [
    SystemMessage(
        content="You are a helpful assistant that answers general knowledge questions."
    ),
    HumanMessage(content="What is the capital of France?"),
]
chat.invoke(messages)
```

```output
AIMessage(content=[{'role': 'human', 'text': 'What is the capital of France?'}, {'role': 'assistant', 'text': 'The capital of France is Paris.'}])
```

### Async

```python
await chat.ainvoke(messages)
```

```output
AIMessage(content=[{'role': 'human', 'text': 'What is the capital of France?'}, {'role': 'assistant', 'text': 'The capital of France is Paris.'}])
```

### Streaming

```python
for chunk in chat.stream(messages):
    print(chunk.content, end="", flush=True)
```

```output
 The capital of France is Paris.
```

### Batch

```python
chat.batch([messages])
```

```output
[AIMessage(content=[{'role': 'human', 'text': 'What is the capital of France?'}, {'role': 'assistant', 'text': 'The capital of France is Paris.'}])]
```

## Chaining

```python
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("Tell me a joke about {topic}")
chain = prompt | chat
```

```python
chain.invoke({"topic": "cows"})
```

```output
AIMessage(content=[{'role': 'human', 'text': 'Tell me a joke about cows'}, {'role': 'assistant', 'text': "Sure, here's a joke about cows:\n\nWhy did the cow cross the road?\n\nTo get to the udder side!"}])
```

## API reference

더 자세한 내용은 [API reference](https://python.langchain.com/api_reference/community/chat_models/langchain_community.chat_models.symblai_nebula.ChatNebula.html)를 확인하세요.

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/chat/symblai_nebula.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
