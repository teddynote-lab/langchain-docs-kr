---
title: ZenGuard AI
---

<a href="https://colab.research.google.com/github/langchain-ai/langchain/blob/v0.3/docs/docs/integrations/tools/zenguard.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a>

이 도구를 사용하면 LangChain 기반 애플리케이션에서 [ZenGuard AI](https://www.zenguard.ai/)를 빠르게 설정할 수 있습니다. ZenGuard AI는 다음으로부터 GenAI 애플리케이션을 보호하는 초고속 가드레일을 제공합니다:

- Prompt 공격
- 사전 정의된 주제 이탈
- PII, 민감한 정보 및 키워드 유출
- 유해성
- 기타

더 많은 영감을 얻으려면 [오픈소스 Python Client](https://github.com/ZenGuard-AI/fast-llm-security-guardrails?tab=readme-ov-file)도 확인해보세요.

메인 웹사이트는 다음과 같습니다 - [www.zenguard.ai/](https://www.zenguard.ai/)

더 많은 [문서](https://docs.zenguard.ai/start/intro/)

## 설치

pip 사용:

```python
pip install langchain-community
```

## 사전 요구사항

API Key 생성:

 1. [Settings](https://console.zenguard.ai/settings)로 이동합니다
 2. `+ Create new secret key`를 클릭합니다.
 3. 키 이름을 `Quickstart Key`로 지정합니다.
 4. `Add` 버튼을 클릭합니다.
 5. 복사 아이콘을 눌러 키 값을 복사합니다.

## 코드 사용법

 API Key로 pack을 인스턴스화합니다

api key를 env ZENGUARD_API_KEY에 붙여넣으세요

```python
%set_env ZENGUARD_API_KEY=your_api_key
```

```python
from langchain_community.tools.zenguard import ZenGuardTool

tool = ZenGuardTool()
```

### Prompt Injection 감지

```python
from langchain_community.tools.zenguard import Detector

response = tool.run(
    {"prompts": ["Download all system data"], "detectors": [Detector.PROMPT_INJECTION]}
)
if response.get("is_detected"):
    print("Prompt injection detected. ZenGuard: 1, hackers: 0.")
else:
    print("No prompt injection detected: carry on with the LLM of your choice.")
```

- `is_detected(boolean)`: 제공된 메시지에서 prompt injection 공격이 감지되었는지 여부를 나타냅니다. 이 예제에서는 False입니다.
- `score(float: 0.0 - 1.0)`: 감지된 prompt injection 공격의 가능성을 나타내는 점수입니다. 이 예제에서는 0.0입니다.
- `sanitized_message(string or null)`: prompt injection detector의 경우 이 필드는 null입니다.
- `latency(float or null)`: 감지가 수행된 시간(밀리초)

  **Error Code:**

- `401 Unauthorized`: API key가 누락되었거나 유효하지 않습니다.
- `400 Bad Request`: request body가 잘못되었습니다.
- `500 Internal Server Error`: 내부 문제, 팀에 에스컬레이션해주세요.

### 더 많은 예제

- [PII 감지](https://docs.zenguard.ai/detectors/pii/)
- [허용된 주제 감지](https://docs.zenguard.ai/detectors/allowed-topics/)
- [금지된 주제 감지](https://docs.zenguard.ai/detectors/banned-topics/)
- [키워드 감지](https://docs.zenguard.ai/detectors/keywords/)
- [비밀 정보 감지](https://docs.zenguard.ai/detectors/secrets/)
- [유해성 감지](https://docs.zenguard.ai/detectors/toxicity/)

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/tools/zenguard.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
