---
title: Apache Doris
---

>[Apache Doris](https://doris.apache.org/)는 실시간 분석을 위한 현대적인 데이터 웨어하우스입니다.
대규모 실시간 데이터에 대해 매우 빠른 분석을 제공합니다.

>일반적으로 `Apache Doris`는 OLAP으로 분류되며, [ClickBench — a Benchmark For Analytical DBMS](https://benchmark.clickhouse.com/)에서 뛰어난 성능을 보여주었습니다. 초고속 벡터화 실행 엔진을 갖추고 있어 빠른 vectordb로도 사용할 수 있습니다.

이 통합을 사용하려면 `pip install -qU langchain-community`로 `langchain-community`를 설치해야 합니다

여기서는 Apache Doris Vector Store를 사용하는 방법을 보여드리겠습니다.

## Setup

```python
pip install -qU  pymysql
```

처음에 `update_vectordb = False`로 설정합니다. 업데이트된 문서가 없다면 문서의 embedding을 다시 빌드할 필요가 없습니다

```python
!pip install  sqlalchemy
!pip install langchain
```

```python
from langchain.chains import RetrievalQA
from langchain_community.document_loaders import (
    DirectoryLoader,
    UnstructuredMarkdownLoader,
)
from langchain_community.vectorstores.apache_doris import (
    ApacheDoris,
    ApacheDorisSettings,
)
from langchain_openai import OpenAI, OpenAIEmbeddings
from langchain_text_splitters import TokenTextSplitter

update_vectordb = False
```

## 문서를 로드하고 token으로 분할하기

`docs` 디렉토리 아래의 모든 markdown 파일을 로드합니다

Apache Doris 문서의 경우, [github.com/apache/doris](https://github.com/apache/doris)에서 repo를 clone할 수 있으며, 그 안에 `docs` 디렉토리가 있습니다.

```python
loader = DirectoryLoader(
    "./docs", glob="**/*.md", loader_cls=UnstructuredMarkdownLoader
)
documents = loader.load()
```

문서를 token으로 분할하고, 새로운 문서/token이 있으므로 `update_vectordb = True`로 설정합니다.

```python
# load text splitter and split docs into snippets of text
text_splitter = TokenTextSplitter(chunk_size=400, chunk_overlap=50)
split_docs = text_splitter.split_documents(documents)

# tell vectordb to update text embeddings
update_vectordb = True
```

split_docs[-20]

print("# docs  = %d, # splits = %d" % (len(documents), len(split_docs)))

## vectordb instance 생성하기

### Apache Doris를 vectordb로 사용하기

```python
def gen_apache_doris(update_vectordb, embeddings, settings):
    if update_vectordb:
        docsearch = ApacheDoris.from_documents(split_docs, embeddings, config=settings)
    else:
        docsearch = ApacheDoris(embeddings, settings)
    return docsearch
```

## token을 embedding으로 변환하고 vectordb에 저장하기

여기서는 Apache Doris를 vectordb로 사용하며, `ApacheDorisSettings`를 통해 Apache Doris instance를 구성할 수 있습니다.

Apache Doris instance 구성은 mysql instance 구성과 매우 유사합니다. 다음을 지정해야 합니다:

1. host/port
2. username(기본값: 'root')
3. password(기본값: '')
4. database(기본값: 'default')
5. table(기본값: 'langchain')

```python
import os
from getpass import getpass

if "OPENAI_API_KEY" not in os.environ:
    os.environ["OPENAI_API_KEY"] = getpass()
```

```python
update_vectordb = True

embeddings = OpenAIEmbeddings()

# configure Apache Doris settings(host/port/user/pw/db)
settings = ApacheDorisSettings()
settings.port = 9030
settings.host = "172.30.34.130"
settings.username = "root"
settings.password = ""
settings.database = "langchain"
docsearch = gen_apache_doris(update_vectordb, embeddings, settings)

print(docsearch)

update_vectordb = False
```

## QA를 구축하고 질문하기

```python
llm = OpenAI()
qa = RetrievalQA.from_chain_type(
    llm=llm, chain_type="stuff", retriever=docsearch.as_retriever()
)
query = "what is apache doris"
resp = qa.run(query)
print(resp)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/vectorstores/apache_doris.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
