---
title: ThirdAI NeuralDB
---

>[NeuralDB](https://www.thirdai.com/neuraldb-enterprise/)는 [ThirdAI](https://www.thirdai.com/)에서 개발한 CPU 친화적이고 미세 조정 가능한 vector store입니다.

## 초기화

두 가지 초기화 방법이 있습니다:

- 처음부터: 기본 모델
- Checkpoint에서: 이전에 저장된 모델 로드

다음의 모든 초기화 방법에서 `THIRDAI_KEY` 환경 변수가 설정되어 있으면 `thirdai_key` 매개변수를 생략할 수 있습니다.

ThirdAI API key는 [www.thirdai.com/try-bolt/](https://www.thirdai.com/try-bolt/)에서 얻을 수 있습니다.

이 integration을 사용하려면 `pip install -qU langchain-community`로 `langchain-community`를 설치해야 합니다.

```python
from langchain_community.vectorstores import NeuralDBVectorStore

# From scratch
vectorstore = NeuralDBVectorStore.from_scratch(thirdai_key="your-thirdai-key")

# From checkpoint
vectorstore = NeuralDBVectorStore.from_checkpoint(
    # Path to a NeuralDB checkpoint. For example, if you call
    # vectorstore.save("/path/to/checkpoint.ndb") in one script, then you can
    # call NeuralDBVectorStore.from_checkpoint("/path/to/checkpoint.ndb") in
    # another script to load the saved model.
    checkpoint="/path/to/checkpoint.ndb",
    thirdai_key="your-thirdai-key",
)
```

## Document source 삽입

```python
vectorstore.insert(
    # If you have PDF, DOCX, or CSV files, you can directly pass the paths to the documents
    sources=["/path/to/doc.pdf", "/path/to/doc.docx", "/path/to/doc.csv"],
    # When True this means that the underlying model in the NeuralDB will
    # undergo unsupervised pretraining on the inserted files. Defaults to True.
    train=True,
    # Much faster insertion with a slight drop in performance. Defaults to True.
    fast_mode=True,
)

from thirdai import neural_db as ndb

vectorstore.insert(
    # If you have files in other formats, or prefer to configure how
    # your files are parsed, then you can pass in NeuralDB document objects
    # like this.
    sources=[
        ndb.PDF(
            "/path/to/doc.pdf",
            version="v2",
            chunk_size=100,
            metadata={"published": 2022},
        ),
        ndb.Unstructured("/path/to/deck.pptx"),
    ]
)
```

## 유사도 검색

vectorstore를 쿼리하려면 표준 LangChain vectorstore 메서드인 `similarity_search`를 사용할 수 있으며, 이는 LangChain Document 객체의 리스트를 반환합니다. 각 document 객체는 인덱싱된 파일의 텍스트 청크를 나타냅니다. 예를 들어, 인덱싱된 PDF 파일 중 하나의 단락을 포함할 수 있습니다. 텍스트 외에도 document의 metadata 필드에는 document의 ID, 이 document의 source(어떤 파일에서 왔는지), document의 score와 같은 정보가 포함됩니다.

```python
# This returns a list of LangChain Document objects
documents = vectorstore.similarity_search("query", k=10)
```

## Fine tuning

NeuralDBVectorStore는 사용자 행동과 도메인별 지식에 맞게 fine tuning될 수 있습니다. 두 가지 방법으로 fine tuning할 수 있습니다:

1. Association: vectorstore는 source phrase를 target phrase와 연관시킵니다. vectorstore가 source phrase를 보면 target phrase와 관련된 결과도 고려합니다.
2. Upvoting: vectorstore는 특정 쿼리에 대한 document의 score를 상향 조정합니다. 이는 사용자 행동에 맞게 vectorstore를 fine tuning하려는 경우 유용합니다. 예를 들어, 사용자가 "how is a car manufactured"를 검색하고 id 52인 반환된 document를 좋아한다면, "how is a car manufactured" 쿼리에 대해 id 52인 document를 upvote할 수 있습니다.

```python
vectorstore.associate(source="source phrase", target="target phrase")
vectorstore.associate_batch(
    [
        ("source phrase 1", "target phrase 1"),
        ("source phrase 2", "target phrase 2"),
    ]
)

vectorstore.upvote(query="how is a car manufactured", document_id=52)
vectorstore.upvote_batch(
    [
        ("query 1", 52),
        ("query 2", 20),
    ]
)
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/integrations/vectorstores/thirdai_neuraldb.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
