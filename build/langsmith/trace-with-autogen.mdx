---
title: AutoGen으로 추적하기
sidebarTitle: AutoGen
---

LangSmith는 OpenInference의 AutoGen instrumentation을 사용하여 [AutoGen](https://microsoft.github.io/autogen/stable/)에서 생성된 trace를 캡처할 수 있습니다. 이 가이드는 AutoGen 멀티 에이전트 대화에서 자동으로 trace를 캡처하고 모니터링 및 분석을 위해 LangSmith로 전송하는 방법을 보여줍니다.

## 설치

선호하는 패키지 매니저를 사용하여 필요한 패키지를 설치하세요:

<CodeGroup>

```bash pip
pip install langsmith autogen openinference-instrumentation-autogen openinference-instrumentation-openai
```

```bash uv
uv add langsmith autogen openinference-instrumentation-autogen openinference-instrumentation-openai
```

</CodeGroup>

<Info>
최적의 OpenTelemetry 지원을 위해 LangSmith Python SDK 버전 `langsmith>=0.4.26`이 필요합니다.
</Info>

## 설정

### 1. 환경 변수 구성

API key와 프로젝트 이름을 설정하세요:

<CodeGroup>

```bash Shell
export LANGSMITH_API_KEY=<your_langsmith_api_key>
export LANGSMITH_PROJECT=<your_project_name>
export OPENAI_API_KEY=<your_openai_api_key>
```

</CodeGroup>

### 2. OpenTelemetry 통합 구성

AutoGen 애플리케이션에서 LangSmith OpenTelemetry 통합을 AutoGen 및 OpenAI instrumentor와 함께 import하고 구성하세요:

```python
from langsmith.integrations.otel import configure
from openinference.instrumentation.autogen import AutogenInstrumentor
from openinference.instrumentation.openai import OpenAIInstrumentor

# Configure LangSmith tracing
configure(project_name="autogen-demo")

# Instrument AutoGen and OpenAI calls
AutogenInstrumentor().instrument()
OpenAIInstrumentor().instrument()
```

<Note>
OpenTelemetry 환경 변수를 설정하거나 exporter를 수동으로 구성할 필요가 없습니다—`configure()`가 모든 것을 자동으로 처리합니다.
</Note>

### 3. AutoGen 애플리케이션 생성 및 실행

구성이 완료되면 AutoGen 애플리케이션이 자동으로 LangSmith로 trace를 전송합니다:

```python
import autogen
from openinference.instrumentation.autogen import AutogenInstrumentor
from openinference.instrumentation.openai import OpenAIInstrumentor
from langsmith.integrations.otel import configure
import os
import dotenv

# Load environment variables
dotenv.load_dotenv(".env.local")

# Configure LangSmith tracing
configure(project_name="autogen-code-review")

# Instrument AutoGen and OpenAI
AutogenInstrumentor().instrument()
OpenAIInstrumentor().instrument()

# Configure your agents
config_list = [
    {
        "model": "gpt-4",
        "api_key": os.getenv("OPENAI_API_KEY"),
    }
]

# Create a code reviewer agent
code_reviewer = autogen.AssistantAgent(
    name="code_reviewer",
    llm_config={"config_list": config_list},
    system_message="""You are an expert code reviewer. Your role is to:
    1. Review code for bugs, security issues, and best practices
    2. Suggest improvements and optimizations
    3. Provide constructive feedback
    Always be thorough but constructive in your reviews.""",
)

# Create a developer agent
developer = autogen.AssistantAgent(
    name="developer",
    llm_config={"config_list": config_list},
    system_message="""You are a senior software developer. Your role is to:
    1. Write clean, efficient code
    2. Address feedback from code reviews
    3. Explain your implementation decisions
    4. Implement requested features and fixes""",
)

# Create a user proxy agent
user_proxy = autogen.UserProxyAgent(
    name="user_proxy",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=8,
    is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
    code_execution_config={"work_dir": "workspace"},
    llm_config={"config_list": config_list},
)

def run_code_review_session(task_description: str):
    """Run a multi-agent code review session."""

    # Create a group chat with the agents
    groupchat = autogen.GroupChat(
        agents=[user_proxy, developer, code_reviewer],
        messages=[],
        max_round=10
    )

    # Create a group chat manager
    manager = autogen.GroupChatManager(
        groupchat=groupchat,
        llm_config={"config_list": config_list}
    )

    # Start the conversation
    user_proxy.initiate_chat(
        manager,
        message=f"""
        Task: {task_description}

        Developer: Please implement the requested feature.
        Code Reviewer: Please review the implementation and provide feedback.

        Work together to create a high-quality solution.
        """
    )

    return "Code review session completed"

# Example usage
if __name__ == "__main__":
    task = """
    Create a Python function that implements a binary search algorithm.
    The function should:
    - Take a sorted list and a target value as parameters
    - Return the index of the target if found, or -1 if not found
    - Include proper error handling and documentation
    """

    result = run_code_review_session(task)
    print(f"Result: {result}")
```

## 고급 사용법

### 커스텀 metadata 및 tag

AutoGen 애플리케이션에서 span attribute를 설정하여 trace에 커스텀 metadata를 추가할 수 있습니다:

```python
from opentelemetry import trace

# Get the current tracer
tracer = trace.get_tracer(__name__)

def run_code_review_session(task_description: str):
    with tracer.start_as_current_span("autogen_code_review") as span:
        # Add custom metadata
        span.set_attribute("langsmith.metadata.session_type", "code_review")
        span.set_attribute("langsmith.metadata.agent_count", "3")
        span.set_attribute("langsmith.metadata.task_complexity", "medium")
        span.set_attribute("langsmith.span.tags", "autogen,code-review,multi-agent")

        # Your AutoGen code here
        groupchat = autogen.GroupChat(
            agents=[user_proxy, developer, code_reviewer],
            messages=[],
            max_round=10
        )

        manager = autogen.GroupChatManager(
            groupchat=groupchat,
            llm_config={"config_list": config_list}
        )

        user_proxy.initiate_chat(manager, message=task_description)
        return "Session completed"
```

### 다른 instrumentor와 결합

AutoGen instrumentation을 다른 instrumentor(예: Semantic Kernel, DSPy)와 결합하려면 이를 추가하고 instrumentor로 초기화하세요:

```python
from langsmith.integrations.otel import configure
from openinference.instrumentation.autogen import AutogenInstrumentor
from openinference.instrumentation.openai import OpenAIInstrumentor
from openinference.instrumentation.dspy import DSPyInstrumentor

# Configure LangSmith tracing
configure(project_name="multi-framework-app")

# Initialize multiple instrumentors
AutogenInstrumentor().instrument()
OpenAIInstrumentor().instrument()
DSPyInstrumentor().instrument()

# Your application code using multiple frameworks
```

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/trace-with-autogen.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
