---
title: 프로그래밍 방식으로 prompt 관리하기
sidebarTitle: 프로그래밍 방식으로 prompt 관리하기
---

LangSmith Python 및 TypeScript SDK를 사용하여 프로그래밍 방식으로 prompt를 관리할 수 있습니다.

<Note>
이전에는 이 기능이 `langchainhub` package에 있었으나 현재는 deprecated되었습니다. 앞으로 모든 기능은 `langsmith` package에 포함됩니다.
</Note>

## package 설치

Python에서는 LangSmith SDK를 직접 사용하거나(*권장, 전체 기능 제공*) LangChain package를 통해 사용할 수 있습니다(prompt push 및 pull로 제한됨).

TypeScript에서는 prompt를 pull하기 위해 LangChain npm package를 사용해야 합니다(push도 가능). 다른 모든 기능은 LangSmith package를 사용하세요.

<CodeGroup>
```bash pip
pip install -U langsmith # version >= 0.1.99
pip install -U langchain langsmith # langsmith version >= 0.1.99 and langchain >= 0.2.13
```

```bash uv
uv add langsmith  # version >= 0.1.99
uv add langchain langsmith # langsmith version >= 0.1.99 and langchain >= 0.2.13
```

```bash TypeScript
yarn add langsmith langchain // langsmith version >= 0.1.99 and langchain version >= 0.2.14
```
</CodeGroup>

## 환경 변수 설정

LangSmith에서 현재 workspace의 api key로 `LANGSMITH_API_KEY`를 이미 설정했다면 이 단계를 건너뛸 수 있습니다.

그렇지 않은 경우, LangSmith에서 `Settings > API Keys > Create API Key`로 이동하여 workspace의 API key를 가져오세요.

환경 변수를 설정하세요.

```bash
export LANGSMITH_API_KEY="lsv2_..."
```

<Note>
우리가 "prompts"라고 부르는 것은 이전에 "repos"라고 불렸으므로, 코드에서 "repo"에 대한 모든 참조는 prompt를 의미합니다.
</Note>

## prompt push하기

새 prompt를 생성하거나 기존 prompt를 업데이트하려면 `push prompt` method를 사용할 수 있습니다.

<CodeGroup>

```python Python
from langsmith import Client
from langchain_core.prompts import ChatPromptTemplate

client = Client()
prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
url = client.push_prompt("joke-generator", object=prompt)
# url is a link to the prompt in the UI
print(url)
```

```python LangChain (Python)
from langchain_classic import hub as prompts
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
url = prompts.push("joke-generator", prompt)
# url is a link to the prompt in the UI
print(url)
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { ChatPromptTemplate } from "@langchain/core/prompts";

const prompt = ChatPromptTemplate.fromTemplate("tell me a joke about {topic}");
const url = hub.push("joke-generator", {
  object: prompt,
});
// url is a link to the prompt in the UI
console.log(url);
```

</CodeGroup>

prompt와 model의 RunnableSequence로 prompt를 push할 수도 있습니다. 이는 이 prompt와 함께 사용하려는 model 구성을 저장하는 데 유용합니다. provider는 LangSmith playground에서 지원되어야 합니다. (설정 참조: [Supported Providers](https://langsmith.com/playground))

<CodeGroup>

```python Python
from langsmith import Client
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

client = Client()
model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
chain = prompt | model
client.push_prompt("joke-generator-with-model", object=chain)
```

```python LangChain (Python)
from langchain_classic import hub as prompts
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4o-mini")
prompt = ChatPromptTemplate.from_template("tell me a joke about {topic}")
chain = prompt | model
url = prompts.push("joke-generator-with-model", chain)
# url is a link to the prompt in the UI
print(url)
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { ChatOpenAI } from "@langchain/openai";

const model = new ChatOpenAI({ model: "gpt-4o-mini" });
const prompt = ChatPromptTemplate.fromTemplate("tell me a joke about {topic}");
const chain = prompt.pipe(model);
await hub.push("joke-generator-with-model", {
  object: chain,
});
```

</CodeGroup>

## prompt pull하기

prompt를 pull하려면 `pull prompt` method를 사용할 수 있으며, 이는 prompt를 langchain `PromptTemplate`로 반환합니다.

**private prompt**를 pull하려면 owner handle을 지정할 필요가 없습니다(설정한 경우 지정할 수 있습니다).

LangChain Hub에서 **public prompt**를 pull하려면 prompt 작성자의 handle을 지정해야 합니다.

<CodeGroup>

```python Python
from langsmith import Client
from langchain_openai import ChatOpenAI

client = Client()
prompt = client.pull_prompt("joke-generator")
model = ChatOpenAI(model="gpt-4o-mini")
chain = prompt | model
chain.invoke({"topic": "cats"})
```

```python LangChain (Python)
from langchain_classic import hub as prompts
from langchain_openai import ChatOpenAI

prompt = prompts.pull("joke-generator")
model = ChatOpenAI(model="gpt-4o-mini")
chain = prompt | model
chain.invoke({"topic": "cats"})
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { ChatOpenAI } from "@langchain/openai";

const prompt = await hub.pull("joke-generator");
const model = new ChatOpenAI({ model: "gpt-4o-mini" });
const chain = prompt.pipe(model);
await chain.invoke({"topic": "cats"});
```

</CodeGroup>

prompt를 push하는 것과 유사하게, prompt와 model의 RunnableSequence로 prompt를 pull할 수도 있습니다. prompt를 pull할 때 include\_model을 지정하기만 하면 됩니다. 저장된 prompt에 model이 포함되어 있으면 RunnableSequence로 반환됩니다. 사용 중인 model에 대한 적절한 환경 변수가 설정되어 있는지 확인하세요.

<CodeGroup>

```python Python
from langsmith import Client

client = Client()
chain = client.pull_prompt("joke-generator-with-model", include_model=True)
chain.invoke({"topic": "cats"})
```

```python LangChain (Python)
from langchain_classic import hub as prompts

chain = prompts.pull("joke-generator-with-model", include_model=True)
chain.invoke({"topic": "cats"})
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { Runnable } from "@langchain/core/runnables";

const chain = await hub.pull<Runnable>("joke-generator-with-model", { includeModel: true });
await chain.invoke({"topic": "cats"});
```

</CodeGroup>

prompt를 pull할 때 특정 commit hash 또는 [commit tag](/langsmith/manage-prompts#commit-tags)를 지정하여 prompt의 특정 버전을 pull할 수도 있습니다.

<CodeGroup>

```python Python
prompt = client.pull_prompt("joke-generator:12344e88")
```

```python LangChain (Python)
prompt = prompts.pull("joke-generator:12344e88")
```

```typescript TypeScript
const prompt = await hub.pull("joke-generator:12344e88")
```

</CodeGroup>

LangChain Hub에서 public prompt를 pull하려면 prompt 작성자의 handle을 지정해야 합니다.

<CodeGroup>

```python Python
prompt = client.pull_prompt("efriis/my-first-prompt")
```

```python LangChain (Python)
prompt = prompts.pull("efriis/my-first-prompt")
```

```typescript TypeScript
const prompt = await hub.pull("efriis/my-first-prompt")
```

</CodeGroup>

<Note>
prompt를 pull할 때, Node.js 또는 dynamic import를 지원하는 환경을 사용하는 경우 `langchain/hub/node` entrypoint를 사용하는 것이 좋습니다. 이는 prompt 구성과 연결된 model의 deserialization을 자동으로 처리합니다.

Node가 아닌 환경에서는 "includeModel"이 OpenAI가 아닌 model에 대해 지원되지 않으므로 기본 `langchain/hub` entrypoint를 사용해야 합니다.
</Note>

## LangChain 없이 prompt 사용하기

LangSmith에 prompt를 저장하되 model provider의 API와 직접 사용하려면 변환 method를 사용할 수 있습니다. 이들은 prompt를 OpenAI 또는 Anthropic API에 필요한 payload로 변환합니다.

이러한 변환 method는 LangChain integration package 내의 로직에 의존하므로, 선택한 공식 SDK 외에도 적절한 package를 dependency로 설치해야 합니다. 다음은 몇 가지 예시입니다:

### OpenAI

<CodeGroup>

```bash Python
pip install -U langchain_openai
```

```bash TypeScript
yarn add @langchain/openai @langchain/core // @langchain/openai version >= 0.3.2
```

</CodeGroup>

<CodeGroup>

```python Python
from openai import OpenAI
from langsmith.client import Client, convert_prompt_to_openai_format

# langsmith client
client = Client()
# openai client
oai_client = OpenAI()

# pull prompt and invoke to populate the variables
prompt = client.pull_prompt("joke-generator")
prompt_value = prompt.invoke({"topic": "cats"})
openai_payload = convert_prompt_to_openai_format(prompt_value)
openai_response = oai_client.chat.completions.create(**openai_payload)
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { convertPromptToOpenAI } from "@langchain/openai";
import OpenAI from "openai";

const prompt = await hub.pull("jacob/joke-generator");
const formattedPrompt = await prompt.invoke({
  topic: "cats",
});
const { messages } = convertPromptToOpenAI(formattedPrompt);

const openAIClient = new OpenAI();
const openAIResponse = await openAIClient.chat.completions.create({
  model: "gpt-4o-mini",
  messages,
});
```

</CodeGroup>

### Anthropic

<CodeGroup>

```bash Python
pip install -U langchain_anthropic
```

```bash TypeScript
yarn add @langchain/anthropic @langchain/core // @langchain/anthropic version >= 0.3.3
```

</CodeGroup>

<CodeGroup>

```python Python
from anthropic import Anthropic
from langsmith.client import Client, convert_prompt_to_anthropic_format

# langsmith client
client = Client()
# anthropic client
anthropic_client = Anthropic()

# pull prompt and invoke to populate the variables
prompt = client.pull_prompt("joke-generator")
prompt_value = prompt.invoke({"topic": "cats"})
anthropic_payload = convert_prompt_to_anthropic_format(prompt_value)
anthropic_response = anthropic_client.messages.create(**anthropic_payload)
```

```typescript TypeScript
import * as hub from "langchain/hub";
import { convertPromptToAnthropic } from "@langchain/anthropic";
import Anthropic from "@anthropic-ai/sdk";

const prompt = await hub.pull("jacob/joke-generator");
const formattedPrompt = await prompt.invoke({
  topic: "cats",
});
const { messages, system } = convertPromptToAnthropic(formattedPrompt);

const anthropicClient = new Anthropic();
const anthropicResponse = await anthropicClient.messages.create({
  model: "claude-3-haiku-20240307",
  system,
  messages,
  max_tokens: 1024,
  stream: false,
});
```

</CodeGroup>

## prompt 목록 조회, 삭제 및 좋아요

`list prompts`, `delete prompt`, `like prompt` 및 `unlike prompt` method를 사용하여 prompt를 목록 조회, 삭제 및 좋아요/좋아요 취소할 수도 있습니다. 이러한 method에 대한 광범위한 문서는 [LangSmith SDK client](https://github.com/langchain-ai/langsmith-sdk)를 참조하세요.

<CodeGroup>

```python Python
# List all prompts in my workspace
prompts = client.list_prompts()

# List my private prompts that include "joke"
prompts = client.list_prompts(query="joke", is_public=False)

# Delete a prompt
client.delete_prompt("joke-generator")

# Like a prompt
client.like_prompt("efriis/my-first-prompt")

# Unlike a prompt
client.unlike_prompt("efriis/my-first-prompt")
```

```typescript TypeScript
// List all prompts in my workspace
import Client from "langsmith";

const client = new Client({ apiKey: "lsv2_..." });
const prompts = client.listPrompts();

for await (const prompt of prompts) {
  console.log(prompt);
}

// List my private prompts that include "joke"
const private_joke_prompts = client.listPrompts({ query: "joke", isPublic: false});

// Delete a prompt
client.deletePrompt("joke-generator");

// Like a prompt
client.likePrompt("efriis/my-first-prompt");

// Unlike a prompt
client.unlikePrompt("efriis/my-first-prompt");
```

</CodeGroup>

---

<Callout icon="pen-to-square" iconType="regular">
    [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/langsmith/manage-prompts-programmatically.mdx)
</Callout>
<Tip icon="terminal" iconType="regular">
    [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for    real-time answers.
</Tip>
